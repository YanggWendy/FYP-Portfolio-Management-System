{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YanggWendy/FYP-Portfolio-Management-System/blob/main/FYP_2000_2022_Long_1234_new_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQmep9Gace9s"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ2tsFHqDJwn",
        "outputId": "217f0174-455e-4e40-934d-c797c7a88ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "FOLDERNAME = 'FYP Data/'\n",
        "assert FOLDERNAME is not None, \"[1]Enter the foldername.\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlaqXHFO-kN0",
        "outputId": "732950c9-0d83-47e9-cfab-129412c13c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.9/dist-packages (0.2.17)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.9/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.9/dist-packages (from yfinance) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.9/dist-packages (from yfinance) (1.22.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.9/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.9/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.9/dist-packages (from yfinance) (4.9.2)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.9/dist-packages (from yfinance) (2.3.7)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.9/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.9/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: cryptography>=3.3.2 in /usr/local/lib/python3.9/dist-packages (from yfinance) (40.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.9/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fundamentalanalysis\n",
            "  Downloading fundamentalanalysis-0.2.14-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: fundamentalanalysis\n",
            "Successfully installed fundamentalanalysis-0.2.14\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install fundamentalanalysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF6v7dh-E9l6"
      },
      "outputs": [],
      "source": [
        "PATH = '/content/drive/My Drive/FYP Data/' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToK29hD_-R8c"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import statistics\n",
        "import fundamentalanalysis as fa\n",
        "import datetime\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau,TensorBoard\n",
        "from tensorflow.keras.models import load_model\n",
        "import math\n",
        "from keras import Input # for instantiating a keras tensor\n",
        "from keras.layers import Bidirectional, GRU, RepeatVector, Dense, TimeDistributed # for creating layers inside the Neural Network\n",
        "from keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDxQFn0OowH8"
      },
      "source": [
        "# Get Ticker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkSKSsaC_-vp"
      },
      "outputs": [],
      "source": [
        "sp500url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
        "data_table = pd.read_html(sp500url)\n",
        "data_table[0]\n",
        "SP500_ticker = data_table[0]['Symbol'].tolist()\n",
        "\n",
        "#remove invalid stock ticker\n",
        "SP500_ticker.remove('BRK.B')\n",
        "SP500_ticker.remove('BF.B')\n",
        "SP500_ticker.remove('GEHC')\n",
        "#SP500_ticker.remove('BG')\n",
        "#SP500_ticker.remove('FICO')\n",
        "#SP500_ticker.remove('PODD')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ5rsKJQNVCA",
        "outputId": "50de1348-8e49-4b8e-9690-29f0dda43544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  500 of 500 completed\n"
          ]
        }
      ],
      "source": [
        "#data = yf.download(SP500_ticker, period='max', interval=\"1d\", group_by='tickers')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrLMn20eBOWx"
      },
      "source": [
        "# Get Technical list & Fundamental data list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fx9nR29FBNzL"
      },
      "outputs": [],
      "source": [
        "Technical_list = ['Close','Volume','VEMA12','VSTD20','V20','AR','BR','AU','AD']\n",
        "fundamental_list = ['marketCap', 'peRatio', 'pbRatio', 'evToSales','receivablesTurnover', 'payablesTurnover','debtToAssets', 'inventoryTurnover',\n",
        " 'roe','revenuePerShare','cashPerShare']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "2lwe8G2NIIJN",
        "outputId": "310294f8-cce8-43a3-fa46-226149b6ed6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 FOXA                                                         \\\n",
              "                 Open       High        Low      Close  Adj Close     Volume   \n",
              "Date                                                                           \n",
              "2023-01-31  33.660000  33.980000  33.514999  33.939999  33.702190  2027800.0   \n",
              "2023-01-30  33.580002  33.869999  33.490002  33.660000  33.424152  1951800.0   \n",
              "2023-01-27  33.930000  34.075001  33.665001  33.849998  33.612820  1518600.0   \n",
              "2023-01-26  33.540001  34.049999  33.419998  33.959999  33.722050  2239200.0   \n",
              "2023-01-25  33.259998  34.139999  33.040001  33.490002  33.255348  5308100.0   \n",
              "...               ...        ...        ...        ...        ...        ...   \n",
              "1993-02-04        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "1993-02-03        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "1993-02-02        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "1993-02-01        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "1993-01-29        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "\n",
              "                   ZTS                                      ...   WTW   GWW  \\\n",
              "                  Open        High         Low       Close  ...    AD    AD   \n",
              "Date                                                        ...               \n",
              "2023-01-31  164.500000  165.710007  162.619995  165.490005  ...  0.04  0.36   \n",
              "2023-01-30  164.000000  165.630005  163.820007  164.699997  ...  0.08  0.40   \n",
              "2023-01-27  166.979996  167.690002  164.500000  165.179993  ...  0.04  0.44   \n",
              "2023-01-26  166.869995  168.300003  166.119995  168.240005  ...  0.04  0.48   \n",
              "2023-01-25  165.440002  166.720001  163.779999  165.509995  ...  0.04  0.52   \n",
              "...                ...         ...         ...         ...  ...   ...   ...   \n",
              "1993-02-04         NaN         NaN         NaN         NaN  ...  0.00  0.00   \n",
              "1993-02-03         NaN         NaN         NaN         NaN  ...  0.00  0.00   \n",
              "1993-02-02         NaN         NaN         NaN         NaN  ...  0.00  0.00   \n",
              "1993-02-01         NaN         NaN         NaN         NaN  ...  0.00  0.00   \n",
              "1993-01-29         NaN         NaN         NaN         NaN  ...  0.00  0.00   \n",
              "\n",
              "            WYNN   XEL   XYL   YUM  ZBRA   ZBH  ZION   ZTS  \n",
              "              AD    AD    AD    AD    AD    AD    AD    AD  \n",
              "Date                                                        \n",
              "2023-01-31  0.20  0.76  0.80  0.28  0.04  0.72  0.04  0.40  \n",
              "2023-01-30  0.24  0.80  0.84  0.32  0.08  0.76  0.08  0.44  \n",
              "2023-01-27  0.28  0.84  0.88  0.36  0.12  0.80  0.04  0.04  \n",
              "2023-01-26  0.32  0.88  0.92  0.40  0.16  0.84  0.04  0.08  \n",
              "2023-01-25  0.36  0.92  0.96  0.44  0.20  0.88  0.08  0.12  \n",
              "...          ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "1993-02-04  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
              "1993-02-03  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
              "1993-02-02  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
              "1993-02-01  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
              "1993-01-29  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
              "\n",
              "[7556 rows x 6500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffc42cea-5e25-4952-90e6-c114d1aff056\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">FOXA</th>\n",
              "      <th colspan=\"4\" halign=\"left\">ZTS</th>\n",
              "      <th>...</th>\n",
              "      <th>WTW</th>\n",
              "      <th>GWW</th>\n",
              "      <th>WYNN</th>\n",
              "      <th>XEL</th>\n",
              "      <th>XYL</th>\n",
              "      <th>YUM</th>\n",
              "      <th>ZBRA</th>\n",
              "      <th>ZBH</th>\n",
              "      <th>ZION</th>\n",
              "      <th>ZTS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>...</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-01-31</th>\n",
              "      <td>33.660000</td>\n",
              "      <td>33.980000</td>\n",
              "      <td>33.514999</td>\n",
              "      <td>33.939999</td>\n",
              "      <td>33.702190</td>\n",
              "      <td>2027800.0</td>\n",
              "      <td>164.500000</td>\n",
              "      <td>165.710007</td>\n",
              "      <td>162.619995</td>\n",
              "      <td>165.490005</td>\n",
              "      <td>...</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-30</th>\n",
              "      <td>33.580002</td>\n",
              "      <td>33.869999</td>\n",
              "      <td>33.490002</td>\n",
              "      <td>33.660000</td>\n",
              "      <td>33.424152</td>\n",
              "      <td>1951800.0</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>165.630005</td>\n",
              "      <td>163.820007</td>\n",
              "      <td>164.699997</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-27</th>\n",
              "      <td>33.930000</td>\n",
              "      <td>34.075001</td>\n",
              "      <td>33.665001</td>\n",
              "      <td>33.849998</td>\n",
              "      <td>33.612820</td>\n",
              "      <td>1518600.0</td>\n",
              "      <td>166.979996</td>\n",
              "      <td>167.690002</td>\n",
              "      <td>164.500000</td>\n",
              "      <td>165.179993</td>\n",
              "      <td>...</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-26</th>\n",
              "      <td>33.540001</td>\n",
              "      <td>34.049999</td>\n",
              "      <td>33.419998</td>\n",
              "      <td>33.959999</td>\n",
              "      <td>33.722050</td>\n",
              "      <td>2239200.0</td>\n",
              "      <td>166.869995</td>\n",
              "      <td>168.300003</td>\n",
              "      <td>166.119995</td>\n",
              "      <td>168.240005</td>\n",
              "      <td>...</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-25</th>\n",
              "      <td>33.259998</td>\n",
              "      <td>34.139999</td>\n",
              "      <td>33.040001</td>\n",
              "      <td>33.490002</td>\n",
              "      <td>33.255348</td>\n",
              "      <td>5308100.0</td>\n",
              "      <td>165.440002</td>\n",
              "      <td>166.720001</td>\n",
              "      <td>163.779999</td>\n",
              "      <td>165.509995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-02-04</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-02-03</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-02-02</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-02-01</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-01-29</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7556 rows Ã— 6500 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffc42cea-5e25-4952-90e6-c114d1aff056')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ffc42cea-5e25-4952-90e6-c114d1aff056 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ffc42cea-5e25-4952-90e6-c114d1aff056');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "stock_data = pd.read_csv(\"drive/My Drive/FYP Data/stock data.csv\",index_col = 0,header = [0,1])\n",
        "stock_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHgYPkXpBh-_"
      },
      "source": [
        "# Add stock selection label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SP500_final = pd.read_csv(\"drive/My Drive/FYP Data/sp500 data final.csv\",index_col = 0,header = [0,1])\n",
        "SP500_final = SP500_final.drop(index='2023-01-31')\n",
        "\n",
        "SP500_final"
      ],
      "metadata": {
        "id": "wUOKqMbo1SfI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "outputId": "21eb3825-bb21-4020-a220-907b63942264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 FOXA                                                         \\\n",
              "                 Open       High        Low      Close  Adj Close     Volume   \n",
              "Date                                                                           \n",
              "2022-12-30  30.299999  30.459999  29.920000  30.370001  30.157207  2620900.0   \n",
              "2022-11-30  31.629999  32.465000  31.250000  32.450001  32.222633  4222200.0   \n",
              "2022-10-31  28.840000  29.000000  28.469999  28.870001  28.667717  3363700.0   \n",
              "2022-09-30  30.719999  31.360001  30.549999  30.680000  30.465034  3276000.0   \n",
              "2022-08-31  34.400002  34.689999  34.160000  34.180000  33.940510  2479900.0   \n",
              "...               ...        ...        ...        ...        ...        ...   \n",
              "1993-05-28        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "1993-04-30        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "1993-03-31        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "1993-02-26        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "1993-01-29        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "\n",
              "                   ZTS                                      ...  \\\n",
              "                  Open        High         Low       Close  ...   \n",
              "Date                                                        ...   \n",
              "2022-12-30  147.199997  147.789993  144.740005  146.550003  ...   \n",
              "2022-11-30  148.089996  154.179993  146.910004  154.139999  ...   \n",
              "2022-10-31  152.110001  153.339996  149.839996  150.779999  ...   \n",
              "2022-09-30  150.419998  152.029999  148.039993  148.289993  ...   \n",
              "2022-08-31  158.160004  159.410004  156.210007  156.529999  ...   \n",
              "...                ...         ...         ...         ...  ...   \n",
              "1993-05-28         NaN         NaN         NaN         NaN  ...   \n",
              "1993-04-30         NaN         NaN         NaN         NaN  ...   \n",
              "1993-03-31         NaN         NaN         NaN         NaN  ...   \n",
              "1993-02-26         NaN         NaN         NaN         NaN  ...   \n",
              "1993-01-29         NaN         NaN         NaN         NaN  ...   \n",
              "\n",
              "                                WTW                      GWW  \\\n",
              "           excessive monthly return excessive monthly return   \n",
              "Date                                                           \n",
              "2022-12-30                -0.086483                -0.066035   \n",
              "2022-11-30                 0.117453                 0.046251   \n",
              "2022-10-31                 0.016905                -0.079165   \n",
              "2022-09-30                -0.076605                 0.031974   \n",
              "2022-08-31                 0.163840                 0.073836   \n",
              "...                             ...                      ...   \n",
              "1993-05-28                      NaN                -0.024339   \n",
              "1993-04-30                      NaN                -0.015399   \n",
              "1993-03-31                      NaN                 0.084719   \n",
              "1993-02-26                      NaN                 0.046446   \n",
              "1993-01-29                      NaN                -0.068853   \n",
              "\n",
              "                               WYNN                      XEL  \\\n",
              "           excessive monthly return excessive monthly return   \n",
              "Date                                                           \n",
              "2022-12-30                 0.130925                -0.144888   \n",
              "2022-11-30                 0.109647                 0.122305   \n",
              "2022-10-31                 0.198050                -0.032700   \n",
              "2022-09-30                -0.148748                -0.145207   \n",
              "2022-08-31                 0.232588                 0.054270   \n",
              "...                             ...                      ...   \n",
              "1993-05-28                      NaN                 0.046571   \n",
              "1993-04-30                      NaN                -0.081487   \n",
              "1993-03-31                      NaN                 0.024366   \n",
              "1993-02-26                      NaN                -0.037860   \n",
              "1993-01-29                      NaN                 0.041163   \n",
              "\n",
              "                                XYL                      YUM  \\\n",
              "           excessive monthly return excessive monthly return   \n",
              "Date                                                           \n",
              "2022-12-30                -0.185104                -0.106802   \n",
              "2022-11-30                 0.108028                 0.119364   \n",
              "2022-10-31                -0.014336                -0.023149   \n",
              "2022-09-30                 0.009953                -0.050552   \n",
              "2022-08-31                 0.151264                 0.148269   \n",
              "...                             ...                      ...   \n",
              "1993-05-28                      NaN                      NaN   \n",
              "1993-04-30                      NaN                      NaN   \n",
              "1993-03-31                      NaN                      NaN   \n",
              "1993-02-26                      NaN                      NaN   \n",
              "1993-01-29                      NaN                      NaN   \n",
              "\n",
              "                               ZBRA                      ZBH  \\\n",
              "           excessive monthly return excessive monthly return   \n",
              "Date                                                           \n",
              "2022-12-30                 0.107328                -0.127030   \n",
              "2022-11-30                 0.072555                 0.185487   \n",
              "2022-10-31                -0.156872                -0.051633   \n",
              "2022-09-30                -0.081600                -0.078381   \n",
              "2022-08-31                 0.060936                 0.175670   \n",
              "...                             ...                      ...   \n",
              "1993-05-28                 0.130199                      NaN   \n",
              "1993-04-30                 0.152673                      NaN   \n",
              "1993-03-31                 0.214637                      NaN   \n",
              "1993-02-26                 0.083093                      NaN   \n",
              "1993-01-29                -0.062574                      NaN   \n",
              "\n",
              "                               ZION                      ZTS  \n",
              "           excessive monthly return excessive monthly return  \n",
              "Date                                                          \n",
              "2022-12-30                -0.044408                 0.003464  \n",
              "2022-11-30                 0.072540                 0.074631  \n",
              "2022-10-31                -0.113493                -0.088899  \n",
              "2022-09-30                -0.141316                -0.145760  \n",
              "2022-08-31                 0.116541                 0.139676  \n",
              "...                             ...                      ...  \n",
              "1993-05-28                -0.046344                      NaN  \n",
              "1993-04-30                -0.053939                      NaN  \n",
              "1993-03-31                -0.068616                      NaN  \n",
              "1993-02-26                 0.002651                      NaN  \n",
              "1993-01-29                 0.035806                      NaN  \n",
              "\n",
              "[360 rows x 7505 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10403f2f-a91e-4c52-a400-15d930034c98\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">FOXA</th>\n",
              "      <th colspan=\"4\" halign=\"left\">ZTS</th>\n",
              "      <th>...</th>\n",
              "      <th>WTW</th>\n",
              "      <th>GWW</th>\n",
              "      <th>WYNN</th>\n",
              "      <th>XEL</th>\n",
              "      <th>XYL</th>\n",
              "      <th>YUM</th>\n",
              "      <th>ZBRA</th>\n",
              "      <th>ZBH</th>\n",
              "      <th>ZION</th>\n",
              "      <th>ZTS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>...</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>30.299999</td>\n",
              "      <td>30.459999</td>\n",
              "      <td>29.920000</td>\n",
              "      <td>30.370001</td>\n",
              "      <td>30.157207</td>\n",
              "      <td>2620900.0</td>\n",
              "      <td>147.199997</td>\n",
              "      <td>147.789993</td>\n",
              "      <td>144.740005</td>\n",
              "      <td>146.550003</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.086483</td>\n",
              "      <td>-0.066035</td>\n",
              "      <td>0.130925</td>\n",
              "      <td>-0.144888</td>\n",
              "      <td>-0.185104</td>\n",
              "      <td>-0.106802</td>\n",
              "      <td>0.107328</td>\n",
              "      <td>-0.127030</td>\n",
              "      <td>-0.044408</td>\n",
              "      <td>0.003464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>31.629999</td>\n",
              "      <td>32.465000</td>\n",
              "      <td>31.250000</td>\n",
              "      <td>32.450001</td>\n",
              "      <td>32.222633</td>\n",
              "      <td>4222200.0</td>\n",
              "      <td>148.089996</td>\n",
              "      <td>154.179993</td>\n",
              "      <td>146.910004</td>\n",
              "      <td>154.139999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.117453</td>\n",
              "      <td>0.046251</td>\n",
              "      <td>0.109647</td>\n",
              "      <td>0.122305</td>\n",
              "      <td>0.108028</td>\n",
              "      <td>0.119364</td>\n",
              "      <td>0.072555</td>\n",
              "      <td>0.185487</td>\n",
              "      <td>0.072540</td>\n",
              "      <td>0.074631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>28.840000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>28.469999</td>\n",
              "      <td>28.870001</td>\n",
              "      <td>28.667717</td>\n",
              "      <td>3363700.0</td>\n",
              "      <td>152.110001</td>\n",
              "      <td>153.339996</td>\n",
              "      <td>149.839996</td>\n",
              "      <td>150.779999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016905</td>\n",
              "      <td>-0.079165</td>\n",
              "      <td>0.198050</td>\n",
              "      <td>-0.032700</td>\n",
              "      <td>-0.014336</td>\n",
              "      <td>-0.023149</td>\n",
              "      <td>-0.156872</td>\n",
              "      <td>-0.051633</td>\n",
              "      <td>-0.113493</td>\n",
              "      <td>-0.088899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>30.719999</td>\n",
              "      <td>31.360001</td>\n",
              "      <td>30.549999</td>\n",
              "      <td>30.680000</td>\n",
              "      <td>30.465034</td>\n",
              "      <td>3276000.0</td>\n",
              "      <td>150.419998</td>\n",
              "      <td>152.029999</td>\n",
              "      <td>148.039993</td>\n",
              "      <td>148.289993</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.076605</td>\n",
              "      <td>0.031974</td>\n",
              "      <td>-0.148748</td>\n",
              "      <td>-0.145207</td>\n",
              "      <td>0.009953</td>\n",
              "      <td>-0.050552</td>\n",
              "      <td>-0.081600</td>\n",
              "      <td>-0.078381</td>\n",
              "      <td>-0.141316</td>\n",
              "      <td>-0.145760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>34.400002</td>\n",
              "      <td>34.689999</td>\n",
              "      <td>34.160000</td>\n",
              "      <td>34.180000</td>\n",
              "      <td>33.940510</td>\n",
              "      <td>2479900.0</td>\n",
              "      <td>158.160004</td>\n",
              "      <td>159.410004</td>\n",
              "      <td>156.210007</td>\n",
              "      <td>156.529999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.163840</td>\n",
              "      <td>0.073836</td>\n",
              "      <td>0.232588</td>\n",
              "      <td>0.054270</td>\n",
              "      <td>0.151264</td>\n",
              "      <td>0.148269</td>\n",
              "      <td>0.060936</td>\n",
              "      <td>0.175670</td>\n",
              "      <td>0.116541</td>\n",
              "      <td>0.139676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-05-28</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.024339</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.046571</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.130199</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.046344</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-04-30</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.015399</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.081487</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.152673</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.053939</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-03-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.084719</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.024366</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.214637</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.068616</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-02-26</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.046446</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.037860</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.083093</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.002651</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-01-29</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.068853</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.041163</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.062574</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.035806</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>360 rows Ã— 7505 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10403f2f-a91e-4c52-a400-15d930034c98')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10403f2f-a91e-4c52-a400-15d930034c98 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10403f2f-a91e-4c52-a400-15d930034c98');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "70c5b167d69b4cfdb4fbb3dec4ccbaab",
            "de8bd591cb6a4ff19aa3184e8c34c447",
            "6444f2e66f6240d4b91d87be65497c8e",
            "dd4c62282ce841fcbe77f83f20b64ad2",
            "8a682286f6374973a07d15397d9bd447",
            "90c7cb64659245378833e391230f758f",
            "c2fcd3e215c6401ba93de100d2bf193c",
            "806a464727674843a12f7ce55e4ee8f0",
            "3073da8b73d64e07b0fc51bc062a1964",
            "680a0bdb067b459bb6595d932304fd4e",
            "7da5668281b3446ea1684bfc7786ba68"
          ]
        },
        "id": "B-eIIPfnBgAr",
        "outputId": "d41cb9e4-6e0f-4c56-c92f-283348155e8a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70c5b167d69b4cfdb4fbb3dec4ccbaab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
            "<ipython-input-13-b57bcc10e4b1>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 MMM       AOS       ABT        ABBV         ACN        ATVI  \\\n",
              "Date                                                                           \n",
              "2022-12-30 -0.166135  0.056965 -0.118852   -0.211537   -0.080017   -0.125514   \n",
              "2022-11-30  0.075844  0.066249  0.144415    0.126540    0.010590    0.159031   \n",
              "2022-10-31 -0.109752 -0.002384 -0.023857   -0.010227   -0.051197   -0.095386   \n",
              "2022-09-30 -0.024180 -0.034927 -0.140021   -0.071723   -0.059170   -0.183267   \n",
              "2022-08-31  0.080938  0.052902  0.134938    0.190458    0.084296    0.139444   \n",
              "...              ...       ...       ...         ...         ...         ...   \n",
              "1993-05-28 -0.036279  0.014785 -0.048389 -100.000000 -100.000000 -100.000000   \n",
              "1993-04-30 -0.039332  0.144174 -0.080845 -100.000000 -100.000000 -100.000000   \n",
              "1993-03-31  0.067157 -0.042842  0.133700 -100.000000 -100.000000 -100.000000   \n",
              "1993-02-26  0.002728  0.068587 -0.049541 -100.000000 -100.000000 -100.000000   \n",
              "1993-01-29  0.055193  0.035141 -0.071337 -100.000000 -100.000000 -100.000000   \n",
              "\n",
              "                 ADM      ADBE       ADP         AAP  ...         WTW  \\\n",
              "Date                                                  ...               \n",
              "2022-12-30 -0.233475 -0.025308 -0.180409   -0.090068  ...   -0.086483   \n",
              "2022-11-30  0.076179  0.099519  0.028165    0.097645  ...    0.117453   \n",
              "2022-10-31 -0.105821 -0.028200 -0.018341   -0.316164  ...    0.016905   \n",
              "2022-09-30  0.042918 -0.005211 -0.093980    0.052237  ...   -0.076605   \n",
              "2022-08-31  0.107666 -0.070750  0.117771    0.119381  ...    0.163840   \n",
              "...              ...       ...       ...         ...  ...         ...   \n",
              "1993-05-28 -0.003560 -0.057483 -0.003398 -100.000000  ... -100.000000   \n",
              "1993-04-30 -0.098939  0.098899 -0.069167 -100.000000  ... -100.000000   \n",
              "1993-03-31  0.022049  0.382571 -0.006241 -100.000000  ... -100.000000   \n",
              "1993-02-26 -0.063488 -0.071601 -0.065349 -100.000000  ... -100.000000   \n",
              "1993-01-29 -0.011813  0.053964  0.027325 -100.000000  ... -100.000000   \n",
              "\n",
              "                 GWW        WYNN       XEL         XYL         YUM      ZBRA  \\\n",
              "Date                                                                           \n",
              "2022-12-30 -0.066035    0.130925 -0.144888   -0.185104   -0.106802  0.107328   \n",
              "2022-11-30  0.046251    0.109647  0.122305    0.108028    0.119364  0.072555   \n",
              "2022-10-31 -0.079165    0.198050 -0.032700   -0.014336   -0.023149 -0.156872   \n",
              "2022-09-30  0.031974   -0.148748 -0.145207    0.009953   -0.050552 -0.081600   \n",
              "2022-08-31  0.073836    0.232588  0.054270    0.151264    0.148269  0.060936   \n",
              "...              ...         ...       ...         ...         ...       ...   \n",
              "1993-05-28 -0.024339 -100.000000  0.046571 -100.000000 -100.000000  0.130199   \n",
              "1993-04-30 -0.015399 -100.000000 -0.081487 -100.000000 -100.000000  0.152673   \n",
              "1993-03-31  0.084719 -100.000000  0.024366 -100.000000 -100.000000  0.214637   \n",
              "1993-02-26  0.046446 -100.000000 -0.037860 -100.000000 -100.000000  0.083093   \n",
              "1993-01-29 -0.068853 -100.000000  0.041163 -100.000000 -100.000000 -0.062574   \n",
              "\n",
              "                   ZBH      ZION         ZTS  \n",
              "Date                                          \n",
              "2022-12-30   -0.127030 -0.044408    0.003464  \n",
              "2022-11-30    0.185487  0.072540    0.074631  \n",
              "2022-10-31   -0.051633 -0.113493   -0.088899  \n",
              "2022-09-30   -0.078381 -0.141316   -0.145760  \n",
              "2022-08-31    0.175670  0.116541    0.139676  \n",
              "...                ...       ...         ...  \n",
              "1993-05-28 -100.000000 -0.046344 -100.000000  \n",
              "1993-04-30 -100.000000 -0.053939 -100.000000  \n",
              "1993-03-31 -100.000000 -0.068616 -100.000000  \n",
              "1993-02-26 -100.000000  0.002651 -100.000000  \n",
              "1993-01-29 -100.000000  0.035806 -100.000000  \n",
              "\n",
              "[360 rows x 500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64c98063-4fec-4651-861a-c4d4a274a2d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MMM</th>\n",
              "      <th>AOS</th>\n",
              "      <th>ABT</th>\n",
              "      <th>ABBV</th>\n",
              "      <th>ACN</th>\n",
              "      <th>ATVI</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADBE</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AAP</th>\n",
              "      <th>...</th>\n",
              "      <th>WTW</th>\n",
              "      <th>GWW</th>\n",
              "      <th>WYNN</th>\n",
              "      <th>XEL</th>\n",
              "      <th>XYL</th>\n",
              "      <th>YUM</th>\n",
              "      <th>ZBRA</th>\n",
              "      <th>ZBH</th>\n",
              "      <th>ZION</th>\n",
              "      <th>ZTS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>-0.166135</td>\n",
              "      <td>0.056965</td>\n",
              "      <td>-0.118852</td>\n",
              "      <td>-0.211537</td>\n",
              "      <td>-0.080017</td>\n",
              "      <td>-0.125514</td>\n",
              "      <td>-0.233475</td>\n",
              "      <td>-0.025308</td>\n",
              "      <td>-0.180409</td>\n",
              "      <td>-0.090068</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.086483</td>\n",
              "      <td>-0.066035</td>\n",
              "      <td>0.130925</td>\n",
              "      <td>-0.144888</td>\n",
              "      <td>-0.185104</td>\n",
              "      <td>-0.106802</td>\n",
              "      <td>0.107328</td>\n",
              "      <td>-0.127030</td>\n",
              "      <td>-0.044408</td>\n",
              "      <td>0.003464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>0.075844</td>\n",
              "      <td>0.066249</td>\n",
              "      <td>0.144415</td>\n",
              "      <td>0.126540</td>\n",
              "      <td>0.010590</td>\n",
              "      <td>0.159031</td>\n",
              "      <td>0.076179</td>\n",
              "      <td>0.099519</td>\n",
              "      <td>0.028165</td>\n",
              "      <td>0.097645</td>\n",
              "      <td>...</td>\n",
              "      <td>0.117453</td>\n",
              "      <td>0.046251</td>\n",
              "      <td>0.109647</td>\n",
              "      <td>0.122305</td>\n",
              "      <td>0.108028</td>\n",
              "      <td>0.119364</td>\n",
              "      <td>0.072555</td>\n",
              "      <td>0.185487</td>\n",
              "      <td>0.072540</td>\n",
              "      <td>0.074631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>-0.109752</td>\n",
              "      <td>-0.002384</td>\n",
              "      <td>-0.023857</td>\n",
              "      <td>-0.010227</td>\n",
              "      <td>-0.051197</td>\n",
              "      <td>-0.095386</td>\n",
              "      <td>-0.105821</td>\n",
              "      <td>-0.028200</td>\n",
              "      <td>-0.018341</td>\n",
              "      <td>-0.316164</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016905</td>\n",
              "      <td>-0.079165</td>\n",
              "      <td>0.198050</td>\n",
              "      <td>-0.032700</td>\n",
              "      <td>-0.014336</td>\n",
              "      <td>-0.023149</td>\n",
              "      <td>-0.156872</td>\n",
              "      <td>-0.051633</td>\n",
              "      <td>-0.113493</td>\n",
              "      <td>-0.088899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>-0.024180</td>\n",
              "      <td>-0.034927</td>\n",
              "      <td>-0.140021</td>\n",
              "      <td>-0.071723</td>\n",
              "      <td>-0.059170</td>\n",
              "      <td>-0.183267</td>\n",
              "      <td>0.042918</td>\n",
              "      <td>-0.005211</td>\n",
              "      <td>-0.093980</td>\n",
              "      <td>0.052237</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.076605</td>\n",
              "      <td>0.031974</td>\n",
              "      <td>-0.148748</td>\n",
              "      <td>-0.145207</td>\n",
              "      <td>0.009953</td>\n",
              "      <td>-0.050552</td>\n",
              "      <td>-0.081600</td>\n",
              "      <td>-0.078381</td>\n",
              "      <td>-0.141316</td>\n",
              "      <td>-0.145760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>0.080938</td>\n",
              "      <td>0.052902</td>\n",
              "      <td>0.134938</td>\n",
              "      <td>0.190458</td>\n",
              "      <td>0.084296</td>\n",
              "      <td>0.139444</td>\n",
              "      <td>0.107666</td>\n",
              "      <td>-0.070750</td>\n",
              "      <td>0.117771</td>\n",
              "      <td>0.119381</td>\n",
              "      <td>...</td>\n",
              "      <td>0.163840</td>\n",
              "      <td>0.073836</td>\n",
              "      <td>0.232588</td>\n",
              "      <td>0.054270</td>\n",
              "      <td>0.151264</td>\n",
              "      <td>0.148269</td>\n",
              "      <td>0.060936</td>\n",
              "      <td>0.175670</td>\n",
              "      <td>0.116541</td>\n",
              "      <td>0.139676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-05-28</th>\n",
              "      <td>-0.036279</td>\n",
              "      <td>0.014785</td>\n",
              "      <td>-0.048389</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-0.003560</td>\n",
              "      <td>-0.057483</td>\n",
              "      <td>-0.003398</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-0.024339</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>0.046571</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>0.130199</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-0.046344</td>\n",
              "      <td>-100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-04-30</th>\n",
              "      <td>-0.039332</td>\n",
              "      <td>0.144174</td>\n",
              "      <td>-0.080845</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-0.098939</td>\n",
              "      <td>0.098899</td>\n",
              "      <td>-0.069167</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-0.015399</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-0.081487</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>0.152673</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-0.053939</td>\n",
              "      <td>-100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-03-31</th>\n",
              "      <td>0.067157</td>\n",
              "      <td>-0.042842</td>\n",
              "      <td>0.133700</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>0.022049</td>\n",
              "      <td>0.382571</td>\n",
              "      <td>-0.006241</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>0.084719</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>0.024366</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>0.214637</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-0.068616</td>\n",
              "      <td>-100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-02-26</th>\n",
              "      <td>0.002728</td>\n",
              "      <td>0.068587</td>\n",
              "      <td>-0.049541</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-0.063488</td>\n",
              "      <td>-0.071601</td>\n",
              "      <td>-0.065349</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>0.046446</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-0.037860</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>0.083093</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>0.002651</td>\n",
              "      <td>-100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-01-29</th>\n",
              "      <td>0.055193</td>\n",
              "      <td>0.035141</td>\n",
              "      <td>-0.071337</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-0.011813</td>\n",
              "      <td>0.053964</td>\n",
              "      <td>0.027325</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-0.068853</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>0.041163</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-0.062574</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>0.035806</td>\n",
              "      <td>-100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>360 rows Ã— 500 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64c98063-4fec-4651-861a-c4d4a274a2d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-64c98063-4fec-4651-861a-c4d4a274a2d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-64c98063-4fec-4651-861a-c4d4a274a2d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "er_return = pd.DataFrame()\n",
        "for ticker in tqdm(SP500_ticker):\n",
        "  er_return[ticker] = SP500_final[ticker,\"excessive monthly return\"].tolist()\n",
        "\n",
        "er_return.index = SP500_final.index\n",
        "er_return[np.isnan(er_return)] = -100\n",
        "er_return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaCuWhKNzD7l"
      },
      "outputs": [],
      "source": [
        "er_return.to_csv(\"drive/My Drive/FYP Data/er_return.csv\",index=True, header=True )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "er_return = er_return[:-84]"
      ],
      "metadata": {
        "id": "3Ee9Lx8fsOWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_qB0xJZ55EH",
        "outputId": "ff93c803-6c17-492d-e9df-3594d5cd64d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(276, 126)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#get top25% data\n",
        "\n",
        "#get index of top25% excessive return stock\n",
        "er_return_index = np.argsort(-er_return.values, axis=1)[:,:126]\n",
        "\n",
        "#get name of top25% excessive return stock\n",
        "top_stock_name = []\n",
        "count = 0\n",
        "for index in er_return_index:\n",
        "  stock_list = []\n",
        "  for stock_i in index:\n",
        "    if er_return[SP500_ticker[stock_i]][count] != -100:\n",
        "      stock_list.append(SP500_ticker[stock_i])\n",
        "    else:\n",
        "      print(er_return[SP500_ticker[stock_i]][count])\n",
        "  count = count + 1\n",
        "  top_stock_name.append(stock_list)\n",
        "np.array(top_stock_name).shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get middle 25% data\n",
        "\n",
        "#get index of middle 25% excessive return stock\n",
        "er_return_index = np.argsort(-er_return.values, axis=1)[:,126:252]\n",
        "\n",
        "#get name of middle25% excessive return stock\n",
        "middle_stock_name = []\n",
        "count = 0\n",
        "for index in er_return_index:\n",
        "  stock_list = []\n",
        "  for stock_i in index:\n",
        "    if er_return[SP500_ticker[stock_i]][count] != -100:\n",
        "      stock_list.append(SP500_ticker[stock_i])\n",
        "    else:\n",
        "      print(er_return[SP500_ticker[stock_i]][count])\n",
        "  count = count + 1\n",
        "  middle_stock_name.append(stock_list)\n",
        "np.array(middle_stock_name).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpDg3z_9vJzK",
        "outputId": "f8d95be7-3a4c-48ee-b740-6a3402b1c820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(276, 126)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get top 25% data\n",
        "\n",
        "#get index of top 25% excessive return stock\n",
        "er_return_index = np.argsort(-er_return.values, axis=1)[:,252:370]\n",
        "\n",
        "#get name of top25% excessive return stock\n",
        "stock_name = []\n",
        "count = 0\n",
        "for index in er_return_index:\n",
        "  stock_list = []\n",
        "  for stock_i in index:\n",
        "    if er_return[SP500_ticker[stock_i]][count] != -100:\n",
        "      stock_list.append(SP500_ticker[stock_i])\n",
        "    else:\n",
        "      print(er_return[SP500_ticker[stock_i]][count])\n",
        "  stock_name.append(stock_list)\n",
        "  count = count + 1\n",
        "np.array(stock_name).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Pguf2cevLI2",
        "outputId": "b1bd8636-030f-4ed3-f7c7-8d5b75351a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n",
            "-100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-1491e9f095f2>:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.array(stock_name).shape\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(276,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SP500_final = SP500_final[:-84]\n",
        "SP500_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "hxFzbumKvji2",
        "outputId": "b3ff9af8-ba95-4622-9e5a-da0d127aaaa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 FOXA                                                         \\\n",
              "                 Open       High        Low      Close  Adj Close     Volume   \n",
              "Date                                                                           \n",
              "2022-12-30  30.299999  30.459999  29.920000  30.370001  30.157207  2620900.0   \n",
              "2022-11-30  31.629999  32.465000  31.250000  32.450001  32.222633  4222200.0   \n",
              "2022-10-31  28.840000  29.000000  28.469999  28.870001  28.667717  3363700.0   \n",
              "2022-09-30  30.719999  31.360001  30.549999  30.680000  30.465034  3276000.0   \n",
              "2022-08-31  34.400002  34.689999  34.160000  34.180000  33.940510  2479900.0   \n",
              "...               ...        ...        ...        ...        ...        ...   \n",
              "2000-05-31        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-04-28        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-03-31        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-02-29        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-01-31        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "\n",
              "                   ZTS                                      ...  \\\n",
              "                  Open        High         Low       Close  ...   \n",
              "Date                                                        ...   \n",
              "2022-12-30  147.199997  147.789993  144.740005  146.550003  ...   \n",
              "2022-11-30  148.089996  154.179993  146.910004  154.139999  ...   \n",
              "2022-10-31  152.110001  153.339996  149.839996  150.779999  ...   \n",
              "2022-09-30  150.419998  152.029999  148.039993  148.289993  ...   \n",
              "2022-08-31  158.160004  159.410004  156.210007  156.529999  ...   \n",
              "...                ...         ...         ...         ...  ...   \n",
              "2000-05-31         NaN         NaN         NaN         NaN  ...   \n",
              "2000-04-28         NaN         NaN         NaN         NaN  ...   \n",
              "2000-03-31         NaN         NaN         NaN         NaN  ...   \n",
              "2000-02-29         NaN         NaN         NaN         NaN  ...   \n",
              "2000-01-31         NaN         NaN         NaN         NaN  ...   \n",
              "\n",
              "                                WTW                      GWW  \\\n",
              "           excessive monthly return excessive monthly return   \n",
              "Date                                                           \n",
              "2022-12-30                -0.086483                -0.066035   \n",
              "2022-11-30                 0.117453                 0.046251   \n",
              "2022-10-31                 0.016905                -0.079165   \n",
              "2022-09-30                -0.076605                 0.031974   \n",
              "2022-08-31                 0.163840                 0.073836   \n",
              "...                             ...                      ...   \n",
              "2000-05-31                      NaN                -0.263055   \n",
              "2000-04-28                      NaN                -0.047806   \n",
              "2000-03-31                      NaN                -0.130220   \n",
              "2000-02-29                      NaN                 0.078886   \n",
              "2000-01-31                      NaN                -0.076458   \n",
              "\n",
              "                               WYNN                      XEL  \\\n",
              "           excessive monthly return excessive monthly return   \n",
              "Date                                                           \n",
              "2022-12-30                 0.130925                -0.144888   \n",
              "2022-11-30                 0.109647                 0.122305   \n",
              "2022-10-31                 0.198050                -0.032700   \n",
              "2022-09-30                -0.148748                -0.145207   \n",
              "2022-08-31                 0.232588                 0.054270   \n",
              "...                             ...                      ...   \n",
              "2000-05-31                      NaN                -0.122144   \n",
              "2000-04-28                      NaN                 0.045772   \n",
              "2000-03-31                      NaN                 0.167725   \n",
              "2000-02-29                      NaN                -0.056595   \n",
              "2000-01-31                      NaN                -0.057210   \n",
              "\n",
              "                                XYL                      YUM  \\\n",
              "           excessive monthly return excessive monthly return   \n",
              "Date                                                           \n",
              "2022-12-30                -0.185104                -0.106802   \n",
              "2022-11-30                 0.108028                 0.119364   \n",
              "2022-10-31                -0.014336                -0.023149   \n",
              "2022-09-30                 0.009953                -0.050552   \n",
              "2022-08-31                 0.151264                 0.148269   \n",
              "...                             ...                      ...   \n",
              "2000-05-31                      NaN                -0.070820   \n",
              "2000-04-28                      NaN                -0.103241   \n",
              "2000-03-31                      NaN                 0.160784   \n",
              "2000-02-29                      NaN                -0.021601   \n",
              "2000-01-31                      NaN                -0.039417   \n",
              "\n",
              "                               ZBRA                      ZBH  \\\n",
              "           excessive monthly return excessive monthly return   \n",
              "Date                                                           \n",
              "2022-12-30                 0.107328                -0.127030   \n",
              "2022-11-30                 0.072555                 0.185487   \n",
              "2022-10-31                -0.156872                -0.051633   \n",
              "2022-09-30                -0.081600                -0.078381   \n",
              "2022-08-31                 0.060936                 0.175670   \n",
              "...                             ...                      ...   \n",
              "2000-05-31                -0.111396                      NaN   \n",
              "2000-04-28                -0.126450                      NaN   \n",
              "2000-03-31                 0.210241                      NaN   \n",
              "2000-02-29                -0.437094                      NaN   \n",
              "2000-01-31                 0.155056                      NaN   \n",
              "\n",
              "                               ZION                      ZTS  \n",
              "           excessive monthly return excessive monthly return  \n",
              "Date                                                          \n",
              "2022-12-30                -0.044408                 0.003464  \n",
              "2022-11-30                 0.072540                 0.074631  \n",
              "2022-10-31                -0.113493                -0.088899  \n",
              "2022-09-30                -0.141316                -0.145760  \n",
              "2022-08-31                 0.116541                 0.139676  \n",
              "...                             ...                      ...  \n",
              "2000-05-31                -0.050324                      NaN  \n",
              "2000-04-28                 0.154939                      NaN  \n",
              "2000-03-31                 0.067238                      NaN  \n",
              "2000-02-29                -0.403815                      NaN  \n",
              "2000-01-31                -0.072085                      NaN  \n",
              "\n",
              "[276 rows x 7505 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4e0e094-c805-4784-97b7-eeea29e0dc1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">FOXA</th>\n",
              "      <th colspan=\"4\" halign=\"left\">ZTS</th>\n",
              "      <th>...</th>\n",
              "      <th>WTW</th>\n",
              "      <th>GWW</th>\n",
              "      <th>WYNN</th>\n",
              "      <th>XEL</th>\n",
              "      <th>XYL</th>\n",
              "      <th>YUM</th>\n",
              "      <th>ZBRA</th>\n",
              "      <th>ZBH</th>\n",
              "      <th>ZION</th>\n",
              "      <th>ZTS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>...</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "      <th>excessive monthly return</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>30.299999</td>\n",
              "      <td>30.459999</td>\n",
              "      <td>29.920000</td>\n",
              "      <td>30.370001</td>\n",
              "      <td>30.157207</td>\n",
              "      <td>2620900.0</td>\n",
              "      <td>147.199997</td>\n",
              "      <td>147.789993</td>\n",
              "      <td>144.740005</td>\n",
              "      <td>146.550003</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.086483</td>\n",
              "      <td>-0.066035</td>\n",
              "      <td>0.130925</td>\n",
              "      <td>-0.144888</td>\n",
              "      <td>-0.185104</td>\n",
              "      <td>-0.106802</td>\n",
              "      <td>0.107328</td>\n",
              "      <td>-0.127030</td>\n",
              "      <td>-0.044408</td>\n",
              "      <td>0.003464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>31.629999</td>\n",
              "      <td>32.465000</td>\n",
              "      <td>31.250000</td>\n",
              "      <td>32.450001</td>\n",
              "      <td>32.222633</td>\n",
              "      <td>4222200.0</td>\n",
              "      <td>148.089996</td>\n",
              "      <td>154.179993</td>\n",
              "      <td>146.910004</td>\n",
              "      <td>154.139999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.117453</td>\n",
              "      <td>0.046251</td>\n",
              "      <td>0.109647</td>\n",
              "      <td>0.122305</td>\n",
              "      <td>0.108028</td>\n",
              "      <td>0.119364</td>\n",
              "      <td>0.072555</td>\n",
              "      <td>0.185487</td>\n",
              "      <td>0.072540</td>\n",
              "      <td>0.074631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>28.840000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>28.469999</td>\n",
              "      <td>28.870001</td>\n",
              "      <td>28.667717</td>\n",
              "      <td>3363700.0</td>\n",
              "      <td>152.110001</td>\n",
              "      <td>153.339996</td>\n",
              "      <td>149.839996</td>\n",
              "      <td>150.779999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016905</td>\n",
              "      <td>-0.079165</td>\n",
              "      <td>0.198050</td>\n",
              "      <td>-0.032700</td>\n",
              "      <td>-0.014336</td>\n",
              "      <td>-0.023149</td>\n",
              "      <td>-0.156872</td>\n",
              "      <td>-0.051633</td>\n",
              "      <td>-0.113493</td>\n",
              "      <td>-0.088899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>30.719999</td>\n",
              "      <td>31.360001</td>\n",
              "      <td>30.549999</td>\n",
              "      <td>30.680000</td>\n",
              "      <td>30.465034</td>\n",
              "      <td>3276000.0</td>\n",
              "      <td>150.419998</td>\n",
              "      <td>152.029999</td>\n",
              "      <td>148.039993</td>\n",
              "      <td>148.289993</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.076605</td>\n",
              "      <td>0.031974</td>\n",
              "      <td>-0.148748</td>\n",
              "      <td>-0.145207</td>\n",
              "      <td>0.009953</td>\n",
              "      <td>-0.050552</td>\n",
              "      <td>-0.081600</td>\n",
              "      <td>-0.078381</td>\n",
              "      <td>-0.141316</td>\n",
              "      <td>-0.145760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>34.400002</td>\n",
              "      <td>34.689999</td>\n",
              "      <td>34.160000</td>\n",
              "      <td>34.180000</td>\n",
              "      <td>33.940510</td>\n",
              "      <td>2479900.0</td>\n",
              "      <td>158.160004</td>\n",
              "      <td>159.410004</td>\n",
              "      <td>156.210007</td>\n",
              "      <td>156.529999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.163840</td>\n",
              "      <td>0.073836</td>\n",
              "      <td>0.232588</td>\n",
              "      <td>0.054270</td>\n",
              "      <td>0.151264</td>\n",
              "      <td>0.148269</td>\n",
              "      <td>0.060936</td>\n",
              "      <td>0.175670</td>\n",
              "      <td>0.116541</td>\n",
              "      <td>0.139676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-05-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.263055</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.122144</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.070820</td>\n",
              "      <td>-0.111396</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.050324</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-04-28</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.047806</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.045772</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.103241</td>\n",
              "      <td>-0.126450</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.154939</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.130220</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.167725</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.160784</td>\n",
              "      <td>0.210241</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.067238</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-29</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.078886</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.056595</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.021601</td>\n",
              "      <td>-0.437094</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.403815</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.076458</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.057210</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.039417</td>\n",
              "      <td>0.155056</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.072085</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>276 rows Ã— 7505 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4e0e094-c805-4784-97b7-eeea29e0dc1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4e0e094-c805-4784-97b7-eeea29e0dc1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4e0e094-c805-4784-97b7-eeea29e0dc1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "867a567209184bf8a7aac60c39f836cf",
            "2e87c17598c245ec8707cad59cf8cdad",
            "2820dedc911f41ff876795807a4df66a",
            "ae8efcbb8fa444acbf9e05336909ff02",
            "3fae791a12044b87a2fc79d576fa4d43",
            "7e5fbdb5ef03439ba2f576a5fa88430b",
            "4d2d0a955cd7419586e17c246b418f96",
            "bc53ad5c84ec41fba30b6cc5b016ae73",
            "89d02ba505b649d1a70d81c547bc6356",
            "50f0dc003d66484898ac232d79efb105",
            "3e13da0773154c6b94ec006842bf5ce9",
            "80ef02b5b2e349528bf54c67094be30c",
            "98e08d0ba04f46c481f02db75868d286",
            "59f5b0291fec4e5cb717f449b49da0a8",
            "90f94970061448baa4fbcd4c04229a72",
            "6442a9e5e127479b9bc863db54a007cc",
            "de8f5e6092be445e8544cdec2ec26717",
            "0a4d85eb46d84a4db9496d5f7420a419",
            "d4a1141c3091474b9a51d04ad1905293",
            "c9eb5fecc6004552a1ebe5d32414607f",
            "6f1c7164ba6545d3bebec129c3d45745",
            "e8557f46463f4fefb68ebf56f141fc97"
          ]
        },
        "id": "ccJ8kGDC7Vsq",
        "outputId": "a607b647-0bfb-4788-fa1a-1a16545c4e1e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "867a567209184bf8a7aac60c39f836cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-3f25661853a4>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  SP500_final[ticker, 'label'] = label\n",
            "<ipython-input-19-3f25661853a4>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  SP500_final[ticker, 'label'] = label\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80ef02b5b2e349528bf54c67094be30c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
            "<ipython-input-19-3f25661853a4>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            MMM  AOS  ABT  ABBV  ACN  ATVI  ADM  ADBE  ADP  AAP  ...  WTW  \\\n",
              "Date                                                             ...        \n",
              "2022-12-30    0    3    0     0    1     0    0     2    0    1  ...    1   \n",
              "2022-11-30    1    1    3     3    0     3    1     2    0    2  ...    3   \n",
              "2022-10-31    0    3    2     2    1     0    0     2    2    0  ...    3   \n",
              "2022-09-30    2    2    0     1    2     0    3     2    1    3  ...    1   \n",
              "2022-08-31    1    0    3     3    1     3    2     0    2    2  ...    3   \n",
              "...         ...  ...  ...   ...  ...   ...  ...   ...  ...  ...  ...  ...   \n",
              "2000-05-31    2    2    3     0    0     3    1     3    2    0  ...    0   \n",
              "2000-04-28    2    2    3     0    0     2    3     1    2    0  ...    0   \n",
              "2000-03-31    2    3    3     0    0     1    1     3    3    0  ...    0   \n",
              "2000-02-29    1    2    2     0    0     1    1     2    2    0  ...    0   \n",
              "2000-01-31    2    1    3     0    0     1    1     3    2    0  ...    0   \n",
              "\n",
              "            GWW  WYNN  XEL  XYL  YUM  ZBRA  ZBH  ZION  ZTS  \n",
              "Date                                                        \n",
              "2022-12-30    1     3    0    0    1     3    0     2    3  \n",
              "2022-11-30    0     3    3    2    3     1    3     1    1  \n",
              "2022-10-31    1     3    2    2    2     0    1     0    0  \n",
              "2022-09-30    3     0    0    3    2     1    1     0    0  \n",
              "2022-08-31    1     3    0    3    3     0    3     2    3  \n",
              "...         ...   ...  ...  ...  ...   ...  ...   ...  ...  \n",
              "2000-05-31    1     0    1    0    2     1    0     2    0  \n",
              "2000-04-28    1     0    2    0    1     1    0     3    0  \n",
              "2000-03-31    1     0    3    0    3     3    0     2    0  \n",
              "2000-02-29    3     0    2    0    3     1    0     1    0  \n",
              "2000-01-31    2     0    2    0    2     3    0     2    0  \n",
              "\n",
              "[276 rows x 500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-182a2497-3d27-4961-98b5-41c86179f775\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MMM</th>\n",
              "      <th>AOS</th>\n",
              "      <th>ABT</th>\n",
              "      <th>ABBV</th>\n",
              "      <th>ACN</th>\n",
              "      <th>ATVI</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADBE</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AAP</th>\n",
              "      <th>...</th>\n",
              "      <th>WTW</th>\n",
              "      <th>GWW</th>\n",
              "      <th>WYNN</th>\n",
              "      <th>XEL</th>\n",
              "      <th>XYL</th>\n",
              "      <th>YUM</th>\n",
              "      <th>ZBRA</th>\n",
              "      <th>ZBH</th>\n",
              "      <th>ZION</th>\n",
              "      <th>ZTS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-05-31</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-04-28</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-31</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-29</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-31</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>276 rows Ã— 500 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-182a2497-3d27-4961-98b5-41c86179f775')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-182a2497-3d27-4961-98b5-41c86179f775 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-182a2497-3d27-4961-98b5-41c86179f775');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#add label\n",
        "for ticker in tqdm(SP500_ticker):\n",
        "  label = []\n",
        "  for i in range(0,276):\n",
        "    if ticker in top_stock_name[i]:\n",
        "      label.append(3)\n",
        "    elif ticker in middle_stock_name[i]:\n",
        "      label.append(2)\n",
        "    elif ticker in stock_name[i]:\n",
        "      label.append(1)\n",
        "    else:\n",
        "      label.append(0)\n",
        "  SP500_final[ticker, 'label'] = label\n",
        "\n",
        "#get the label\n",
        "label_df = pd.DataFrame()\n",
        "for ticker in tqdm(SP500_ticker):\n",
        "  label_df[ticker] = SP500_final[ticker,\"label\"].tolist()\n",
        "label_df.index = SP500_final.index\n",
        "label_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7W8hfLkwu72"
      },
      "outputs": [],
      "source": [
        "label_df.to_csv(\"drive/My Drive/FYP Data/Long_label_1234.csv\",index=True, header=True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7aL6rTwujJB"
      },
      "source": [
        "# LSTM with Technical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "tAUcewXi9eqv",
        "outputId": "1665f859-04a9-401b-dd0e-e1acfbc09005"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            MMM  AOS  ABT  ABBV  ACN  ATVI  ADM  ADBE  ADP  AAP  ...  WTW  \\\n",
              "Date                                                             ...        \n",
              "2000-01-31    2    1    3     0    0     1    1     3    2    0  ...    0   \n",
              "2000-02-29    1    2    2     0    0     1    1     2    2    0  ...    0   \n",
              "2000-03-31    2    3    3     0    0     1    1     3    3    0  ...    0   \n",
              "2000-04-28    2    2    3     0    0     2    3     1    2    0  ...    0   \n",
              "2000-05-31    2    2    3     0    0     3    1     3    2    0  ...    0   \n",
              "...         ...  ...  ...   ...  ...   ...  ...   ...  ...  ...  ...  ...   \n",
              "2022-08-31    1    0    3     3    1     3    2     0    2    2  ...    3   \n",
              "2022-09-30    2    2    0     1    2     0    3     2    1    3  ...    1   \n",
              "2022-10-31    0    3    2     2    1     0    0     2    2    0  ...    3   \n",
              "2022-11-30    1    1    3     3    0     3    1     2    0    2  ...    3   \n",
              "2022-12-30    0    3    0     0    1     0    0     2    0    1  ...    1   \n",
              "\n",
              "            GWW  WYNN  XEL  XYL  YUM  ZBRA  ZBH  ZION  ZTS  \n",
              "Date                                                        \n",
              "2000-01-31    2     0    2    0    2     3    0     2    0  \n",
              "2000-02-29    3     0    2    0    3     1    0     1    0  \n",
              "2000-03-31    1     0    3    0    3     3    0     2    0  \n",
              "2000-04-28    1     0    2    0    1     1    0     3    0  \n",
              "2000-05-31    1     0    1    0    2     1    0     2    0  \n",
              "...         ...   ...  ...  ...  ...   ...  ...   ...  ...  \n",
              "2022-08-31    1     3    0    3    3     0    3     2    3  \n",
              "2022-09-30    3     0    0    3    2     1    1     0    0  \n",
              "2022-10-31    1     3    2    2    2     0    1     0    0  \n",
              "2022-11-30    0     3    3    2    3     1    3     1    1  \n",
              "2022-12-30    1     3    0    0    1     3    0     2    3  \n",
              "\n",
              "[276 rows x 500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f18dbf31-8e88-459f-aa64-03f69aba8b4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MMM</th>\n",
              "      <th>AOS</th>\n",
              "      <th>ABT</th>\n",
              "      <th>ABBV</th>\n",
              "      <th>ACN</th>\n",
              "      <th>ATVI</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADBE</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AAP</th>\n",
              "      <th>...</th>\n",
              "      <th>WTW</th>\n",
              "      <th>GWW</th>\n",
              "      <th>WYNN</th>\n",
              "      <th>XEL</th>\n",
              "      <th>XYL</th>\n",
              "      <th>YUM</th>\n",
              "      <th>ZBRA</th>\n",
              "      <th>ZBH</th>\n",
              "      <th>ZION</th>\n",
              "      <th>ZTS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-31</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-29</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-31</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-04-28</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-05-31</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>276 rows Ã— 500 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f18dbf31-8e88-459f-aa64-03f69aba8b4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f18dbf31-8e88-459f-aa64-03f69aba8b4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f18dbf31-8e88-459f-aa64-03f69aba8b4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "label_df = pd.read_csv(\"drive/My Drive/FYP Data/Long_label_1234.csv\",index_col = 0)\n",
        "label_df = label_df.reindex(index=label_df.index[::-1])\n",
        "label_df.reset_index()\n",
        "label_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "id": "3D267neZytA8",
        "outputId": "cb2451b5-8c6e-4747-e62b-bb59ab0a8c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-5f3361fcc5b5>:5: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  multi_factor = multi_factor.drop(columns = ['year', 'month','if_last_date','date'], axis=1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 FOXA                                                         \\\n",
              "                 Open       High        Low      Close  Adj Close     Volume   \n",
              "Date                                                                           \n",
              "2000-01-31        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-02-29        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-03-31        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-04-28        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-05-31        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "...               ...        ...        ...        ...        ...        ...   \n",
              "2022-08-31  34.400002  34.689999  34.160000  34.180000  33.940510  2479900.0   \n",
              "2022-09-30  30.719999  31.360001  30.549999  30.680000  30.465034  3276000.0   \n",
              "2022-10-31  28.840000  29.000000  28.469999  28.870001  28.667717  3363700.0   \n",
              "2022-11-30  31.629999  32.465000  31.250000  32.450001  32.222633  4222200.0   \n",
              "2022-12-30  30.299999  30.459999  29.920000  30.370001  30.157207  2620900.0   \n",
              "\n",
              "                   ZTS                                      ...   WTW   GWW  \\\n",
              "                  Open        High         Low       Close  ...    AD    AD   \n",
              "Date                                                        ...               \n",
              "2000-01-31         NaN         NaN         NaN         NaN  ...  1.00  0.44   \n",
              "2000-02-29         NaN         NaN         NaN         NaN  ...  1.00  1.00   \n",
              "2000-03-31         NaN         NaN         NaN         NaN  ...  1.00  0.40   \n",
              "2000-04-28         NaN         NaN         NaN         NaN  ...  1.00  0.88   \n",
              "2000-05-31         NaN         NaN         NaN         NaN  ...  1.00  1.00   \n",
              "...                ...         ...         ...         ...  ...   ...   ...   \n",
              "2022-08-31  158.160004  159.410004  156.210007  156.529999  ...  0.08  0.04   \n",
              "2022-09-30  150.419998  152.029999  148.039993  148.289993  ...  0.84  0.92   \n",
              "2022-10-31  152.110001  153.339996  149.839996  150.779999  ...  0.56  0.08   \n",
              "2022-11-30  148.089996  154.179993  146.910004  154.139999  ...  0.12  0.04   \n",
              "2022-12-30  147.199997  147.789993  144.740005  146.550003  ...  0.20  0.68   \n",
              "\n",
              "            WYNN   XEL   XYL   YUM  ZBRA   ZBH  ZION   ZTS  \n",
              "              AD    AD    AD    AD    AD    AD    AD    AD  \n",
              "Date                                                        \n",
              "2000-01-31  1.00  0.28  1.00  1.00  0.32  1.00  0.56  1.00  \n",
              "2000-02-29  1.00  0.96  1.00  1.00  0.84  1.00  0.84  1.00  \n",
              "2000-03-31  1.00  0.40  1.00  0.08  0.64  1.00  0.24  1.00  \n",
              "2000-04-28  1.00  0.08  1.00  0.04  0.36  1.00  0.24  1.00  \n",
              "2000-05-31  1.00  0.04  1.00  1.00  0.88  1.00  0.48  1.00  \n",
              "...          ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "2022-08-31  1.00  0.04  0.04  1.00  1.00  0.96  0.04  1.00  \n",
              "2022-09-30  0.32  1.00  0.92  0.96  1.00  0.88  1.00  0.92  \n",
              "2022-10-31  0.84  0.56  0.56  0.56  0.48  0.80  0.80  0.56  \n",
              "2022-11-30  0.16  0.04  0.04  0.04  0.36  0.36  0.32  0.32  \n",
              "2022-12-30  0.08  0.16  0.84  0.04  0.84  0.04  0.72  0.76  \n",
              "\n",
              "[276 rows x 6500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce93ce00-5bca-4d88-9ca1-9c574a74bb7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">FOXA</th>\n",
              "      <th colspan=\"4\" halign=\"left\">ZTS</th>\n",
              "      <th>...</th>\n",
              "      <th>WTW</th>\n",
              "      <th>GWW</th>\n",
              "      <th>WYNN</th>\n",
              "      <th>XEL</th>\n",
              "      <th>XYL</th>\n",
              "      <th>YUM</th>\n",
              "      <th>ZBRA</th>\n",
              "      <th>ZBH</th>\n",
              "      <th>ZION</th>\n",
              "      <th>ZTS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>...</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.44</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.28</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-29</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.84</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.84</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-04-28</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.88</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.36</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-05-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.88</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.48</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>34.400002</td>\n",
              "      <td>34.689999</td>\n",
              "      <td>34.160000</td>\n",
              "      <td>34.180000</td>\n",
              "      <td>33.940510</td>\n",
              "      <td>2479900.0</td>\n",
              "      <td>158.160004</td>\n",
              "      <td>159.410004</td>\n",
              "      <td>156.210007</td>\n",
              "      <td>156.529999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.04</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>30.719999</td>\n",
              "      <td>31.360001</td>\n",
              "      <td>30.549999</td>\n",
              "      <td>30.680000</td>\n",
              "      <td>30.465034</td>\n",
              "      <td>3276000.0</td>\n",
              "      <td>150.419998</td>\n",
              "      <td>152.029999</td>\n",
              "      <td>148.039993</td>\n",
              "      <td>148.289993</td>\n",
              "      <td>...</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.96</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.88</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>28.840000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>28.469999</td>\n",
              "      <td>28.870001</td>\n",
              "      <td>28.667717</td>\n",
              "      <td>3363700.0</td>\n",
              "      <td>152.110001</td>\n",
              "      <td>153.339996</td>\n",
              "      <td>149.839996</td>\n",
              "      <td>150.779999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>31.629999</td>\n",
              "      <td>32.465000</td>\n",
              "      <td>31.250000</td>\n",
              "      <td>32.450001</td>\n",
              "      <td>32.222633</td>\n",
              "      <td>4222200.0</td>\n",
              "      <td>148.089996</td>\n",
              "      <td>154.179993</td>\n",
              "      <td>146.910004</td>\n",
              "      <td>154.139999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>30.299999</td>\n",
              "      <td>30.459999</td>\n",
              "      <td>29.920000</td>\n",
              "      <td>30.370001</td>\n",
              "      <td>30.157207</td>\n",
              "      <td>2620900.0</td>\n",
              "      <td>147.199997</td>\n",
              "      <td>147.789993</td>\n",
              "      <td>144.740005</td>\n",
              "      <td>146.550003</td>\n",
              "      <td>...</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>276 rows Ã— 6500 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce93ce00-5bca-4d88-9ca1-9c574a74bb7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce93ce00-5bca-4d88-9ca1-9c574a74bb7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce93ce00-5bca-4d88-9ca1-9c574a74bb7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "multi_factor = pd.read_csv(\"drive/My Drive/FYP Data/stock data month.csv\",index_col = 0,header = [0,1])\n",
        "multi_factor = multi_factor.reindex(index=multi_factor.index[::-1])\n",
        "multi_factor.reset_index()\n",
        "multi_factor = multi_factor.drop(index='2023-01-31')\n",
        "multi_factor = multi_factor.drop(columns = ['year', 'month','if_last_date','date'], axis=1)\n",
        "multi_factor = multi_factor[84:]\n",
        "multi_factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRDuXCOTicwA",
        "outputId": "c705a76d-e182-4af5-8c18-43ea3c046ae8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['2000-01-31', '2000-02-29', '2000-03-31', '2000-04-28',\n",
              "       '2000-05-31', '2000-06-30', '2000-07-31', '2000-08-31',\n",
              "       '2000-09-29', '2000-10-31', '2000-11-30', '2000-12-29',\n",
              "       '2001-01-31', '2001-02-28', '2001-03-30', '2001-04-30',\n",
              "       '2001-05-31', '2001-06-29', '2001-07-31', '2001-08-31',\n",
              "       '2001-09-28', '2001-10-31', '2001-11-30', '2001-12-31',\n",
              "       '2002-01-31', '2002-02-28', '2002-03-28', '2002-04-30',\n",
              "       '2002-05-31', '2002-06-28', '2002-07-31', '2002-08-30',\n",
              "       '2002-09-30', '2002-10-31', '2002-11-29', '2002-12-31',\n",
              "       '2003-01-31', '2003-02-28', '2003-03-31', '2003-04-30',\n",
              "       '2003-05-30', '2003-06-30', '2003-07-31', '2003-08-29',\n",
              "       '2003-09-30', '2003-10-31', '2003-11-28', '2003-12-31',\n",
              "       '2004-01-30', '2004-02-27', '2004-03-31', '2004-04-30',\n",
              "       '2004-05-28', '2004-06-30', '2004-07-30', '2004-08-31',\n",
              "       '2004-09-30', '2004-10-29', '2004-11-30', '2004-12-31',\n",
              "       '2005-01-31', '2005-02-28', '2005-03-31', '2005-04-29',\n",
              "       '2005-05-31', '2005-06-30', '2005-07-29', '2005-08-31',\n",
              "       '2005-09-30', '2005-10-31', '2005-11-30', '2005-12-30',\n",
              "       '2006-01-31', '2006-02-28', '2006-03-31', '2006-04-28',\n",
              "       '2006-05-31', '2006-06-30', '2006-07-31', '2006-08-31',\n",
              "       '2006-09-29', '2006-10-31', '2006-11-30', '2006-12-29',\n",
              "       '2007-01-31', '2007-02-28', '2007-03-30', '2007-04-30',\n",
              "       '2007-05-31', '2007-06-29', '2007-07-31', '2007-08-31',\n",
              "       '2007-09-28', '2007-10-31', '2007-11-30', '2007-12-31',\n",
              "       '2008-01-31', '2008-02-29', '2008-03-31', '2008-04-30',\n",
              "       '2008-05-30', '2008-06-30', '2008-07-31', '2008-08-29',\n",
              "       '2008-09-30', '2008-10-31', '2008-11-28', '2008-12-31',\n",
              "       '2009-01-30', '2009-02-27', '2009-03-31', '2009-04-30',\n",
              "       '2009-05-29', '2009-06-30', '2009-07-31', '2009-08-31',\n",
              "       '2009-09-30', '2009-10-30', '2009-11-30', '2009-12-31',\n",
              "       '2010-01-29', '2010-02-26', '2010-03-31', '2010-04-30',\n",
              "       '2010-05-28', '2010-06-30', '2010-07-30', '2010-08-31',\n",
              "       '2010-09-30', '2010-10-29', '2010-11-30', '2010-12-31',\n",
              "       '2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',\n",
              "       '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',\n",
              "       '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30',\n",
              "       '2012-01-31', '2012-02-29', '2012-03-30', '2012-04-30',\n",
              "       '2012-05-31', '2012-06-29', '2012-07-31', '2012-08-31',\n",
              "       '2012-09-28', '2012-10-31', '2012-11-30', '2012-12-31',\n",
              "       '2013-01-31', '2013-02-28', '2013-03-28', '2013-04-30',\n",
              "       '2013-05-31', '2013-06-28', '2013-07-31', '2013-08-30',\n",
              "       '2013-09-30', '2013-10-31', '2013-11-29', '2013-12-31',\n",
              "       '2014-01-31', '2014-02-28', '2014-03-31', '2014-04-30',\n",
              "       '2014-05-30', '2014-06-30', '2014-07-31', '2014-08-29',\n",
              "       '2014-09-30', '2014-10-31', '2014-11-28', '2014-12-31',\n",
              "       '2015-01-30', '2015-02-27', '2015-03-31', '2015-04-30',\n",
              "       '2015-05-29', '2015-06-30', '2015-07-31', '2015-08-31',\n",
              "       '2015-09-30', '2015-10-30', '2015-11-30', '2015-12-31',\n",
              "       '2016-01-29', '2016-02-29', '2016-03-31', '2016-04-29',\n",
              "       '2016-05-31', '2016-06-30', '2016-07-29', '2016-08-31',\n",
              "       '2016-09-30', '2016-10-31', '2016-11-30', '2016-12-30',\n",
              "       '2017-01-31', '2017-02-28', '2017-03-31', '2017-04-28',\n",
              "       '2017-05-31', '2017-06-30', '2017-07-31', '2017-08-31',\n",
              "       '2017-09-29', '2017-10-31', '2017-11-30', '2017-12-29',\n",
              "       '2018-01-31', '2018-02-28', '2018-03-29', '2018-04-30',\n",
              "       '2018-05-31', '2018-06-29', '2018-07-31', '2018-08-31',\n",
              "       '2018-09-28', '2018-10-31', '2018-11-30', '2018-12-31',\n",
              "       '2019-01-31', '2019-02-28', '2019-03-29', '2019-04-30',\n",
              "       '2019-05-31', '2019-06-28', '2019-07-31', '2019-08-30',\n",
              "       '2019-09-30', '2019-10-31', '2019-11-29', '2019-12-31',\n",
              "       '2020-01-31', '2020-02-28', '2020-03-31', '2020-04-30',\n",
              "       '2020-05-29', '2020-06-30', '2020-07-31', '2020-08-31',\n",
              "       '2020-09-30', '2020-10-30', '2020-11-30', '2020-12-31',\n",
              "       '2021-01-29', '2021-02-26', '2021-03-31', '2021-04-30',\n",
              "       '2021-05-28', '2021-06-30', '2021-07-30', '2021-08-31',\n",
              "       '2021-09-30', '2021-10-29', '2021-11-30', '2021-12-31',\n",
              "       '2022-01-31', '2022-02-28', '2022-03-31', '2022-04-29',\n",
              "       '2022-05-31', '2022-06-30', '2022-07-29', '2022-08-31',\n",
              "       '2022-09-30', '2022-10-31', '2022-11-30', '2022-12-30'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "multi_factor[np.isnan(multi_factor)] = 0\n",
        "#get time list\n",
        "time = multi_factor.index.values\n",
        "time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oAGxI_69t0m",
        "outputId": "f2ce081c-64f5-42a8-adf7-3ccb40d9908f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape == (276, 6500)\n",
            "All timestamps == 276\n",
            "Featured selected: [('FOXA', 'Open'), ('FOXA', 'High'), ('FOXA', 'Low'), ('FOXA', 'Close'), ('FOXA', 'Adj Close'), ('FOXA', 'Volume'), ('ZTS', 'Open'), ('ZTS', 'High'), ('ZTS', 'Low'), ('ZTS', 'Close'), ('ZTS', 'Adj Close'), ('ZTS', 'Volume'), ('AMCR', 'Open'), ('AMCR', 'High'), ('AMCR', 'Low'), ('AMCR', 'Close'), ('AMCR', 'Adj Close'), ('AMCR', 'Volume'), ('GRMN', 'Open'), ('GRMN', 'High'), ('GRMN', 'Low'), ('GRMN', 'Close'), ('GRMN', 'Adj Close'), ('GRMN', 'Volume'), ('AMT', 'Open'), ('AMT', 'High'), ('AMT', 'Low'), ('AMT', 'Close'), ('AMT', 'Adj Close'), ('AMT', 'Volume'), ('GPN', 'Open'), ('GPN', 'High'), ('GPN', 'Low'), ('GPN', 'Close'), ('GPN', 'Adj Close'), ('GPN', 'Volume'), ('ROP', 'Open'), ('ROP', 'High'), ('ROP', 'Low'), ('ROP', 'Close'), ('ROP', 'Adj Close'), ('ROP', 'Volume'), ('AFL', 'Open'), ('AFL', 'High'), ('AFL', 'Low'), ('AFL', 'Close'), ('AFL', 'Adj Close'), ('AFL', 'Volume'), ('CNC', 'Open'), ('CNC', 'High'), ('CNC', 'Low'), ('CNC', 'Close'), ('CNC', 'Adj Close'), ('CNC', 'Volume'), ('XEL', 'Open'), ('XEL', 'High'), ('XEL', 'Low'), ('XEL', 'Close'), ('XEL', 'Adj Close'), ('XEL', 'Volume'), ('CHTR', 'Open'), ('CHTR', 'High'), ('CHTR', 'Low'), ('CHTR', 'Close'), ('CHTR', 'Adj Close'), ('CHTR', 'Volume'), ('LHX', 'Open'), ('LHX', 'High'), ('LHX', 'Low'), ('LHX', 'Close'), ('LHX', 'Adj Close'), ('LHX', 'Volume'), ('SYF', 'Open'), ('SYF', 'High'), ('SYF', 'Low'), ('SYF', 'Close'), ('SYF', 'Adj Close'), ('SYF', 'Volume'), ('PPL', 'Open'), ('PPL', 'High'), ('PPL', 'Low'), ('PPL', 'Close'), ('PPL', 'Adj Close'), ('PPL', 'Volume'), ('WMT', 'Open'), ('WMT', 'High'), ('WMT', 'Low'), ('WMT', 'Close'), ('WMT', 'Adj Close'), ('WMT', 'Volume'), ('ARE', 'Open'), ('ARE', 'High'), ('ARE', 'Low'), ('ARE', 'Close'), ('ARE', 'Adj Close'), ('ARE', 'Volume'), ('HLT', 'Open'), ('HLT', 'High'), ('HLT', 'Low'), ('HLT', 'Close'), ('HLT', 'Adj Close'), ('HLT', 'Volume'), ('HCA', 'Open'), ('HCA', 'High'), ('HCA', 'Low'), ('HCA', 'Close'), ('HCA', 'Adj Close'), ('HCA', 'Volume'), ('HES', 'Open'), ('HES', 'High'), ('HES', 'Low'), ('HES', 'Close'), ('HES', 'Adj Close'), ('HES', 'Volume'), ('PPG', 'Open'), ('PPG', 'High'), ('PPG', 'Low'), ('PPG', 'Close'), ('PPG', 'Adj Close'), ('PPG', 'Volume'), ('HII', 'Open'), ('HII', 'High'), ('HII', 'Low'), ('HII', 'Close'), ('HII', 'Adj Close'), ('HII', 'Volume'), ('CPB', 'Open'), ('CPB', 'High'), ('CPB', 'Low'), ('CPB', 'Close'), ('CPB', 'Adj Close'), ('CPB', 'Volume'), ('L', 'Open'), ('L', 'High'), ('L', 'Low'), ('L', 'Close'), ('L', 'Adj Close'), ('L', 'Volume'), ('AEE', 'Open'), ('AEE', 'High'), ('AEE', 'Low'), ('AEE', 'Close'), ('AEE', 'Adj Close'), ('AEE', 'Volume'), ('DAL', 'Open'), ('DAL', 'High'), ('DAL', 'Low'), ('DAL', 'Close'), ('DAL', 'Adj Close'), ('DAL', 'Volume'), ('T', 'Open'), ('T', 'High'), ('T', 'Low'), ('T', 'Close'), ('T', 'Adj Close'), ('T', 'Volume'), ('NDAQ', 'Open'), ('NDAQ', 'High'), ('NDAQ', 'Low'), ('NDAQ', 'Close'), ('NDAQ', 'Adj Close'), ('NDAQ', 'Volume'), ('MO', 'Open'), ('MO', 'High'), ('MO', 'Low'), ('MO', 'Close'), ('MO', 'Adj Close'), ('MO', 'Volume'), ('SNA', 'Open'), ('SNA', 'High'), ('SNA', 'Low'), ('SNA', 'Close'), ('SNA', 'Adj Close'), ('SNA', 'Volume'), ('PEAK', 'Open'), ('PEAK', 'High'), ('PEAK', 'Low'), ('PEAK', 'Close'), ('PEAK', 'Adj Close'), ('PEAK', 'Volume'), ('MSCI', 'Open'), ('MSCI', 'High'), ('MSCI', 'Low'), ('MSCI', 'Close'), ('MSCI', 'Adj Close'), ('MSCI', 'Volume'), ('TFX', 'Open'), ('TFX', 'High'), ('TFX', 'Low'), ('TFX', 'Close'), ('TFX', 'Adj Close'), ('TFX', 'Volume'), ('MKC', 'Open'), ('MKC', 'High'), ('MKC', 'Low'), ('MKC', 'Close'), ('MKC', 'Adj Close'), ('MKC', 'Volume'), ('GILD', 'Open'), ('GILD', 'High'), ('GILD', 'Low'), ('GILD', 'Close'), ('GILD', 'Adj Close'), ('GILD', 'Volume'), ('CVS', 'Open'), ('CVS', 'High'), ('CVS', 'Low'), ('CVS', 'Close'), ('CVS', 'Adj Close'), ('CVS', 'Volume'), ('HPQ', 'Open'), ('HPQ', 'High'), ('HPQ', 'Low'), ('HPQ', 'Close'), ('HPQ', 'Adj Close'), ('HPQ', 'Volume'), ('BXP', 'Open'), ('BXP', 'High'), ('BXP', 'Low'), ('BXP', 'Close'), ('BXP', 'Adj Close'), ('BXP', 'Volume'), ('MSFT', 'Open'), ('MSFT', 'High'), ('MSFT', 'Low'), ('MSFT', 'Close'), ('MSFT', 'Adj Close'), ('MSFT', 'Volume'), ('KMX', 'Open'), ('KMX', 'High'), ('KMX', 'Low'), ('KMX', 'Close'), ('KMX', 'Adj Close'), ('KMX', 'Volume'), ('APH', 'Open'), ('APH', 'High'), ('APH', 'Low'), ('APH', 'Close'), ('APH', 'Adj Close'), ('APH', 'Volume'), ('MAR', 'Open'), ('MAR', 'High'), ('MAR', 'Low'), ('MAR', 'Close'), ('MAR', 'Adj Close'), ('MAR', 'Volume'), ('BALL', 'Open'), ('BALL', 'High'), ('BALL', 'Low'), ('BALL', 'Close'), ('BALL', 'Adj Close'), ('BALL', 'Volume'), ('EMR', 'Open'), ('EMR', 'High'), ('EMR', 'Low'), ('EMR', 'Close'), ('EMR', 'Adj Close'), ('EMR', 'Volume'), ('ORLY', 'Open'), ('ORLY', 'High'), ('ORLY', 'Low'), ('ORLY', 'Close'), ('ORLY', 'Adj Close'), ('ORLY', 'Volume'), ('INCY', 'Open'), ('INCY', 'High'), ('INCY', 'Low'), ('INCY', 'Close'), ('INCY', 'Adj Close'), ('INCY', 'Volume'), ('COO', 'Open'), ('COO', 'High'), ('COO', 'Low'), ('COO', 'Close'), ('COO', 'Adj Close'), ('COO', 'Volume'), ('PGR', 'Open'), ('PGR', 'High'), ('PGR', 'Low'), ('PGR', 'Close'), ('PGR', 'Adj Close'), ('PGR', 'Volume'), ('NKE', 'Open'), ('NKE', 'High'), ('NKE', 'Low'), ('NKE', 'Close'), ('NKE', 'Adj Close'), ('NKE', 'Volume'), ('BMY', 'Open'), ('BMY', 'High'), ('BMY', 'Low'), ('BMY', 'Close'), ('BMY', 'Adj Close'), ('BMY', 'Volume'), ('CF', 'Open'), ('CF', 'High'), ('CF', 'Low'), ('CF', 'Close'), ('CF', 'Adj Close'), ('CF', 'Volume'), ('JCI', 'Open'), ('JCI', 'High'), ('JCI', 'Low'), ('JCI', 'Close'), ('JCI', 'Adj Close'), ('JCI', 'Volume'), ('FICO', 'Open'), ('FICO', 'High'), ('FICO', 'Low'), ('FICO', 'Close'), ('FICO', 'Adj Close'), ('FICO', 'Volume'), ('DISH', 'Open'), ('DISH', 'High'), ('DISH', 'Low'), ('DISH', 'Close'), ('DISH', 'Adj Close'), ('DISH', 'Volume'), ('FISV', 'Open'), ('FISV', 'High'), ('FISV', 'Low'), ('FISV', 'Close'), ('FISV', 'Adj Close'), ('FISV', 'Volume'), ('ISRG', 'Open'), ('ISRG', 'High'), ('ISRG', 'Low'), ('ISRG', 'Close'), ('ISRG', 'Adj Close'), ('ISRG', 'Volume'), ('ADM', 'Open'), ('ADM', 'High'), ('ADM', 'Low'), ('ADM', 'Close'), ('ADM', 'Adj Close'), ('ADM', 'Volume'), ('MRK', 'Open'), ('MRK', 'High'), ('MRK', 'Low'), ('MRK', 'Close'), ('MRK', 'Adj Close'), ('MRK', 'Volume'), ('GOOG', 'Open'), ('GOOG', 'High'), ('GOOG', 'Low'), ('GOOG', 'Close'), ('GOOG', 'Adj Close'), ('GOOG', 'Volume'), ('AVY', 'Open'), ('AVY', 'High'), ('AVY', 'Low'), ('AVY', 'Close'), ('AVY', 'Adj Close'), ('AVY', 'Volume'), ('CMI', 'Open'), ('CMI', 'High'), ('CMI', 'Low'), ('CMI', 'Close'), ('CMI', 'Adj Close'), ('CMI', 'Volume'), ('XRAY', 'Open'), ('XRAY', 'High'), ('XRAY', 'Low'), ('XRAY', 'Close'), ('XRAY', 'Adj Close'), ('XRAY', 'Volume'), ('ELV', 'Open'), ('ELV', 'High'), ('ELV', 'Low'), ('ELV', 'Close'), ('ELV', 'Adj Close'), ('ELV', 'Volume'), ('MTCH', 'Open'), ('MTCH', 'High'), ('MTCH', 'Low'), ('MTCH', 'Close'), ('MTCH', 'Adj Close'), ('MTCH', 'Volume'), ('ORCL', 'Open'), ('ORCL', 'High'), ('ORCL', 'Low'), ('ORCL', 'Close'), ('ORCL', 'Adj Close'), ('ORCL', 'Volume'), ('PH', 'Open'), ('PH', 'High'), ('PH', 'Low'), ('PH', 'Close'), ('PH', 'Adj Close'), ('PH', 'Volume'), ('BAX', 'Open'), ('BAX', 'High'), ('BAX', 'Low'), ('BAX', 'Close'), ('BAX', 'Adj Close'), ('BAX', 'Volume'), ('EW', 'Open'), ('EW', 'High'), ('EW', 'Low'), ('EW', 'Close'), ('EW', 'Adj Close'), ('EW', 'Volume'), ('MCK', 'Open'), ('MCK', 'High'), ('MCK', 'Low'), ('MCK', 'Close'), ('MCK', 'Adj Close'), ('MCK', 'Volume'), ('AWK', 'Open'), ('AWK', 'High'), ('AWK', 'Low'), ('AWK', 'Close'), ('AWK', 'Adj Close'), ('AWK', 'Volume'), ('MLM', 'Open'), ('MLM', 'High'), ('MLM', 'Low'), ('MLM', 'Close'), ('MLM', 'Adj Close'), ('MLM', 'Volume'), ('PCG', 'Open'), ('PCG', 'High'), ('PCG', 'Low'), ('PCG', 'Close'), ('PCG', 'Adj Close'), ('PCG', 'Volume'), ('TXT', 'Open'), ('TXT', 'High'), ('TXT', 'Low'), ('TXT', 'Close'), ('TXT', 'Adj Close'), ('TXT', 'Volume'), ('PXD', 'Open'), ('PXD', 'High'), ('PXD', 'Low'), ('PXD', 'Close'), ('PXD', 'Adj Close'), ('PXD', 'Volume'), ('LH', 'Open'), ('LH', 'High'), ('LH', 'Low'), ('LH', 'Close'), ('LH', 'Adj Close'), ('LH', 'Volume'), ('HWM', 'Open'), ('HWM', 'High'), ('HWM', 'Low'), ('HWM', 'Close'), ('HWM', 'Adj Close'), ('HWM', 'Volume'), ('TROW', 'Open'), ('TROW', 'High'), ('TROW', 'Low'), ('TROW', 'Close'), ('TROW', 'Adj Close'), ('TROW', 'Volume'), ('CINF', 'Open'), ('CINF', 'High'), ('CINF', 'Low'), ('CINF', 'Close'), ('CINF', 'Adj Close'), ('CINF', 'Volume'), ('MOS', 'Open'), ('MOS', 'High'), ('MOS', 'Low'), ('MOS', 'Close'), ('MOS', 'Adj Close'), ('MOS', 'Volume'), ('MCO', 'Open'), ('MCO', 'High'), ('MCO', 'Low'), ('MCO', 'Close'), ('MCO', 'Adj Close'), ('MCO', 'Volume'), ('BIO', 'Open'), ('BIO', 'High'), ('BIO', 'Low'), ('BIO', 'Close'), ('BIO', 'Adj Close'), ('BIO', 'Volume'), ('KDP', 'Open'), ('KDP', 'High'), ('KDP', 'Low'), ('KDP', 'Close'), ('KDP', 'Adj Close'), ('KDP', 'Volume'), ('UDR', 'Open'), ('UDR', 'High'), ('UDR', 'Low'), ('UDR', 'Close'), ('UDR', 'Adj Close'), ('UDR', 'Volume'), ('A', 'Open'), ('A', 'High'), ('A', 'Low'), ('A', 'Close'), ('A', 'Adj Close'), ('A', 'Volume'), ('LOW', 'Open'), ('LOW', 'High'), ('LOW', 'Low'), ('LOW', 'Close'), ('LOW', 'Adj Close'), ('LOW', 'Volume'), ('AMAT', 'Open'), ('AMAT', 'High'), ('AMAT', 'Low'), ('AMAT', 'Close'), ('AMAT', 'Adj Close'), ('AMAT', 'Volume'), ('PEP', 'Open'), ('PEP', 'High'), ('PEP', 'Low'), ('PEP', 'Close'), ('PEP', 'Adj Close'), ('PEP', 'Volume'), ('DVA', 'Open'), ('DVA', 'High'), ('DVA', 'Low'), ('DVA', 'Close'), ('DVA', 'Adj Close'), ('DVA', 'Volume'), ('BKNG', 'Open'), ('BKNG', 'High'), ('BKNG', 'Low'), ('BKNG', 'Close'), ('BKNG', 'Adj Close'), ('BKNG', 'Volume'), ('CTSH', 'Open'), ('CTSH', 'High'), ('CTSH', 'Low'), ('CTSH', 'Close'), ('CTSH', 'Adj Close'), ('CTSH', 'Volume'), ('NEE', 'Open'), ('NEE', 'High'), ('NEE', 'Low'), ('NEE', 'Close'), ('NEE', 'Adj Close'), ('NEE', 'Volume'), ('CBOE', 'Open'), ('CBOE', 'High'), ('CBOE', 'Low'), ('CBOE', 'Close'), ('CBOE', 'Adj Close'), ('CBOE', 'Volume'), ('CMS', 'Open'), ('CMS', 'High'), ('CMS', 'Low'), ('CMS', 'Close'), ('CMS', 'Adj Close'), ('CMS', 'Volume'), ('NWSA', 'Open'), ('NWSA', 'High'), ('NWSA', 'Low'), ('NWSA', 'Close'), ('NWSA', 'Adj Close'), ('NWSA', 'Volume'), ('GLW', 'Open'), ('GLW', 'High'), ('GLW', 'Low'), ('GLW', 'Close'), ('GLW', 'Adj Close'), ('GLW', 'Volume'), ('AAL', 'Open'), ('AAL', 'High'), ('AAL', 'Low'), ('AAL', 'Close'), ('AAL', 'Adj Close'), ('AAL', 'Volume'), ('SYK', 'Open'), ('SYK', 'High'), ('SYK', 'Low'), ('SYK', 'Close'), ('SYK', 'Adj Close'), ('SYK', 'Volume'), ('LUV', 'Open'), ('LUV', 'High'), ('LUV', 'Low'), ('LUV', 'Close'), ('LUV', 'Adj Close'), ('LUV', 'Volume'), ('JNPR', 'Open'), ('JNPR', 'High'), ('JNPR', 'Low'), ('JNPR', 'Close'), ('JNPR', 'Adj Close'), ('JNPR', 'Volume'), ('TSN', 'Open'), ('TSN', 'High'), ('TSN', 'Low'), ('TSN', 'Close'), ('TSN', 'Adj Close'), ('TSN', 'Volume'), ('GS', 'Open'), ('GS', 'High'), ('GS', 'Low'), ('GS', 'Close'), ('GS', 'Adj Close'), ('GS', 'Volume'), ('BBWI', 'Open'), ('BBWI', 'High'), ('BBWI', 'Low'), ('BBWI', 'Close'), ('BBWI', 'Adj Close'), ('BBWI', 'Volume'), ('IRM', 'Open'), ('IRM', 'High'), ('IRM', 'Low'), ('IRM', 'Close'), ('IRM', 'Adj Close'), ('IRM', 'Volume'), ('BEN', 'Open'), ('BEN', 'High'), ('BEN', 'Low'), ('BEN', 'Close'), ('BEN', 'Adj Close'), ('BEN', 'Volume'), ('DHR', 'Open'), ('DHR', 'High'), ('DHR', 'Low'), ('DHR', 'Close'), ('DHR', 'Adj Close'), ('DHR', 'Volume'), ('KEY', 'Open'), ('KEY', 'High'), ('KEY', 'Low'), ('KEY', 'Close'), ('KEY', 'Adj Close'), ('KEY', 'Volume'), ('J', 'Open'), ('J', 'High'), ('J', 'Low'), ('J', 'Close'), ('J', 'Adj Close'), ('J', 'Volume'), ('ON', 'Open'), ('ON', 'High'), ('ON', 'Low'), ('ON', 'Close'), ('ON', 'Adj Close'), ('ON', 'Volume'), ('ZBRA', 'Open'), ('ZBRA', 'High'), ('ZBRA', 'Low'), ('ZBRA', 'Close'), ('ZBRA', 'Adj Close'), ('ZBRA', 'Volume'), ('SEDG', 'Open'), ('SEDG', 'High'), ('SEDG', 'Low'), ('SEDG', 'Close'), ('SEDG', 'Adj Close'), ('SEDG', 'Volume'), ('DLTR', 'Open'), ('DLTR', 'High'), ('DLTR', 'Low'), ('DLTR', 'Close'), ('DLTR', 'Adj Close'), ('DLTR', 'Volume'), ('TER', 'Open'), ('TER', 'High'), ('TER', 'Low'), ('TER', 'Close'), ('TER', 'Adj Close'), ('TER', 'Volume'), ('CEG', 'Open'), ('CEG', 'High'), ('CEG', 'Low'), ('CEG', 'Close'), ('CEG', 'Adj Close'), ('CEG', 'Volume'), ('PNC', 'Open'), ('PNC', 'High'), ('PNC', 'Low'), ('PNC', 'Close'), ('PNC', 'Adj Close'), ('PNC', 'Volume'), ('VTRS', 'Open'), ('VTRS', 'High'), ('VTRS', 'Low'), ('VTRS', 'Close'), ('VTRS', 'Adj Close'), ('VTRS', 'Volume'), ('AMP', 'Open'), ('AMP', 'High'), ('AMP', 'Low'), ('AMP', 'Close'), ('AMP', 'Adj Close'), ('AMP', 'Volume'), ('STZ', 'Open'), ('STZ', 'High'), ('STZ', 'Low'), ('STZ', 'Close'), ('STZ', 'Adj Close'), ('STZ', 'Volume'), ('TMO', 'Open'), ('TMO', 'High'), ('TMO', 'Low'), ('TMO', 'Close'), ('TMO', 'Adj Close'), ('TMO', 'Volume'), ('ALB', 'Open'), ('ALB', 'High'), ('ALB', 'Low'), ('ALB', 'Close'), ('ALB', 'Adj Close'), ('ALB', 'Volume'), ('QCOM', 'Open'), ('QCOM', 'High'), ('QCOM', 'Low'), ('QCOM', 'Close'), ('QCOM', 'Adj Close'), ('QCOM', 'Volume'), ('CCI', 'Open'), ('CCI', 'High'), ('CCI', 'Low'), ('CCI', 'Close'), ('CCI', 'Adj Close'), ('CCI', 'Volume'), ('LVS', 'Open'), ('LVS', 'High'), ('LVS', 'Low'), ('LVS', 'Close'), ('LVS', 'Adj Close'), ('LVS', 'Volume'), ('CSX', 'Open'), ('CSX', 'High'), ('CSX', 'Low'), ('CSX', 'Close'), ('CSX', 'Adj Close'), ('CSX', 'Volume'), ('ADSK', 'Open'), ('ADSK', 'High'), ('ADSK', 'Low'), ('ADSK', 'Close'), ('ADSK', 'Adj Close'), ('ADSK', 'Volume'), ('UHS', 'Open'), ('UHS', 'High'), ('UHS', 'Low'), ('UHS', 'Close'), ('UHS', 'Adj Close'), ('UHS', 'Volume'), ('DOW', 'Open'), ('DOW', 'High'), ('DOW', 'Low'), ('DOW', 'Close'), ('DOW', 'Adj Close'), ('DOW', 'Volume'), ('RMD', 'Open'), ('RMD', 'High'), ('RMD', 'Low'), ('RMD', 'Close'), ('RMD', 'Adj Close'), ('RMD', 'Volume'), ('CAH', 'Open'), ('CAH', 'High'), ('CAH', 'Low'), ('CAH', 'Close'), ('CAH', 'Adj Close'), ('CAH', 'Volume'), ('WBD', 'Open'), ('WBD', 'High'), ('WBD', 'Low'), ('WBD', 'Close'), ('WBD', 'Adj Close'), ('WBD', 'Volume'), ('STLD', 'Open'), ('STLD', 'High'), ('STLD', 'Low'), ('STLD', 'Close'), ('STLD', 'Adj Close'), ('STLD', 'Volume'), ('ANET', 'Open'), ('ANET', 'High'), ('ANET', 'Low'), ('ANET', 'Close'), ('ANET', 'Adj Close'), ('ANET', 'Volume'), ('DG', 'Open'), ('DG', 'High'), ('DG', 'Low'), ('DG', 'Close'), ('DG', 'Adj Close'), ('DG', 'Volume'), ('GEN', 'Open'), ('GEN', 'High'), ('GEN', 'Low'), ('GEN', 'Close'), ('GEN', 'Adj Close'), ('GEN', 'Volume'), ('MA', 'Open'), ('MA', 'High'), ('MA', 'Low'), ('MA', 'Close'), ('MA', 'Adj Close'), ('MA', 'Volume'), ('IP', 'Open'), ('IP', 'High'), ('IP', 'Low'), ('IP', 'Close'), ('IP', 'Adj Close'), ('IP', 'Volume'), ('PTC', 'Open'), ('PTC', 'High'), ('PTC', 'Low'), ('PTC', 'Close'), ('PTC', 'Adj Close'), ('PTC', 'Volume'), ('CRL', 'Open'), ('CRL', 'High'), ('CRL', 'Low'), ('CRL', 'Close'), ('CRL', 'Adj Close'), ('CRL', 'Volume'), ('ROL', 'Open'), ('ROL', 'High'), ('ROL', 'Low'), ('ROL', 'Close'), ('ROL', 'Adj Close'), ('ROL', 'Volume'), ('USB', 'Open'), ('USB', 'High'), ('USB', 'Low'), ('USB', 'Close'), ('USB', 'Adj Close'), ('USB', 'Volume'), ('MTB', 'Open'), ('MTB', 'High'), ('MTB', 'Low'), ('MTB', 'Close'), ('MTB', 'Adj Close'), ('MTB', 'Volume'), ('PKI', 'Open'), ('PKI', 'High'), ('PKI', 'Low'), ('PKI', 'Close'), ('PKI', 'Adj Close'), ('PKI', 'Volume'), ('TSCO', 'Open'), ('TSCO', 'High'), ('TSCO', 'Low'), ('TSCO', 'Close'), ('TSCO', 'Adj Close'), ('TSCO', 'Volume'), ('BBY', 'Open'), ('BBY', 'High'), ('BBY', 'Low'), ('BBY', 'Close'), ('BBY', 'Adj Close'), ('BBY', 'Volume'), ('REGN', 'Open'), ('REGN', 'High'), ('REGN', 'Low'), ('REGN', 'Close'), ('REGN', 'Adj Close'), ('REGN', 'Volume'), ('EQR', 'Open'), ('EQR', 'High'), ('EQR', 'Low'), ('EQR', 'Close'), ('EQR', 'Adj Close'), ('EQR', 'Volume'), ('WY', 'Open'), ('WY', 'High'), ('WY', 'Low'), ('WY', 'Close'), ('WY', 'Adj Close'), ('WY', 'Volume'), ('ADI', 'Open'), ('ADI', 'High'), ('ADI', 'Low'), ('ADI', 'Close'), ('ADI', 'Adj Close'), ('ADI', 'Volume'), ('MPWR', 'Open'), ('MPWR', 'High'), ('MPWR', 'Low'), ('MPWR', 'Close'), ('MPWR', 'Adj Close'), ('MPWR', 'Volume'), ('SBAC', 'Open'), ('SBAC', 'High'), ('SBAC', 'Low'), ('SBAC', 'Close'), ('SBAC', 'Adj Close'), ('SBAC', 'Volume'), ('NCLH', 'Open'), ('NCLH', 'High'), ('NCLH', 'Low'), ('NCLH', 'Close'), ('NCLH', 'Adj Close'), ('NCLH', 'Volume'), ('TRGP', 'Open'), ('TRGP', 'High'), ('TRGP', 'Low'), ('TRGP', 'Close'), ('TRGP', 'Adj Close'), ('TRGP', 'Volume'), ('WRB', 'Open'), ('WRB', 'High'), ('WRB', 'Low'), ('WRB', 'Close'), ('WRB', 'Adj Close'), ('WRB', 'Volume'), ('CAT', 'Open'), ('CAT', 'High'), ('CAT', 'Low'), ('CAT', 'Close'), ('CAT', 'Adj Close'), ('CAT', 'Volume'), ('AIZ', 'Open'), ('AIZ', 'High'), ('AIZ', 'Low'), ('AIZ', 'Close'), ('AIZ', 'Adj Close'), ('AIZ', 'Volume'), ('CHRW', 'Open'), ('CHRW', 'High'), ('CHRW', 'Low'), ('CHRW', 'Close'), ('CHRW', 'Adj Close'), ('CHRW', 'Volume'), ('ADP', 'Open'), ('ADP', 'High'), ('ADP', 'Low'), ('ADP', 'Close'), ('ADP', 'Adj Close'), ('ADP', 'Volume'), ('KO', 'Open'), ('KO', 'High'), ('KO', 'Low'), ('KO', 'Close'), ('KO', 'Adj Close'), ('KO', 'Volume'), ('TPR', 'Open'), ('TPR', 'High'), ('TPR', 'Low'), ('TPR', 'Close'), ('TPR', 'Adj Close'), ('TPR', 'Volume'), ('VMC', 'Open'), ('VMC', 'High'), ('VMC', 'Low'), ('VMC', 'Close'), ('VMC', 'Adj Close'), ('VMC', 'Volume'), ('HOLX', 'Open'), ('HOLX', 'High'), ('HOLX', 'Low'), ('HOLX', 'Close'), ('HOLX', 'Adj Close'), ('HOLX', 'Volume'), ('WFC', 'Open'), ('WFC', 'High'), ('WFC', 'Low'), ('WFC', 'Close'), ('WFC', 'Adj Close'), ('WFC', 'Volume'), ('JBHT', 'Open'), ('JBHT', 'High'), ('JBHT', 'Low'), ('JBHT', 'Close'), ('JBHT', 'Adj Close'), ('JBHT', 'Volume'), ('SNPS', 'Open'), ('SNPS', 'High'), ('SNPS', 'Low'), ('SNPS', 'Close'), ('SNPS', 'Adj Close'), ('SNPS', 'Volume'), ('O', 'Open'), ('O', 'High'), ('O', 'Low'), ('O', 'Close'), ('O', 'Adj Close'), ('O', 'Volume'), ('AES', 'Open'), ('AES', 'High'), ('AES', 'Low'), ('AES', 'Close'), ('AES', 'Adj Close'), ('AES', 'Volume'), ('MMC', 'Open'), ('MMC', 'High'), ('MMC', 'Low'), ('MMC', 'Close'), ('MMC', 'Adj Close'), ('MMC', 'Volume'), ('SPG', 'Open'), ('SPG', 'High'), ('SPG', 'Low'), ('SPG', 'Close'), ('SPG', 'Adj Close'), ('SPG', 'Volume'), ('CMG', 'Open'), ('CMG', 'High'), ('CMG', 'Low'), ('CMG', 'Close'), ('CMG', 'Adj Close'), ('CMG', 'Volume'), ('CL', 'Open'), ('CL', 'High'), ('CL', 'Low'), ('CL', 'Close'), ('CL', 'Adj Close'), ('CL', 'Volume'), ('META', 'Open'), ('META', 'High'), ('META', 'Low'), ('META', 'Close'), ('META', 'Adj Close'), ('META', 'Volume'), ('MKTX', 'Open'), ('MKTX', 'High'), ('MKTX', 'Low'), ('MKTX', 'Close'), ('MKTX', 'Adj Close'), ('MKTX', 'Volume'), ('BR', 'Open'), ('BR', 'High'), ('BR', 'Low'), ('BR', 'Close'), ('BR', 'Adj Close'), ('BR', 'Volume'), ('BSX', 'Open'), ('BSX', 'High'), ('BSX', 'Low'), ('BSX', 'Close'), ('BSX', 'Adj Close'), ('BSX', 'Volume'), ('TJX', 'Open'), ('TJX', 'High'), ('TJX', 'Low'), ('TJX', 'Close'), ('TJX', 'Adj Close'), ('TJX', 'Volume'), ('PYPL', 'Open'), ('PYPL', 'High'), ('PYPL', 'Low'), ('PYPL', 'Close'), ('PYPL', 'Adj Close'), ('PYPL', 'Volume'), ('AJG', 'Open'), ('AJG', 'High'), ('AJG', 'Low'), ('AJG', 'Close'), ('AJG', 'Adj Close'), ('AJG', 'Volume'), ('VZ', 'Open'), ('VZ', 'High'), ('VZ', 'Low'), ('VZ', 'Close'), ('VZ', 'Adj Close'), ('VZ', 'Volume'), ('BWA', 'Open'), ('BWA', 'High'), ('BWA', 'Low'), ('BWA', 'Close'), ('BWA', 'Adj Close'), ('BWA', 'Volume'), ('ICE', 'Open'), ('ICE', 'High'), ('ICE', 'Low'), ('ICE', 'Close'), ('ICE', 'Adj Close'), ('ICE', 'Volume'), ('CARR', 'Open'), ('CARR', 'High'), ('CARR', 'Low'), ('CARR', 'Close'), ('CARR', 'Adj Close'), ('CARR', 'Volume'), ('SLB', 'Open'), ('SLB', 'High'), ('SLB', 'Low'), ('SLB', 'Close'), ('SLB', 'Adj Close'), ('SLB', 'Volume'), ('FRT', 'Open'), ('FRT', 'High'), ('FRT', 'Low'), ('FRT', 'Close'), ('FRT', 'Adj Close'), ('FRT', 'Volume'), ('OMC', 'Open'), ('OMC', 'High'), ('OMC', 'Low'), ('OMC', 'Close'), ('OMC', 'Adj Close'), ('OMC', 'Volume'), ('QRVO', 'Open'), ('QRVO', 'High'), ('QRVO', 'Low'), ('QRVO', 'Close'), ('QRVO', 'Adj Close'), ('QRVO', 'Volume'), ('ROK', 'Open'), ('ROK', 'High'), ('ROK', 'Low'), ('ROK', 'Close'), ('ROK', 'Adj Close'), ('ROK', 'Volume'), ('IEX', 'Open'), ('IEX', 'High'), ('IEX', 'Low'), ('IEX', 'Close'), ('IEX', 'Adj Close'), ('IEX', 'Volume'), ('VRSK', 'Open'), ('VRSK', 'High'), ('VRSK', 'Low'), ('VRSK', 'Close'), ('VRSK', 'Adj Close'), ('VRSK', 'Volume'), ('TRMB', 'Open'), ('TRMB', 'High'), ('TRMB', 'Low'), ('TRMB', 'Close'), ('TRMB', 'Adj Close'), ('TRMB', 'Volume'), ('LNC', 'Open'), ('LNC', 'High'), ('LNC', 'Low'), ('LNC', 'Close'), ('LNC', 'Adj Close'), ('LNC', 'Volume'), ('MGM', 'Open'), ('MGM', 'High'), ('MGM', 'Low'), ('MGM', 'Close'), ('MGM', 'Adj Close'), ('MGM', 'Volume'), ('PNR', 'Open'), ('PNR', 'High'), ('PNR', 'Low'), ('PNR', 'Close'), ('PNR', 'Adj Close'), ('PNR', 'Volume'), ('MNST', 'Open'), ('MNST', 'High'), ('MNST', 'Low'), ('MNST', 'Close'), ('MNST', 'Adj Close'), ('MNST', 'Volume'), ('IDXX', 'Open'), ('IDXX', 'High'), ('IDXX', 'Low'), ('IDXX', 'Close'), ('IDXX', 'Adj Close'), ('IDXX', 'Volume'), ('IBM', 'Open'), ('IBM', 'High'), ('IBM', 'Low'), ('IBM', 'Close'), ('IBM', 'Adj Close'), ('IBM', 'Volume'), ('ES', 'Open'), ('ES', 'High'), ('ES', 'Low'), ('ES', 'Close'), ('ES', 'Adj Close'), ('ES', 'Volume'), ('NVDA', 'Open'), ('NVDA', 'High'), ('NVDA', 'Low'), ('NVDA', 'Close'), ('NVDA', 'Adj Close'), ('NVDA', 'Volume'), ('DPZ', 'Open'), ('DPZ', 'High'), ('DPZ', 'Low'), ('DPZ', 'Close'), ('DPZ', 'Adj Close'), ('DPZ', 'Volume'), ('PFE', 'Open'), ('PFE', 'High'), ('PFE', 'Low'), ('PFE', 'Close'), ('PFE', 'Adj Close'), ('PFE', 'Volume'), ('FRC', 'Open'), ('FRC', 'High'), ('FRC', 'Low'), ('FRC', 'Close'), ('FRC', 'Adj Close'), ('FRC', 'Volume'), ('TAP', 'Open'), ('TAP', 'High'), ('TAP', 'Low'), ('TAP', 'Close'), ('TAP', 'Adj Close'), ('TAP', 'Volume'), ('CE', 'Open'), ('CE', 'High'), ('CE', 'Low'), ('CE', 'Close'), ('CE', 'Adj Close'), ('CE', 'Volume'), ('KLAC', 'Open'), ('KLAC', 'High'), ('KLAC', 'Low'), ('KLAC', 'Close'), ('KLAC', 'Adj Close'), ('KLAC', 'Volume'), ('EQT', 'Open'), ('EQT', 'High'), ('EQT', 'Low'), ('EQT', 'Close'), ('EQT', 'Adj Close'), ('EQT', 'Volume'), ('BA', 'Open'), ('BA', 'High'), ('BA', 'Low'), ('BA', 'Close'), ('BA', 'Adj Close'), ('BA', 'Volume'), ('DVN', 'Open'), ('DVN', 'High'), ('DVN', 'Low'), ('DVN', 'Close'), ('DVN', 'Adj Close'), ('DVN', 'Volume'), ('ULTA', 'Open'), ('ULTA', 'High'), ('ULTA', 'Low'), ('ULTA', 'Close'), ('ULTA', 'Adj Close'), ('ULTA', 'Volume'), ('HBAN', 'Open'), ('HBAN', 'High'), ('HBAN', 'Low'), ('HBAN', 'Close'), ('HBAN', 'Adj Close'), ('HBAN', 'Volume'), ('ITW', 'Open'), ('ITW', 'High'), ('ITW', 'Low'), ('ITW', 'Close'), ('ITW', 'Adj Close'), ('ITW', 'Volume'), ('PKG', 'Open'), ('PKG', 'High'), ('PKG', 'Low'), ('PKG', 'Close'), ('PKG', 'Adj Close'), ('PKG', 'Volume'), ('SO', 'Open'), ('SO', 'High'), ('SO', 'Low'), ('SO', 'Close'), ('SO', 'Adj Close'), ('SO', 'Volume'), ('ALL', 'Open'), ('ALL', 'High'), ('ALL', 'Low'), ('ALL', 'Close'), ('ALL', 'Adj Close'), ('ALL', 'Volume'), ('COP', 'Open'), ('COP', 'High'), ('COP', 'Low'), ('COP', 'Close'), ('COP', 'Adj Close'), ('COP', 'Volume'), ('RF', 'Open'), ('RF', 'High'), ('RF', 'Low'), ('RF', 'Close'), ('RF', 'Adj Close'), ('RF', 'Volume'), ('FSLR', 'Open'), ('FSLR', 'High'), ('FSLR', 'Low'), ('FSLR', 'Close'), ('FSLR', 'Adj Close'), ('FSLR', 'Volume'), ('WMB', 'Open'), ('WMB', 'High'), ('WMB', 'Low'), ('WMB', 'Close'), ('WMB', 'Adj Close'), ('WMB', 'Volume'), ('LDOS', 'Open'), ('LDOS', 'High'), ('LDOS', 'Low'), ('LDOS', 'Close'), ('LDOS', 'Adj Close'), ('LDOS', 'Volume'), ('WST', 'Open'), ('WST', 'High'), ('WST', 'Low'), ('WST', 'Close'), ('WST', 'Adj Close'), ('WST', 'Volume'), ('SWKS', 'Open'), ('SWKS', 'High'), ('SWKS', 'Low'), ('SWKS', 'Close'), ('SWKS', 'Adj Close'), ('SWKS', 'Volume'), ('MHK', 'Open'), ('MHK', 'High'), ('MHK', 'Low'), ('MHK', 'Close'), ('MHK', 'Adj Close'), ('MHK', 'Volume'), ('PAYC', 'Open'), ('PAYC', 'High'), ('PAYC', 'Low'), ('PAYC', 'Close'), ('PAYC', 'Adj Close'), ('PAYC', 'Volume'), ('AIG', 'Open'), ('AIG', 'High'), ('AIG', 'Low'), ('AIG', 'Close'), ('AIG', 'Adj Close'), ('AIG', 'Volume'), ('TECH', 'Open'), ('TECH', 'High'), ('TECH', 'Low'), ('TECH', 'Close'), ('TECH', 'Adj Close'), ('TECH', 'Volume'), ('KEYS', 'Open'), ('KEYS', 'High'), ('KEYS', 'Low'), ('KEYS', 'Close'), ('KEYS', 'Adj Close'), ('KEYS', 'Volume'), ('TTWO', 'Open'), ('TTWO', 'High'), ('TTWO', 'Low'), ('TTWO', 'Close'), ('TTWO', 'Adj Close'), ('TTWO', 'Volume'), ('CPRT', 'Open'), ('CPRT', 'High'), ('CPRT', 'Low'), ('CPRT', 'Close'), ('CPRT', 'Adj Close'), ('CPRT', 'Volume'), ('RTX', 'Open'), ('RTX', 'High'), ('RTX', 'Low'), ('RTX', 'Close'), ('RTX', 'Adj Close'), ('RTX', 'Volume'), ('IT', 'Open'), ('IT', 'High'), ('IT', 'Low'), ('IT', 'Close'), ('IT', 'Adj Close'), ('IT', 'Volume'), ('KR', 'Open'), ('KR', 'High'), ('KR', 'Low'), ('KR', 'Close'), ('KR', 'Adj Close'), ('KR', 'Volume'), ('NOW', 'Open'), ('NOW', 'High'), ('NOW', 'Low'), ('NOW', 'Close'), ('NOW', 'Adj Close'), ('NOW', 'Volume'), ('MCHP', 'Open'), ('MCHP', 'High'), ('MCHP', 'Low'), ('MCHP', 'Close'), ('MCHP', 'Adj Close'), ('MCHP', 'Volume'), ('DD', 'Open'), ('DD', 'High'), ('DD', 'Low'), ('DD', 'Close'), ('DD', 'Adj Close'), ('DD', 'Volume'), ('ETSY', 'Open'), ('ETSY', 'High'), ('ETSY', 'Low'), ('ETSY', 'Close'), ('ETSY', 'Adj Close'), ('ETSY', 'Volume'), ('LMT', 'Open'), ('LMT', 'High'), ('LMT', 'Low'), ('LMT', 'Close'), ('LMT', 'Adj Close'), ('LMT', 'Volume'), ('K', 'Open'), ('K', 'High'), ('K', 'Low'), ('K', 'Close'), ('K', 'Adj Close'), ('K', 'Volume'), ('REG', 'Open'), ('REG', 'High'), ('REG', 'Low'), ('REG', 'Close'), ('REG', 'Adj Close'), ('REG', 'Volume'), ('WM', 'Open'), ('WM', 'High'), ('WM', 'Low'), ('WM', 'Close'), ('WM', 'Adj Close'), ('WM', 'Volume'), ('TDY', 'Open'), ('TDY', 'High'), ('TDY', 'Low'), ('TDY', 'Close'), ('TDY', 'Adj Close'), ('TDY', 'Volume'), ('ZBH', 'Open'), ('ZBH', 'High'), ('ZBH', 'Low'), ('ZBH', 'Close'), ('ZBH', 'Adj Close'), ('ZBH', 'Volume'), ('SYY', 'Open'), ('SYY', 'High'), ('SYY', 'Low'), ('SYY', 'Close'), ('SYY', 'Adj Close'), ('SYY', 'Volume'), ('UNH', 'Open'), ('UNH', 'High'), ('UNH', 'Low'), ('UNH', 'Close'), ('UNH', 'Adj Close'), ('UNH', 'Volume'), ('FOX', 'Open'), ('FOX', 'High'), ('FOX', 'Low'), ('FOX', 'Close'), ('FOX', 'Adj Close'), ('FOX', 'Volume'), ('DFS', 'Open'), ('DFS', 'High'), ('DFS', 'Low'), ('DFS', 'Close'), ('DFS', 'Adj Close'), ('DFS', 'Volume'), ('SHW', 'Open'), ('SHW', 'High'), ('SHW', 'Low'), ('SHW', 'Close'), ('SHW', 'Adj Close'), ('SHW', 'Volume'), ('INVH', 'Open'), ('INVH', 'High'), ('INVH', 'Low'), ('INVH', 'Close'), ('INVH', 'Adj Close'), ('INVH', 'Volume'), ('RL', 'Open'), ('RL', 'High'), ('RL', 'Low'), ('RL', 'Close'), ('RL', 'Adj Close'), ('RL', 'Volume'), ('CTAS', 'Open'), ('CTAS', 'High'), ('CTAS', 'Low'), ('CTAS', 'Close'), ('CTAS', 'Adj Close'), ('CTAS', 'Volume'), ('HIG', 'Open'), ('HIG', 'High'), ('HIG', 'Low'), ('HIG', 'Close'), ('HIG', 'Adj Close'), ('HIG', 'Volume'), ('AAPL', 'Open'), ('AAPL', 'High'), ('AAPL', 'Low'), ('AAPL', 'Close'), ('AAPL', 'Adj Close'), ('AAPL', 'Volume'), ('APD', 'Open'), ('APD', 'High'), ('APD', 'Low'), ('APD', 'Close'), ('APD', 'Adj Close'), ('APD', 'Volume'), ('HPE', 'Open'), ('HPE', 'High'), ('HPE', 'Low'), ('HPE', 'Close'), ('HPE', 'Adj Close'), ('HPE', 'Volume'), ('JNJ', 'Open'), ('JNJ', 'High'), ('JNJ', 'Low'), ('JNJ', 'Close'), ('JNJ', 'Adj Close'), ('JNJ', 'Volume'), ('MOH', 'Open'), ('MOH', 'High'), ('MOH', 'Low'), ('MOH', 'Close'), ('MOH', 'Adj Close'), ('MOH', 'Volume'), ('LKQ', 'Open'), ('LKQ', 'High'), ('LKQ', 'Low'), ('LKQ', 'Close'), ('LKQ', 'Adj Close'), ('LKQ', 'Volume'), ('DRI', 'Open'), ('DRI', 'High'), ('DRI', 'Low'), ('DRI', 'Close'), ('DRI', 'Adj Close'), ('DRI', 'Volume'), ('DUK', 'Open'), ('DUK', 'High'), ('DUK', 'Low'), ('DUK', 'Close'), ('DUK', 'Adj Close'), ('DUK', 'Volume'), ('CI', 'Open'), ('CI', 'High'), ('CI', 'Low'), ('CI', 'Close'), ('CI', 'Adj Close'), ('CI', 'Volume'), ('V', 'Open'), ('V', 'High'), ('V', 'Low'), ('V', 'Close'), ('V', 'Adj Close'), ('V', 'Volume'), ('PG', 'Open'), ('PG', 'High'), ('PG', 'Low'), ('PG', 'Close'), ('PG', 'Adj Close'), ('PG', 'Volume'), ('DXC', 'Open'), ('DXC', 'High'), ('DXC', 'Low'), ('DXC', 'Close'), ('DXC', 'Adj Close'), ('DXC', 'Volume'), ('RSG', 'Open'), ('RSG', 'High'), ('RSG', 'Low'), ('RSG', 'Close'), ('RSG', 'Adj Close'), ('RSG', 'Volume'), ('PCAR', 'Open'), ('PCAR', 'High'), ('PCAR', 'Low'), ('PCAR', 'Close'), ('PCAR', 'Adj Close'), ('PCAR', 'Volume'), ('FAST', 'Open'), ('FAST', 'High'), ('FAST', 'Low'), ('FAST', 'Close'), ('FAST', 'Adj Close'), ('FAST', 'Volume'), ('CDAY', 'Open'), ('CDAY', 'High'), ('CDAY', 'Low'), ('CDAY', 'Close'), ('CDAY', 'Adj Close'), ('CDAY', 'Volume'), ('NTAP', 'Open'), ('NTAP', 'High'), ('NTAP', 'Low'), ('NTAP', 'Close'), ('NTAP', 'Adj Close'), ('NTAP', 'Volume'), ('VLO', 'Open'), ('VLO', 'High'), ('VLO', 'Low'), ('VLO', 'Close'), ('VLO', 'Adj Close'), ('VLO', 'Volume'), ('TSLA', 'Open'), ('TSLA', 'High'), ('TSLA', 'Low'), ('TSLA', 'Close'), ('TSLA', 'Adj Close'), ('TSLA', 'Volume'), ('BDX', 'Open'), ('BDX', 'High'), ('BDX', 'Low'), ('BDX', 'Close'), ('BDX', 'Adj Close'), ('BDX', 'Volume'), ('WAT', 'Open'), ('WAT', 'High'), ('WAT', 'Low'), ('WAT', 'Close'), ('WAT', 'Adj Close'), ('WAT', 'Volume'), ('AAP', 'Open'), ('AAP', 'High'), ('AAP', 'Low'), ('AAP', 'Close'), ('AAP', 'Adj Close'), ('AAP', 'Volume'), ('WHR', 'Open'), ('WHR', 'High'), ('WHR', 'Low'), ('WHR', 'Close'), ('WHR', 'Adj Close'), ('WHR', 'Volume'), ('VICI', 'Open'), ('VICI', 'High'), ('VICI', 'Low'), ('VICI', 'Close'), ('VICI', 'Adj Close'), ('VICI', 'Volume'), ('WBA', 'Open'), ('WBA', 'High'), ('WBA', 'Low'), ('WBA', 'Close'), ('WBA', 'Adj Close'), ('WBA', 'Volume'), ('DOV', 'Open'), ('DOV', 'High'), ('DOV', 'Low'), ('DOV', 'Close'), ('DOV', 'Adj Close'), ('DOV', 'Volume'), ('EIX', 'Open'), ('EIX', 'High'), ('EIX', 'Low'), ('EIX', 'Close'), ('EIX', 'Adj Close'), ('EIX', 'Volume'), ('DE', 'Open'), ('DE', 'High'), ('DE', 'Low'), ('DE', 'Close'), ('DE', 'Adj Close'), ('DE', 'Volume'), ('TXN', 'Open'), ('TXN', 'High'), ('TXN', 'Low'), ('TXN', 'Close'), ('TXN', 'Adj Close'), ('TXN', 'Volume'), ('VTR', 'Open'), ('VTR', 'High'), ('VTR', 'Low'), ('VTR', 'Close'), ('VTR', 'Adj Close'), ('VTR', 'Volume'), ('CB', 'Open'), ('CB', 'High'), ('CB', 'Low'), ('CB', 'Close'), ('CB', 'Adj Close'), ('CB', 'Volume'), ('TDG', 'Open'), ('TDG', 'High'), ('TDG', 'Low'), ('TDG', 'Close'), ('TDG', 'Adj Close'), ('TDG', 'Volume'), ('PAYX', 'Open'), ('PAYX', 'High'), ('PAYX', 'Low'), ('PAYX', 'Close'), ('PAYX', 'Adj Close'), ('PAYX', 'Volume'), ('AZO', 'Open'), ('AZO', 'High'), ('AZO', 'Low'), ('AZO', 'Close'), ('AZO', 'Adj Close'), ('AZO', 'Volume'), ('OXY', 'Open'), ('OXY', 'High'), ('OXY', 'Low'), ('OXY', 'Close'), ('OXY', 'Adj Close'), ('OXY', 'Volume'), ('SJM', 'Open'), ('SJM', 'High'), ('SJM', 'Low'), ('SJM', 'Close'), ('SJM', 'Adj Close'), ('SJM', 'Volume'), ('ED', 'Open'), ('ED', 'High'), ('ED', 'Low'), ('ED', 'Close'), ('ED', 'Adj Close'), ('ED', 'Volume'), ('NI', 'Open'), ('NI', 'High'), ('NI', 'Low'), ('NI', 'Close'), ('NI', 'Adj Close'), ('NI', 'Volume'), ('HUM', 'Open'), ('HUM', 'High'), ('HUM', 'Low'), ('HUM', 'Close'), ('HUM', 'Adj Close'), ('HUM', 'Volume'), ('MU', 'Open'), ('MU', 'High'), ('MU', 'Low'), ('MU', 'Close'), ('MU', 'Adj Close'), ('MU', 'Volume'), ('RCL', 'Open'), ('RCL', 'High'), ('RCL', 'Low'), ('RCL', 'Close'), ('RCL', 'Adj Close'), ('RCL', 'Volume'), ('ATVI', 'Open'), ('ATVI', 'High'), ('ATVI', 'Low'), ('ATVI', 'Close'), ('ATVI', 'Adj Close'), ('ATVI', 'Volume'), ('NXPI', 'Open'), ('NXPI', 'High'), ('NXPI', 'Low'), ('NXPI', 'Close'), ('NXPI', 'Adj Close'), ('NXPI', 'Volume'), ('HON', 'Open'), ('HON', 'High'), ('HON', 'Low'), ('HON', 'Close'), ('HON', 'Adj Close'), ('HON', 'Volume'), ('AKAM', 'Open'), ('AKAM', 'High'), ('AKAM', 'Low'), ('AKAM', 'Close'), ('AKAM', 'Adj Close'), ('AKAM', 'Volume'), ('IFF', 'Open'), ('IFF', 'High'), ('IFF', 'Low'), ('IFF', 'Close'), ('IFF', 'Adj Close'), ('IFF', 'Volume'), ('PNW', 'Open'), ('PNW', 'High'), ('PNW', 'Low'), ('PNW', 'Close'), ('PNW', 'Adj Close'), ('PNW', 'Volume'), ('TT', 'Open'), ('TT', 'High'), ('TT', 'Low'), ('TT', 'Close'), ('TT', 'Adj Close'), ('TT', 'Volume'), ('ATO', 'Open'), ('ATO', 'High'), ('ATO', 'Low'), ('ATO', 'Close'), ('ATO', 'Adj Close'), ('ATO', 'Volume'), ('STE', 'Open'), ('STE', 'High'), ('STE', 'Low'), ('STE', 'Close'), ('STE', 'Adj Close'), ('STE', 'Volume'), ('EL', 'Open'), ('EL', 'High'), ('EL', 'Low'), ('EL', 'Close'), ('EL', 'Adj Close'), ('EL', 'Volume'), ('HSY', 'Open'), ('HSY', 'High'), ('HSY', 'Low'), ('HSY', 'Close'), ('HSY', 'Adj Close'), ('HSY', 'Volume'), ('FITB', 'Open'), ('FITB', 'High'), ('FITB', 'Low'), ('FITB', 'Close'), ('FITB', 'Adj Close'), ('FITB', 'Volume'), ('DIS', 'Open'), ('DIS', 'High'), ('DIS', 'Low'), ('DIS', 'Close'), ('DIS', 'Adj Close'), ('DIS', 'Volume'), ('EA', 'Open'), ('EA', 'High'), ('EA', 'Low'), ('EA', 'Close'), ('EA', 'Adj Close'), ('EA', 'Volume'), ('MTD', 'Open'), ('MTD', 'High'), ('MTD', 'Low'), ('MTD', 'Close'), ('MTD', 'Adj Close'), ('MTD', 'Volume'), ('PHM', 'Open'), ('PHM', 'High'), ('PHM', 'Low'), ('PHM', 'Close'), ('PHM', 'Adj Close'), ('PHM', 'Volume'), ('ETN', 'Open'), ('ETN', 'High'), ('ETN', 'Low'), ('ETN', 'Close'), ('ETN', 'Adj Close'), ('ETN', 'Volume'), ('NWL', 'Open'), ('NWL', 'High'), ('NWL', 'Low'), ('NWL', 'Close'), ('NWL', 'Adj Close'), ('NWL', 'Volume'), ('MMM', 'Open'), ('MMM', 'High'), ('MMM', 'Low'), ('MMM', 'Close'), ('MMM', 'Adj Close'), ('MMM', 'Volume'), ('PEG', 'Open'), ('PEG', 'High'), ('PEG', 'Low'), ('PEG', 'Close'), ('PEG', 'Adj Close'), ('PEG', 'Volume'), ('IVZ', 'Open'), ('IVZ', 'High'), ('IVZ', 'Low'), ('IVZ', 'Close'), ('IVZ', 'Adj Close'), ('IVZ', 'Volume'), ('HRL', 'Open'), ('HRL', 'High'), ('HRL', 'Low'), ('HRL', 'Close'), ('HRL', 'Adj Close'), ('HRL', 'Volume'), ('HD', 'Open'), ('HD', 'High'), ('HD', 'Low'), ('HD', 'Close'), ('HD', 'Adj Close'), ('HD', 'Volume'), ('URI', 'Open'), ('URI', 'High'), ('URI', 'Low'), ('URI', 'Close'), ('URI', 'Adj Close'), ('URI', 'Volume'), ('NRG', 'Open'), ('NRG', 'High'), ('NRG', 'Low'), ('NRG', 'Close'), ('NRG', 'Adj Close'), ('NRG', 'Volume'), ('AOS', 'Open'), ('AOS', 'High'), ('AOS', 'Low'), ('AOS', 'Close'), ('AOS', 'Adj Close'), ('AOS', 'Volume'), ('GOOGL', 'Open'), ('GOOGL', 'High'), ('GOOGL', 'Low'), ('GOOGL', 'Close'), ('GOOGL', 'Adj Close'), ('GOOGL', 'Volume'), ('ENPH', 'Open'), ('ENPH', 'High'), ('ENPH', 'Low'), ('ENPH', 'Close'), ('ENPH', 'Adj Close'), ('ENPH', 'Volume'), ('FTNT', 'Open'), ('FTNT', 'High'), ('FTNT', 'Low'), ('FTNT', 'Close'), ('FTNT', 'Adj Close'), ('FTNT', 'Volume'), ('CAG', 'Open'), ('CAG', 'High'), ('CAG', 'Low'), ('CAG', 'Close'), ('CAG', 'Adj Close'), ('CAG', 'Volume'), ('APTV', 'Open'), ('APTV', 'High'), ('APTV', 'Low'), ('APTV', 'Close'), ('APTV', 'Adj Close'), ('APTV', 'Volume'), ('CDNS', 'Open'), ('CDNS', 'High'), ('CDNS', 'Low'), ('CDNS', 'Close'), ('CDNS', 'Adj Close'), ('CDNS', 'Volume'), ('LEN', 'Open'), ('LEN', 'High'), ('LEN', 'Low'), ('LEN', 'Close'), ('LEN', 'Adj Close'), ('LEN', 'Volume'), ('WTW', 'Open'), ('WTW', 'High'), ('WTW', 'Low'), ('WTW', 'Close'), ('WTW', 'Adj Close'), ('WTW', 'Volume'), ('SRE', 'Open'), ('SRE', 'High'), ('SRE', 'Low'), ('SRE', 'Close'), ('SRE', 'Adj Close'), ('SRE', 'Volume'), ('ADBE', 'Open'), ('ADBE', 'High'), ('ADBE', 'Low'), ('ADBE', 'Close'), ('ADBE', 'Adj Close'), ('ADBE', 'Volume'), ('VRSN', 'Open'), ('VRSN', 'High'), ('VRSN', 'Low'), ('VRSN', 'Close'), ('VRSN', 'Adj Close'), ('VRSN', 'Volume'), ('WDC', 'Open'), ('WDC', 'High'), ('WDC', 'Low'), ('WDC', 'Close'), ('WDC', 'Adj Close'), ('WDC', 'Volume'), ('MDLZ', 'Open'), ('MDLZ', 'High'), ('MDLZ', 'Low'), ('MDLZ', 'Close'), ('MDLZ', 'Adj Close'), ('MDLZ', 'Volume'), ('MRO', 'Open'), ('MRO', 'High'), ('MRO', 'Low'), ('MRO', 'Close'), ('MRO', 'Adj Close'), ('MRO', 'Volume'), ('TEL', 'Open'), ('TEL', 'High'), ('TEL', 'Low'), ('TEL', 'Close'), ('TEL', 'Adj Close'), ('TEL', 'Volume'), ('CDW', 'Open'), ('CDW', 'High'), ('CDW', 'Low'), ('CDW', 'Close'), ('CDW', 'Adj Close'), ('CDW', 'Volume'), ('PFG', 'Open'), ('PFG', 'High'), ('PFG', 'Low'), ('PFG', 'Close'), ('PFG', 'Adj Close'), ('PFG', 'Volume'), ('EVRG', 'Open'), ('EVRG', 'High'), ('EVRG', 'Low'), ('EVRG', 'Close'), ('EVRG', 'Adj Close'), ('EVRG', 'Volume'), ('POOL', 'Open'), ('POOL', 'High'), ('POOL', 'Low'), ('POOL', 'Close'), ('POOL', 'Adj Close'), ('POOL', 'Volume'), ('BRO', 'Open'), ('BRO', 'High'), ('BRO', 'Low'), ('BRO', 'Close'), ('BRO', 'Adj Close'), ('BRO', 'Volume'), ('OTIS', 'Open'), ('OTIS', 'High'), ('OTIS', 'Low'), ('OTIS', 'Close'), ('OTIS', 'Adj Close'), ('OTIS', 'Volume'), ('PLD', 'Open'), ('PLD', 'High'), ('PLD', 'Low'), ('PLD', 'Close'), ('PLD', 'Adj Close'), ('PLD', 'Volume'), ('FLT', 'Open'), ('FLT', 'High'), ('FLT', 'Low'), ('FLT', 'Close'), ('FLT', 'Adj Close'), ('FLT', 'Volume'), ('PSA', 'Open'), ('PSA', 'High'), ('PSA', 'Low'), ('PSA', 'Close'), ('PSA', 'Adj Close'), ('PSA', 'Volume'), ('CZR', 'Open'), ('CZR', 'High'), ('CZR', 'Low'), ('CZR', 'Close'), ('CZR', 'Adj Close'), ('CZR', 'Volume'), ('GIS', 'Open'), ('GIS', 'High'), ('GIS', 'Low'), ('GIS', 'Close'), ('GIS', 'Adj Close'), ('GIS', 'Volume'), ('CNP', 'Open'), ('CNP', 'High'), ('CNP', 'Low'), ('CNP', 'Close'), ('CNP', 'Adj Close'), ('CNP', 'Volume'), ('FIS', 'Open'), ('FIS', 'High'), ('FIS', 'Low'), ('FIS', 'Close'), ('FIS', 'Adj Close'), ('FIS', 'Volume'), ('CRM', 'Open'), ('CRM', 'High'), ('CRM', 'Low'), ('CRM', 'Close'), ('CRM', 'Adj Close'), ('CRM', 'Volume'), ('CVX', 'Open'), ('CVX', 'High'), ('CVX', 'Low'), ('CVX', 'Close'), ('CVX', 'Adj Close'), ('CVX', 'Volume'), ('PODD', 'Open'), ('PODD', 'High'), ('PODD', 'Low'), ('PODD', 'Close'), ('PODD', 'Adj Close'), ('PODD', 'Volume'), ('DLR', 'Open'), ('DLR', 'High'), ('DLR', 'Low'), ('DLR', 'Close'), ('DLR', 'Adj Close'), ('DLR', 'Volume'), ('FMC', 'Open'), ('FMC', 'High'), ('FMC', 'Low'), ('FMC', 'Close'), ('FMC', 'Adj Close'), ('FMC', 'Volume'), ('AXP', 'Open'), ('AXP', 'High'), ('AXP', 'Low'), ('AXP', 'Close'), ('AXP', 'Adj Close'), ('AXP', 'Volume'), ('NVR', 'Open'), ('NVR', 'High'), ('NVR', 'Low'), ('NVR', 'Close'), ('NVR', 'Adj Close'), ('NVR', 'Volume'), ('WRK', 'Open'), ('WRK', 'High'), ('WRK', 'Low'), ('WRK', 'Close'), ('WRK', 'Adj Close'), ('WRK', 'Volume'), ('FDX', 'Open'), ('FDX', 'High'), ('FDX', 'Low'), ('FDX', 'Close'), ('FDX', 'Adj Close'), ('FDX', 'Volume'), ('PARA', 'Open'), ('PARA', 'High'), ('PARA', 'Low'), ('PARA', 'Close'), ('PARA', 'Adj Close'), ('PARA', 'Volume'), ('MS', 'Open'), ('MS', 'High'), ('MS', 'Low'), ('MS', 'Close'), ('MS', 'Adj Close'), ('MS', 'Volume'), ('DTE', 'Open'), ('DTE', 'High'), ('DTE', 'Low'), ('DTE', 'Close'), ('DTE', 'Adj Close'), ('DTE', 'Volume'), ('UAL', 'Open'), ('UAL', 'High'), ('UAL', 'Low'), ('UAL', 'Close'), ('UAL', 'Adj Close'), ('UAL', 'Volume'), ('F', 'Open'), ('F', 'High'), ('F', 'Low'), ('F', 'Close'), ('F', 'Adj Close'), ('F', 'Volume'), ('GE', 'Open'), ('GE', 'High'), ('GE', 'Low'), ('GE', 'Close'), ('GE', 'Adj Close'), ('GE', 'Volume'), ('ZION', 'Open'), ('ZION', 'High'), ('ZION', 'Low'), ('ZION', 'Close'), ('ZION', 'Adj Close'), ('ZION', 'Volume'), ('ALGN', 'Open'), ('ALGN', 'High'), ('ALGN', 'Low'), ('ALGN', 'Close'), ('ALGN', 'Adj Close'), ('ALGN', 'Volume'), ('LNT', 'Open'), ('LNT', 'High'), ('LNT', 'Low'), ('LNT', 'Close'), ('LNT', 'Adj Close'), ('LNT', 'Volume'), ('MPC', 'Open'), ('MPC', 'High'), ('MPC', 'Low'), ('MPC', 'Close'), ('MPC', 'Adj Close'), ('MPC', 'Volume'), ('EPAM', 'Open'), ('EPAM', 'High'), ('EPAM', 'Low'), ('EPAM', 'Close'), ('EPAM', 'Adj Close'), ('EPAM', 'Volume'), ('ESS', 'Open'), ('ESS', 'High'), ('ESS', 'Low'), ('ESS', 'Close'), ('ESS', 'Adj Close'), ('ESS', 'Volume'), ('APA', 'Open'), ('APA', 'High'), ('APA', 'Low'), ('APA', 'Close'), ('APA', 'Adj Close'), ('APA', 'Volume'), ('KMI', 'Open'), ('KMI', 'High'), ('KMI', 'Low'), ('KMI', 'Close'), ('KMI', 'Adj Close'), ('KMI', 'Volume'), ('GNRC', 'Open'), ('GNRC', 'High'), ('GNRC', 'Low'), ('GNRC', 'Close'), ('GNRC', 'Adj Close'), ('GNRC', 'Volume'), ('OGN', 'Open'), ('OGN', 'High'), ('OGN', 'Low'), ('OGN', 'Close'), ('OGN', 'Adj Close'), ('OGN', 'Volume'), ('TYL', 'Open'), ('TYL', 'High'), ('TYL', 'Low'), ('TYL', 'Close'), ('TYL', 'Adj Close'), ('TYL', 'Volume'), ('LLY', 'Open'), ('LLY', 'High'), ('LLY', 'Low'), ('LLY', 'Close'), ('LLY', 'Adj Close'), ('LLY', 'Volume'), ('MDT', 'Open'), ('MDT', 'High'), ('MDT', 'Low'), ('MDT', 'Close'), ('MDT', 'Adj Close'), ('MDT', 'Volume'), ('FCX', 'Open'), ('FCX', 'High'), ('FCX', 'Low'), ('FCX', 'Close'), ('FCX', 'Adj Close'), ('FCX', 'Volume'), ('CCL', 'Open'), ('CCL', 'High'), ('CCL', 'Low'), ('CCL', 'Close'), ('CCL', 'Adj Close'), ('CCL', 'Volume'), ('TRV', 'Open'), ('TRV', 'High'), ('TRV', 'Low'), ('TRV', 'Close'), ('TRV', 'Adj Close'), ('TRV', 'Volume'), ('HST', 'Open'), ('HST', 'High'), ('HST', 'Low'), ('HST', 'Close'), ('HST', 'Adj Close'), ('HST', 'Volume'), ('AEP', 'Open'), ('AEP', 'High'), ('AEP', 'Low'), ('AEP', 'Close'), ('AEP', 'Adj Close'), ('AEP', 'Volume'), ('CPT', 'Open'), ('CPT', 'High'), ('CPT', 'Low'), ('CPT', 'Close'), ('CPT', 'Adj Close'), ('CPT', 'Volume'), ('NDSN', 'Open'), ('NDSN', 'High'), ('NDSN', 'Low'), ('NDSN', 'Close'), ('NDSN', 'Adj Close'), ('NDSN', 'Volume'), ('RHI', 'Open'), ('RHI', 'High'), ('RHI', 'Low'), ('RHI', 'Close'), ('RHI', 'Adj Close'), ('RHI', 'Volume'), ('LYB', 'Open'), ('LYB', 'High'), ('LYB', 'Low'), ('LYB', 'Close'), ('LYB', 'Adj Close'), ('LYB', 'Volume'), ('ANSS', 'Open'), ('ANSS', 'High'), ('ANSS', 'Low'), ('ANSS', 'Close'), ('ANSS', 'Adj Close'), ('ANSS', 'Volume'), ('IQV', 'Open'), ('IQV', 'High'), ('IQV', 'Low'), ('IQV', 'Close'), ('IQV', 'Adj Close'), ('IQV', 'Volume'), ('CHD', 'Open'), ('CHD', 'High'), ('CHD', 'Low'), ('CHD', 'Close'), ('CHD', 'Adj Close'), ('CHD', 'Volume'), ('UNP', 'Open'), ('UNP', 'High'), ('UNP', 'Low'), ('UNP', 'Close'), ('UNP', 'Adj Close'), ('UNP', 'Volume'), ('CFG', 'Open'), ('CFG', 'High'), ('CFG', 'Low'), ('CFG', 'Close'), ('CFG', 'Adj Close'), ('CFG', 'Volume'), ('MAA', 'Open'), ('MAA', 'High'), ('MAA', 'Low'), ('MAA', 'Close'), ('MAA', 'Adj Close'), ('MAA', 'Volume'), ('EXC', 'Open'), ('EXC', 'High'), ('EXC', 'Low'), ('EXC', 'Close'), ('EXC', 'Adj Close'), ('EXC', 'Volume'), ('IPG', 'Open'), ('IPG', 'High'), ('IPG', 'Low'), ('IPG', 'Close'), ('IPG', 'Adj Close'), ('IPG', 'Volume'), ('FTV', 'Open'), ('FTV', 'High'), ('FTV', 'Low'), ('FTV', 'Close'), ('FTV', 'Adj Close'), ('FTV', 'Volume'), ('RE', 'Open'), ('RE', 'High'), ('RE', 'Low'), ('RE', 'Close'), ('RE', 'Adj Close'), ('RE', 'Volume'), ('SWK', 'Open'), ('SWK', 'High'), ('SWK', 'Low'), ('SWK', 'Close'), ('SWK', 'Adj Close'), ('SWK', 'Volume'), ('TFC', 'Open'), ('TFC', 'High'), ('TFC', 'Low'), ('TFC', 'Close'), ('TFC', 'Adj Close'), ('TFC', 'Volume'), ('FDS', 'Open'), ('FDS', 'High'), ('FDS', 'Low'), ('FDS', 'Close'), ('FDS', 'Adj Close'), ('FDS', 'Volume'), ('KMB', 'Open'), ('KMB', 'High'), ('KMB', 'Low'), ('KMB', 'Close'), ('KMB', 'Adj Close'), ('KMB', 'Volume'), ('CSCO', 'Open'), ('CSCO', 'High'), ('CSCO', 'Low'), ('CSCO', 'Close'), ('CSCO', 'Adj Close'), ('CSCO', 'Volume'), ('CBRE', 'Open'), ('CBRE', 'High'), ('CBRE', 'Low'), ('CBRE', 'Close'), ('CBRE', 'Adj Close'), ('CBRE', 'Volume'), ('CTLT', 'Open'), ('CTLT', 'High'), ('CTLT', 'Low'), ('CTLT', 'Close'), ('CTLT', 'Adj Close'), ('CTLT', 'Volume'), ('EXPD', 'Open'), ('EXPD', 'High'), ('EXPD', 'Low'), ('EXPD', 'Close'), ('EXPD', 'Adj Close'), ('EXPD', 'Volume'), ('FANG', 'Open'), ('FANG', 'High'), ('FANG', 'Low'), ('FANG', 'Close'), ('FANG', 'Adj Close'), ('FANG', 'Volume'), ('CMCSA', 'Open'), ('CMCSA', 'High'), ('CMCSA', 'Low'), ('CMCSA', 'Close'), ('CMCSA', 'Adj Close'), ('CMCSA', 'Volume'), ('PRU', 'Open'), ('PRU', 'High'), ('PRU', 'Low'), ('PRU', 'Close'), ('PRU', 'Adj Close'), ('PRU', 'Volume'), ('LW', 'Open'), ('LW', 'High'), ('LW', 'Low'), ('LW', 'Close'), ('LW', 'Adj Close'), ('LW', 'Volume'), ('ECL', 'Open'), ('ECL', 'High'), ('ECL', 'Low'), ('ECL', 'Close'), ('ECL', 'Adj Close'), ('ECL', 'Volume'), ('AMGN', 'Open'), ('AMGN', 'High'), ('AMGN', 'Low'), ('AMGN', 'Close'), ('AMGN', 'Adj Close'), ('AMGN', 'Volume'), ('BIIB', 'Open'), ('BIIB', 'High'), ('BIIB', 'Low'), ('BIIB', 'Close'), ('BIIB', 'Adj Close'), ('BIIB', 'Volume'), ('BLK', 'Open'), ('BLK', 'High'), ('BLK', 'Low'), ('BLK', 'Close'), ('BLK', 'Adj Close'), ('BLK', 'Volume'), ('BG', 'Open'), ('BG', 'High'), ('BG', 'Low'), ('BG', 'Close'), ('BG', 'Adj Close'), ('BG', 'Volume'), ('EXR', 'Open'), ('EXR', 'High'), ('EXR', 'Low'), ('EXR', 'Close'), ('EXR', 'Adj Close'), ('EXR', 'Volume'), ('DGX', 'Open'), ('DGX', 'High'), ('DGX', 'Low'), ('DGX', 'Close'), ('DGX', 'Adj Close'), ('DGX', 'Volume'), ('MRNA', 'Open'), ('MRNA', 'High'), ('MRNA', 'Low'), ('MRNA', 'Close'), ('MRNA', 'Adj Close'), ('MRNA', 'Volume'), ('ABC', 'Open'), ('ABC', 'High'), ('ABC', 'Low'), ('ABC', 'Close'), ('ABC', 'Adj Close'), ('ABC', 'Volume'), ('PSX', 'Open'), ('PSX', 'High'), ('PSX', 'Low'), ('PSX', 'Close'), ('PSX', 'Adj Close'), ('PSX', 'Volume'), ('NSC', 'Open'), ('NSC', 'High'), ('NSC', 'Low'), ('NSC', 'Close'), ('NSC', 'Adj Close'), ('NSC', 'Volume'), ('MSI', 'Open'), ('MSI', 'High'), ('MSI', 'Low'), ('MSI', 'Close'), ('MSI', 'Adj Close'), ('MSI', 'Volume'), ('CTRA', 'Open'), ('CTRA', 'High'), ('CTRA', 'Low'), ('CTRA', 'Close'), ('CTRA', 'Adj Close'), ('CTRA', 'Volume'), ('WELL', 'Open'), ('WELL', 'High'), ('WELL', 'Low'), ('WELL', 'Close'), ('WELL', 'Adj Close'), ('WELL', 'Volume'), ('RJF', 'Open'), ('RJF', 'High'), ('RJF', 'Low'), ('RJF', 'Close'), ('RJF', 'Adj Close'), ('RJF', 'Volume'), ('ABT', 'Open'), ('ABT', 'High'), ('ABT', 'Low'), ('ABT', 'Close'), ('ABT', 'Adj Close'), ('ABT', 'Volume'), ('HAS', 'Open'), ('HAS', 'High'), ('HAS', 'Low'), ('HAS', 'Close'), ('HAS', 'Adj Close'), ('HAS', 'Volume'), ('WAB', 'Open'), ('WAB', 'High'), ('WAB', 'Low'), ('WAB', 'Close'), ('WAB', 'Adj Close'), ('WAB', 'Volume'), ('CMA', 'Open'), ('CMA', 'High'), ('CMA', 'Low'), ('CMA', 'Close'), ('CMA', 'Adj Close'), ('CMA', 'Volume'), ('MET', 'Open'), ('MET', 'High'), ('MET', 'Low'), ('MET', 'Close'), ('MET', 'Adj Close'), ('MET', 'Volume'), ('AVB', 'Open'), ('AVB', 'High'), ('AVB', 'Low'), ('AVB', 'Close'), ('AVB', 'Adj Close'), ('AVB', 'Volume'), ('AVGO', 'Open'), ('AVGO', 'High'), ('AVGO', 'Low'), ('AVGO', 'Close'), ('AVGO', 'Adj Close'), ('AVGO', 'Volume'), ('KIM', 'Open'), ('KIM', 'High'), ('KIM', 'Low'), ('KIM', 'Close'), ('KIM', 'Adj Close'), ('KIM', 'Volume'), ('ACGL', 'Open'), ('ACGL', 'High'), ('ACGL', 'Low'), ('ACGL', 'Close'), ('ACGL', 'Adj Close'), ('ACGL', 'Volume'), ('HAL', 'Open'), ('HAL', 'High'), ('HAL', 'Low'), ('HAL', 'Close'), ('HAL', 'Adj Close'), ('HAL', 'Volume'), ('LYV', 'Open'), ('LYV', 'High'), ('LYV', 'Low'), ('LYV', 'Close'), ('LYV', 'Adj Close'), ('LYV', 'Volume'), ('C', 'Open'), ('C', 'High'), ('C', 'Low'), ('C', 'Close'), ('C', 'Adj Close'), ('C', 'Volume'), ('AON', 'Open'), ('AON', 'High'), ('AON', 'Low'), ('AON', 'Close'), ('AON', 'Adj Close'), ('AON', 'Volume'), ('ROST', 'Open'), ('ROST', 'High'), ('ROST', 'Low'), ('ROST', 'Close'), ('ROST', 'Adj Close'), ('ROST', 'Volume'), ('GWW', 'Open'), ('GWW', 'High'), ('GWW', 'Low'), ('GWW', 'Close'), ('GWW', 'Adj Close'), ('GWW', 'Volume'), ('EXPE', 'Open'), ('EXPE', 'High'), ('EXPE', 'Low'), ('EXPE', 'Close'), ('EXPE', 'Adj Close'), ('EXPE', 'Volume'), ('ALLE', 'Open'), ('ALLE', 'High'), ('ALLE', 'Low'), ('ALLE', 'Close'), ('ALLE', 'Adj Close'), ('ALLE', 'Volume'), ('SBUX', 'Open'), ('SBUX', 'High'), ('SBUX', 'Low'), ('SBUX', 'Close'), ('SBUX', 'Adj Close'), ('SBUX', 'Volume'), ('WEC', 'Open'), ('WEC', 'High'), ('WEC', 'Low'), ('WEC', 'Close'), ('WEC', 'Adj Close'), ('WEC', 'Volume'), ('STX', 'Open'), ('STX', 'High'), ('STX', 'Low'), ('STX', 'Close'), ('STX', 'Adj Close'), ('STX', 'Volume'), ('STT', 'Open'), ('STT', 'High'), ('STT', 'Low'), ('STT', 'Close'), ('STT', 'Adj Close'), ('STT', 'Volume'), ('CME', 'Open'), ('CME', 'High'), ('CME', 'Low'), ('CME', 'Close'), ('CME', 'Adj Close'), ('CME', 'Volume'), ('NWS', 'Open'), ('NWS', 'High'), ('NWS', 'Low'), ('NWS', 'Close'), ('NWS', 'Adj Close'), ('NWS', 'Volume'), ('MCD', 'Open'), ('MCD', 'High'), ('MCD', 'Low'), ('MCD', 'Close'), ('MCD', 'Adj Close'), ('MCD', 'Volume'), ('UPS', 'Open'), ('UPS', 'High'), ('UPS', 'Low'), ('UPS', 'Close'), ('UPS', 'Adj Close'), ('UPS', 'Volume'), ('YUM', 'Open'), ('YUM', 'High'), ('YUM', 'Low'), ('YUM', 'Close'), ('YUM', 'Adj Close'), ('YUM', 'Volume'), ('NOC', 'Open'), ('NOC', 'High'), ('NOC', 'Low'), ('NOC', 'Close'), ('NOC', 'Adj Close'), ('NOC', 'Volume'), ('INTU', 'Open'), ('INTU', 'High'), ('INTU', 'Low'), ('INTU', 'Close'), ('INTU', 'Adj Close'), ('INTU', 'Volume'), ('IR', 'Open'), ('IR', 'High'), ('IR', 'Low'), ('IR', 'Close'), ('IR', 'Adj Close'), ('IR', 'Volume'), ('AMD', 'Open'), ('AMD', 'High'), ('AMD', 'Low'), ('AMD', 'Close'), ('AMD', 'Adj Close'), ('AMD', 'Volume'), ('XOM', 'Open'), ('XOM', 'High'), ('XOM', 'Low'), ('XOM', 'Close'), ('XOM', 'Adj Close'), ('XOM', 'Volume'), ('VRTX', 'Open'), ('VRTX', 'High'), ('VRTX', 'Low'), ('VRTX', 'Close'), ('VRTX', 'Adj Close'), ('VRTX', 'Volume'), ('ABBV', 'Open'), ('ABBV', 'High'), ('ABBV', 'Low'), ('ABBV', 'Close'), ('ABBV', 'Adj Close'), ('ABBV', 'Volume'), ('JKHY', 'Open'), ('JKHY', 'High'), ('JKHY', 'Low'), ('JKHY', 'Close'), ('JKHY', 'Adj Close'), ('JKHY', 'Volume'), ('EMN', 'Open'), ('EMN', 'High'), ('EMN', 'Low'), ('EMN', 'Close'), ('EMN', 'Adj Close'), ('EMN', 'Volume'), ('LIN', 'Open'), ('LIN', 'High'), ('LIN', 'Low'), ('LIN', 'Close'), ('LIN', 'Adj Close'), ('LIN', 'Volume'), ('OKE', 'Open'), ('OKE', 'High'), ('OKE', 'Low'), ('OKE', 'Close'), ('OKE', 'Adj Close'), ('OKE', 'Volume'), ('PWR', 'Open'), ('PWR', 'High'), ('PWR', 'Low'), ('PWR', 'Close'), ('PWR', 'Adj Close'), ('PWR', 'Volume'), ('TGT', 'Open'), ('TGT', 'High'), ('TGT', 'Low'), ('TGT', 'Close'), ('TGT', 'Adj Close'), ('TGT', 'Volume'), ('COF', 'Open'), ('COF', 'High'), ('COF', 'Low'), ('COF', 'Close'), ('COF', 'Adj Close'), ('COF', 'Volume'), ('KHC', 'Open'), ('KHC', 'High'), ('KHC', 'Low'), ('KHC', 'Close'), ('KHC', 'Adj Close'), ('KHC', 'Volume'), ('VFC', 'Open'), ('VFC', 'High'), ('VFC', 'Low'), ('VFC', 'Close'), ('VFC', 'Adj Close'), ('VFC', 'Volume'), ('NUE', 'Open'), ('NUE', 'High'), ('NUE', 'Low'), ('NUE', 'Close'), ('NUE', 'Adj Close'), ('NUE', 'Volume'), ('FFIV', 'Open'), ('FFIV', 'High'), ('FFIV', 'Low'), ('FFIV', 'Close'), ('FFIV', 'Adj Close'), ('FFIV', 'Volume'), ('FE', 'Open'), ('FE', 'High'), ('FE', 'Low'), ('FE', 'Close'), ('FE', 'Adj Close'), ('FE', 'Volume'), ('XYL', 'Open'), ('XYL', 'High'), ('XYL', 'Low'), ('XYL', 'Close'), ('XYL', 'Adj Close'), ('XYL', 'Volume'), ('JPM', 'Open'), ('JPM', 'High'), ('JPM', 'Low'), ('JPM', 'Close'), ('JPM', 'Adj Close'), ('JPM', 'Volume'), ('CTVA', 'Open'), ('CTVA', 'High'), ('CTVA', 'Low'), ('CTVA', 'Close'), ('CTVA', 'Adj Close'), ('CTVA', 'Volume'), ('SEE', 'Open'), ('SEE', 'High'), ('SEE', 'Low'), ('SEE', 'Close'), ('SEE', 'Adj Close'), ('SEE', 'Volume'), ('EQIX', 'Open'), ('EQIX', 'High'), ('EQIX', 'Low'), ('EQIX', 'Close'), ('EQIX', 'Adj Close'), ('EQIX', 'Volume'), ('LRCX', 'Open'), ('LRCX', 'High'), ('LRCX', 'Low'), ('LRCX', 'Close'), ('LRCX', 'Adj Close'), ('LRCX', 'Volume'), ('GL', 'Open'), ('GL', 'High'), ('GL', 'Low'), ('GL', 'Close'), ('GL', 'Adj Close'), ('GL', 'Volume'), ('EBAY', 'Open'), ('EBAY', 'High'), ('EBAY', 'Low'), ('EBAY', 'Close'), ('EBAY', 'Adj Close'), ('EBAY', 'Volume'), ('DHI', 'Open'), ('DHI', 'High'), ('DHI', 'Low'), ('DHI', 'Close'), ('DHI', 'Adj Close'), ('DHI', 'Volume'), ('GPC', 'Open'), ('GPC', 'High'), ('GPC', 'Low'), ('GPC', 'Close'), ('GPC', 'Adj Close'), ('GPC', 'Volume'), ('BAC', 'Open'), ('BAC', 'High'), ('BAC', 'Low'), ('BAC', 'Close'), ('BAC', 'Adj Close'), ('BAC', 'Volume'), ('TMUS', 'Open'), ('TMUS', 'High'), ('TMUS', 'Low'), ('TMUS', 'Close'), ('TMUS', 'Adj Close'), ('TMUS', 'Volume'), ('NEM', 'Open'), ('NEM', 'High'), ('NEM', 'Low'), ('NEM', 'Close'), ('NEM', 'Adj Close'), ('NEM', 'Volume'), ('GM', 'Open'), ('GM', 'High'), ('GM', 'Low'), ('GM', 'Close'), ('GM', 'Adj Close'), ('GM', 'Volume'), ('WYNN', 'Open'), ('WYNN', 'High'), ('WYNN', 'Low'), ('WYNN', 'Close'), ('WYNN', 'Adj Close'), ('WYNN', 'Volume'), ('EOG', 'Open'), ('EOG', 'High'), ('EOG', 'Low'), ('EOG', 'Close'), ('EOG', 'Adj Close'), ('EOG', 'Volume'), ('COST', 'Open'), ('COST', 'High'), ('COST', 'Low'), ('COST', 'Close'), ('COST', 'Adj Close'), ('COST', 'Volume'), ('NFLX', 'Open'), ('NFLX', 'High'), ('NFLX', 'Low'), ('NFLX', 'Close'), ('NFLX', 'Adj Close'), ('NFLX', 'Volume'), ('ETR', 'Open'), ('ETR', 'High'), ('ETR', 'Low'), ('ETR', 'Close'), ('ETR', 'Adj Close'), ('ETR', 'Volume'), ('D', 'Open'), ('D', 'High'), ('D', 'Low'), ('D', 'Close'), ('D', 'Adj Close'), ('D', 'Volume'), ('AME', 'Open'), ('AME', 'High'), ('AME', 'Low'), ('AME', 'Close'), ('AME', 'Adj Close'), ('AME', 'Volume'), ('ILMN', 'Open'), ('ILMN', 'High'), ('ILMN', 'Low'), ('ILMN', 'Close'), ('ILMN', 'Adj Close'), ('ILMN', 'Volume'), ('ACN', 'Open'), ('ACN', 'High'), ('ACN', 'Low'), ('ACN', 'Close'), ('ACN', 'Adj Close'), ('ACN', 'Volume'), ('ALK', 'Open'), ('ALK', 'High'), ('ALK', 'Low'), ('ALK', 'Close'), ('ALK', 'Adj Close'), ('ALK', 'Volume'), ('SCHW', 'Open'), ('SCHW', 'High'), ('SCHW', 'Low'), ('SCHW', 'Close'), ('SCHW', 'Adj Close'), ('SCHW', 'Volume'), ('GD', 'Open'), ('GD', 'High'), ('GD', 'Low'), ('GD', 'Close'), ('GD', 'Adj Close'), ('GD', 'Volume'), ('AMZN', 'Open'), ('AMZN', 'High'), ('AMZN', 'Low'), ('AMZN', 'Close'), ('AMZN', 'Adj Close'), ('AMZN', 'Volume'), ('PM', 'Open'), ('PM', 'High'), ('PM', 'Low'), ('PM', 'Close'), ('PM', 'Adj Close'), ('PM', 'Volume'), ('CLX', 'Open'), ('CLX', 'High'), ('CLX', 'Low'), ('CLX', 'Close'), ('CLX', 'Adj Close'), ('CLX', 'Volume'), ('DXCM', 'Open'), ('DXCM', 'High'), ('DXCM', 'Low'), ('DXCM', 'Close'), ('DXCM', 'Adj Close'), ('DXCM', 'Volume'), ('CSGP', 'Open'), ('CSGP', 'High'), ('CSGP', 'Low'), ('CSGP', 'Close'), ('CSGP', 'Adj Close'), ('CSGP', 'Volume'), ('EFX', 'Open'), ('EFX', 'High'), ('EFX', 'Low'), ('EFX', 'Close'), ('EFX', 'Adj Close'), ('EFX', 'Volume'), ('NTRS', 'Open'), ('NTRS', 'High'), ('NTRS', 'Low'), ('NTRS', 'Close'), ('NTRS', 'Adj Close'), ('NTRS', 'Volume'), ('INTC', 'Open'), ('INTC', 'High'), ('INTC', 'Low'), ('INTC', 'Close'), ('INTC', 'Adj Close'), ('INTC', 'Volume'), ('MAS', 'Open'), ('MAS', 'High'), ('MAS', 'Low'), ('MAS', 'Close'), ('MAS', 'Adj Close'), ('MAS', 'Volume'), ('SPGI', 'Open'), ('SPGI', 'High'), ('SPGI', 'Low'), ('SPGI', 'Close'), ('SPGI', 'Adj Close'), ('SPGI', 'Volume'), ('HSIC', 'Open'), ('HSIC', 'High'), ('HSIC', 'Low'), ('HSIC', 'Close'), ('HSIC', 'Adj Close'), ('HSIC', 'Volume'), ('ODFL', 'Open'), ('ODFL', 'High'), ('ODFL', 'Low'), ('ODFL', 'Close'), ('ODFL', 'Adj Close'), ('ODFL', 'Volume'), ('BKR', 'Open'), ('BKR', 'High'), ('BKR', 'Low'), ('BKR', 'Close'), ('BKR', 'Adj Close'), ('BKR', 'Volume'), ('BK', 'Open'), ('BK', 'High'), ('BK', 'Low'), ('BK', 'Close'), ('BK', 'Adj Close'), ('BK', 'Volume'), ('MMM', 'VEMA12'), ('AOS', 'VEMA12'), ('ABT', 'VEMA12'), ('ABBV', 'VEMA12'), ('ACN', 'VEMA12'), ('ATVI', 'VEMA12'), ('ADM', 'VEMA12'), ('ADBE', 'VEMA12'), ('ADP', 'VEMA12'), ('AAP', 'VEMA12'), ('AES', 'VEMA12'), ('AFL', 'VEMA12'), ('A', 'VEMA12'), ('APD', 'VEMA12'), ('AKAM', 'VEMA12'), ('ALK', 'VEMA12'), ('ALB', 'VEMA12'), ('ARE', 'VEMA12'), ('ALGN', 'VEMA12'), ('ALLE', 'VEMA12'), ('LNT', 'VEMA12'), ('ALL', 'VEMA12'), ('GOOGL', 'VEMA12'), ('GOOG', 'VEMA12'), ('MO', 'VEMA12'), ('AMZN', 'VEMA12'), ('AMCR', 'VEMA12'), ('AMD', 'VEMA12'), ('AEE', 'VEMA12'), ('AAL', 'VEMA12'), ('AEP', 'VEMA12'), ('AXP', 'VEMA12'), ('AIG', 'VEMA12'), ('AMT', 'VEMA12'), ('AWK', 'VEMA12'), ('AMP', 'VEMA12'), ('ABC', 'VEMA12'), ('AME', 'VEMA12'), ('AMGN', 'VEMA12'), ('APH', 'VEMA12'), ('ADI', 'VEMA12'), ('ANSS', 'VEMA12'), ('AON', 'VEMA12'), ('APA', 'VEMA12'), ('AAPL', 'VEMA12'), ('AMAT', 'VEMA12'), ('APTV', 'VEMA12'), ('ACGL', 'VEMA12'), ('ANET', 'VEMA12'), ('AJG', 'VEMA12'), ('AIZ', 'VEMA12'), ('T', 'VEMA12'), ('ATO', 'VEMA12'), ('ADSK', 'VEMA12'), ('AZO', 'VEMA12'), ('AVB', 'VEMA12'), ('AVY', 'VEMA12'), ('BKR', 'VEMA12'), ('BALL', 'VEMA12'), ('BAC', 'VEMA12'), ('BBWI', 'VEMA12'), ('BAX', 'VEMA12'), ('BDX', 'VEMA12'), ('WRB', 'VEMA12'), ('BBY', 'VEMA12'), ('BIO', 'VEMA12'), ('TECH', 'VEMA12'), ('BIIB', 'VEMA12'), ('BLK', 'VEMA12'), ('BK', 'VEMA12'), ('BA', 'VEMA12'), ('BKNG', 'VEMA12'), ('BWA', 'VEMA12'), ('BXP', 'VEMA12'), ('BSX', 'VEMA12'), ('BMY', 'VEMA12'), ('AVGO', 'VEMA12'), ('BR', 'VEMA12'), ('BRO', 'VEMA12'), ('BG', 'VEMA12'), ('CHRW', 'VEMA12'), ('CDNS', 'VEMA12'), ('CZR', 'VEMA12'), ('CPT', 'VEMA12'), ('CPB', 'VEMA12'), ('COF', 'VEMA12'), ('CAH', 'VEMA12'), ('KMX', 'VEMA12'), ('CCL', 'VEMA12'), ('CARR', 'VEMA12'), ('CTLT', 'VEMA12'), ('CAT', 'VEMA12'), ('CBOE', 'VEMA12'), ('CBRE', 'VEMA12'), ('CDW', 'VEMA12'), ('CE', 'VEMA12'), ('CNC', 'VEMA12'), ('CNP', 'VEMA12'), ('CDAY', 'VEMA12'), ('CF', 'VEMA12'), ('CRL', 'VEMA12'), ('SCHW', 'VEMA12'), ('CHTR', 'VEMA12'), ('CVX', 'VEMA12'), ('CMG', 'VEMA12'), ('CB', 'VEMA12'), ('CHD', 'VEMA12'), ('CI', 'VEMA12'), ('CINF', 'VEMA12'), ('CTAS', 'VEMA12'), ('CSCO', 'VEMA12'), ('C', 'VEMA12'), ('CFG', 'VEMA12'), ('CLX', 'VEMA12'), ('CME', 'VEMA12'), ('CMS', 'VEMA12'), ('KO', 'VEMA12'), ('CTSH', 'VEMA12'), ('CL', 'VEMA12'), ('CMCSA', 'VEMA12'), ('CMA', 'VEMA12'), ('CAG', 'VEMA12'), ('COP', 'VEMA12'), ('ED', 'VEMA12'), ('STZ', 'VEMA12'), ('CEG', 'VEMA12'), ('COO', 'VEMA12'), ('CPRT', 'VEMA12'), ('GLW', 'VEMA12'), ('CTVA', 'VEMA12'), ('CSGP', 'VEMA12'), ('COST', 'VEMA12'), ('CTRA', 'VEMA12'), ('CCI', 'VEMA12'), ('CSX', 'VEMA12'), ('CMI', 'VEMA12'), ('CVS', 'VEMA12'), ('DHI', 'VEMA12'), ('DHR', 'VEMA12'), ('DRI', 'VEMA12'), ('DVA', 'VEMA12'), ('DE', 'VEMA12'), ('DAL', 'VEMA12'), ('XRAY', 'VEMA12'), ('DVN', 'VEMA12'), ('DXCM', 'VEMA12'), ('FANG', 'VEMA12'), ('DLR', 'VEMA12'), ('DFS', 'VEMA12'), ('DISH', 'VEMA12'), ('DIS', 'VEMA12'), ('DG', 'VEMA12'), ('DLTR', 'VEMA12'), ('D', 'VEMA12'), ('DPZ', 'VEMA12'), ('DOV', 'VEMA12'), ('DOW', 'VEMA12'), ('DTE', 'VEMA12'), ('DUK', 'VEMA12'), ('DD', 'VEMA12'), ('DXC', 'VEMA12'), ('EMN', 'VEMA12'), ('ETN', 'VEMA12'), ('EBAY', 'VEMA12'), ('ECL', 'VEMA12'), ('EIX', 'VEMA12'), ('EW', 'VEMA12'), ('EA', 'VEMA12'), ('ELV', 'VEMA12'), ('LLY', 'VEMA12'), ('EMR', 'VEMA12'), ('ENPH', 'VEMA12'), ('ETR', 'VEMA12'), ('EOG', 'VEMA12'), ('EPAM', 'VEMA12'), ('EQT', 'VEMA12'), ('EFX', 'VEMA12'), ('EQIX', 'VEMA12'), ('EQR', 'VEMA12'), ('ESS', 'VEMA12'), ('EL', 'VEMA12'), ('ETSY', 'VEMA12'), ('RE', 'VEMA12'), ('EVRG', 'VEMA12'), ('ES', 'VEMA12'), ('EXC', 'VEMA12'), ('EXPE', 'VEMA12'), ('EXPD', 'VEMA12'), ('EXR', 'VEMA12'), ('XOM', 'VEMA12'), ('FFIV', 'VEMA12'), ('FDS', 'VEMA12'), ('FICO', 'VEMA12'), ('FAST', 'VEMA12'), ('FRT', 'VEMA12'), ('FDX', 'VEMA12'), ('FITB', 'VEMA12'), ('FRC', 'VEMA12'), ('FSLR', 'VEMA12'), ('FE', 'VEMA12'), ('FIS', 'VEMA12'), ('FISV', 'VEMA12'), ('FLT', 'VEMA12'), ('FMC', 'VEMA12'), ('F', 'VEMA12'), ('FTNT', 'VEMA12'), ('FTV', 'VEMA12'), ('FOXA', 'VEMA12'), ('FOX', 'VEMA12'), ('BEN', 'VEMA12'), ('FCX', 'VEMA12'), ('GRMN', 'VEMA12'), ('IT', 'VEMA12'), ('GEN', 'VEMA12'), ('GNRC', 'VEMA12'), ('GD', 'VEMA12'), ('GE', 'VEMA12'), ('GIS', 'VEMA12'), ('GM', 'VEMA12'), ('GPC', 'VEMA12'), ('GILD', 'VEMA12'), ('GL', 'VEMA12'), ('GPN', 'VEMA12'), ('GS', 'VEMA12'), ('HAL', 'VEMA12'), ('HIG', 'VEMA12'), ('HAS', 'VEMA12'), ('HCA', 'VEMA12'), ('PEAK', 'VEMA12'), ('HSIC', 'VEMA12'), ('HSY', 'VEMA12'), ('HES', 'VEMA12'), ('HPE', 'VEMA12'), ('HLT', 'VEMA12'), ('HOLX', 'VEMA12'), ('HD', 'VEMA12'), ('HON', 'VEMA12'), ('HRL', 'VEMA12'), ('HST', 'VEMA12'), ('HWM', 'VEMA12'), ('HPQ', 'VEMA12'), ('HUM', 'VEMA12'), ('HBAN', 'VEMA12'), ('HII', 'VEMA12'), ('IBM', 'VEMA12'), ('IEX', 'VEMA12'), ('IDXX', 'VEMA12'), ('ITW', 'VEMA12'), ('ILMN', 'VEMA12'), ('INCY', 'VEMA12'), ('IR', 'VEMA12'), ('PODD', 'VEMA12'), ('INTC', 'VEMA12'), ('ICE', 'VEMA12'), ('IFF', 'VEMA12'), ('IP', 'VEMA12'), ('IPG', 'VEMA12'), ('INTU', 'VEMA12'), ('ISRG', 'VEMA12'), ('IVZ', 'VEMA12'), ('INVH', 'VEMA12'), ('IQV', 'VEMA12'), ('IRM', 'VEMA12'), ('JBHT', 'VEMA12'), ('JKHY', 'VEMA12'), ('J', 'VEMA12'), ('JNJ', 'VEMA12'), ('JCI', 'VEMA12'), ('JPM', 'VEMA12'), ('JNPR', 'VEMA12'), ('K', 'VEMA12'), ('KDP', 'VEMA12'), ('KEY', 'VEMA12'), ('KEYS', 'VEMA12'), ('KMB', 'VEMA12'), ('KIM', 'VEMA12'), ('KMI', 'VEMA12'), ('KLAC', 'VEMA12'), ('KHC', 'VEMA12'), ('KR', 'VEMA12'), ('LHX', 'VEMA12'), ('LH', 'VEMA12'), ('LRCX', 'VEMA12'), ('LW', 'VEMA12'), ('LVS', 'VEMA12'), ('LDOS', 'VEMA12'), ('LEN', 'VEMA12'), ('LNC', 'VEMA12'), ('LIN', 'VEMA12'), ('LYV', 'VEMA12'), ('LKQ', 'VEMA12'), ('LMT', 'VEMA12'), ('L', 'VEMA12'), ('LOW', 'VEMA12'), ('LYB', 'VEMA12'), ('MTB', 'VEMA12'), ('MRO', 'VEMA12'), ('MPC', 'VEMA12'), ('MKTX', 'VEMA12'), ('MAR', 'VEMA12'), ('MMC', 'VEMA12'), ('MLM', 'VEMA12'), ('MAS', 'VEMA12'), ('MA', 'VEMA12'), ('MTCH', 'VEMA12'), ('MKC', 'VEMA12'), ('MCD', 'VEMA12'), ('MCK', 'VEMA12'), ('MDT', 'VEMA12'), ('MRK', 'VEMA12'), ('META', 'VEMA12'), ('MET', 'VEMA12'), ('MTD', 'VEMA12'), ('MGM', 'VEMA12'), ('MCHP', 'VEMA12'), ('MU', 'VEMA12'), ('MSFT', 'VEMA12'), ('MAA', 'VEMA12'), ('MRNA', 'VEMA12'), ('MHK', 'VEMA12'), ('MOH', 'VEMA12'), ('TAP', 'VEMA12'), ('MDLZ', 'VEMA12'), ('MPWR', 'VEMA12'), ('MNST', 'VEMA12'), ('MCO', 'VEMA12'), ('MS', 'VEMA12'), ('MOS', 'VEMA12'), ('MSI', 'VEMA12'), ('MSCI', 'VEMA12'), ('NDAQ', 'VEMA12'), ('NTAP', 'VEMA12'), ('NFLX', 'VEMA12'), ('NWL', 'VEMA12'), ('NEM', 'VEMA12'), ('NWSA', 'VEMA12'), ('NWS', 'VEMA12'), ('NEE', 'VEMA12'), ('NKE', 'VEMA12'), ('NI', 'VEMA12'), ('NDSN', 'VEMA12'), ('NSC', 'VEMA12'), ('NTRS', 'VEMA12'), ('NOC', 'VEMA12'), ('NCLH', 'VEMA12'), ('NRG', 'VEMA12'), ('NUE', 'VEMA12'), ('NVDA', 'VEMA12'), ('NVR', 'VEMA12'), ('NXPI', 'VEMA12'), ('ORLY', 'VEMA12'), ('OXY', 'VEMA12'), ('ODFL', 'VEMA12'), ('OMC', 'VEMA12'), ('ON', 'VEMA12'), ('OKE', 'VEMA12'), ('ORCL', 'VEMA12'), ('OGN', 'VEMA12'), ('OTIS', 'VEMA12'), ('PCAR', 'VEMA12'), ('PKG', 'VEMA12'), ('PARA', 'VEMA12'), ('PH', 'VEMA12'), ('PAYX', 'VEMA12'), ('PAYC', 'VEMA12'), ('PYPL', 'VEMA12'), ('PNR', 'VEMA12'), ('PEP', 'VEMA12'), ('PKI', 'VEMA12'), ('PFE', 'VEMA12'), ('PCG', 'VEMA12'), ('PM', 'VEMA12'), ('PSX', 'VEMA12'), ('PNW', 'VEMA12'), ('PXD', 'VEMA12'), ('PNC', 'VEMA12'), ('POOL', 'VEMA12'), ('PPG', 'VEMA12'), ('PPL', 'VEMA12'), ('PFG', 'VEMA12'), ('PG', 'VEMA12'), ('PGR', 'VEMA12'), ('PLD', 'VEMA12'), ('PRU', 'VEMA12'), ('PEG', 'VEMA12'), ('PTC', 'VEMA12'), ('PSA', 'VEMA12'), ('PHM', 'VEMA12'), ('QRVO', 'VEMA12'), ('PWR', 'VEMA12'), ('QCOM', 'VEMA12'), ('DGX', 'VEMA12'), ('RL', 'VEMA12'), ('RJF', 'VEMA12'), ('RTX', 'VEMA12'), ('O', 'VEMA12'), ('REG', 'VEMA12'), ('REGN', 'VEMA12'), ('RF', 'VEMA12'), ('RSG', 'VEMA12'), ('RMD', 'VEMA12'), ('RHI', 'VEMA12'), ('ROK', 'VEMA12'), ('ROL', 'VEMA12'), ('ROP', 'VEMA12'), ('ROST', 'VEMA12'), ('RCL', 'VEMA12'), ('SPGI', 'VEMA12'), ('CRM', 'VEMA12'), ('SBAC', 'VEMA12'), ('SLB', 'VEMA12'), ('STX', 'VEMA12'), ('SEE', 'VEMA12'), ('SRE', 'VEMA12'), ('NOW', 'VEMA12'), ('SHW', 'VEMA12'), ('SPG', 'VEMA12'), ('SWKS', 'VEMA12'), ('SJM', 'VEMA12'), ('SNA', 'VEMA12'), ('SEDG', 'VEMA12'), ('SO', 'VEMA12'), ('LUV', 'VEMA12'), ('SWK', 'VEMA12'), ('SBUX', 'VEMA12'), ('STT', 'VEMA12'), ('STLD', 'VEMA12'), ('STE', 'VEMA12'), ('SYK', 'VEMA12'), ('SYF', 'VEMA12'), ('SNPS', 'VEMA12'), ('SYY', 'VEMA12'), ('TMUS', 'VEMA12'), ('TROW', 'VEMA12'), ('TTWO', 'VEMA12'), ('TPR', 'VEMA12'), ('TRGP', 'VEMA12'), ('TGT', 'VEMA12'), ('TEL', 'VEMA12'), ('TDY', 'VEMA12'), ('TFX', 'VEMA12'), ('TER', 'VEMA12'), ('TSLA', 'VEMA12'), ('TXN', 'VEMA12'), ('TXT', 'VEMA12'), ('TMO', 'VEMA12'), ('TJX', 'VEMA12'), ('TSCO', 'VEMA12'), ('TT', 'VEMA12'), ('TDG', 'VEMA12'), ('TRV', 'VEMA12'), ('TRMB', 'VEMA12'), ('TFC', 'VEMA12'), ('TYL', 'VEMA12'), ('TSN', 'VEMA12'), ('USB', 'VEMA12'), ('UDR', 'VEMA12'), ('ULTA', 'VEMA12'), ('UNP', 'VEMA12'), ('UAL', 'VEMA12'), ('UPS', 'VEMA12'), ('URI', 'VEMA12'), ('UNH', 'VEMA12'), ('UHS', 'VEMA12'), ('VLO', 'VEMA12'), ('VTR', 'VEMA12'), ('VRSN', 'VEMA12'), ('VRSK', 'VEMA12'), ('VZ', 'VEMA12'), ('VRTX', 'VEMA12'), ('VFC', 'VEMA12'), ('VTRS', 'VEMA12'), ('VICI', 'VEMA12'), ('V', 'VEMA12'), ('VMC', 'VEMA12'), ('WAB', 'VEMA12'), ('WBA', 'VEMA12'), ('WMT', 'VEMA12'), ('WBD', 'VEMA12'), ('WM', 'VEMA12'), ('WAT', 'VEMA12'), ('WEC', 'VEMA12'), ('WFC', 'VEMA12'), ('WELL', 'VEMA12'), ('WST', 'VEMA12'), ('WDC', 'VEMA12'), ('WRK', 'VEMA12'), ('WY', 'VEMA12'), ('WHR', 'VEMA12'), ('WMB', 'VEMA12'), ('WTW', 'VEMA12'), ('GWW', 'VEMA12'), ('WYNN', 'VEMA12'), ('XEL', 'VEMA12'), ('XYL', 'VEMA12'), ('YUM', 'VEMA12'), ('ZBRA', 'VEMA12'), ('ZBH', 'VEMA12'), ('ZION', 'VEMA12'), ('ZTS', 'VEMA12'), ('MMM', 'VSTD20'), ('AOS', 'VSTD20'), ('ABT', 'VSTD20'), ('ABBV', 'VSTD20'), ('ACN', 'VSTD20'), ('ATVI', 'VSTD20'), ('ADM', 'VSTD20'), ('ADBE', 'VSTD20'), ('ADP', 'VSTD20'), ('AAP', 'VSTD20'), ('AES', 'VSTD20'), ('AFL', 'VSTD20'), ('A', 'VSTD20'), ('APD', 'VSTD20'), ('AKAM', 'VSTD20'), ('ALK', 'VSTD20'), ('ALB', 'VSTD20'), ('ARE', 'VSTD20'), ('ALGN', 'VSTD20'), ('ALLE', 'VSTD20'), ('LNT', 'VSTD20'), ('ALL', 'VSTD20'), ('GOOGL', 'VSTD20'), ('GOOG', 'VSTD20'), ('MO', 'VSTD20'), ('AMZN', 'VSTD20'), ('AMCR', 'VSTD20'), ('AMD', 'VSTD20'), ('AEE', 'VSTD20'), ('AAL', 'VSTD20'), ('AEP', 'VSTD20'), ('AXP', 'VSTD20'), ('AIG', 'VSTD20'), ('AMT', 'VSTD20'), ('AWK', 'VSTD20'), ('AMP', 'VSTD20'), ('ABC', 'VSTD20'), ('AME', 'VSTD20'), ('AMGN', 'VSTD20'), ('APH', 'VSTD20'), ('ADI', 'VSTD20'), ('ANSS', 'VSTD20'), ('AON', 'VSTD20'), ('APA', 'VSTD20'), ('AAPL', 'VSTD20'), ('AMAT', 'VSTD20'), ('APTV', 'VSTD20'), ('ACGL', 'VSTD20'), ('ANET', 'VSTD20'), ('AJG', 'VSTD20'), ('AIZ', 'VSTD20'), ('T', 'VSTD20'), ('ATO', 'VSTD20'), ('ADSK', 'VSTD20'), ('AZO', 'VSTD20'), ('AVB', 'VSTD20'), ('AVY', 'VSTD20'), ('BKR', 'VSTD20'), ('BALL', 'VSTD20'), ('BAC', 'VSTD20'), ('BBWI', 'VSTD20'), ('BAX', 'VSTD20'), ('BDX', 'VSTD20'), ('WRB', 'VSTD20'), ('BBY', 'VSTD20'), ('BIO', 'VSTD20'), ('TECH', 'VSTD20'), ('BIIB', 'VSTD20'), ('BLK', 'VSTD20'), ('BK', 'VSTD20'), ('BA', 'VSTD20'), ('BKNG', 'VSTD20'), ('BWA', 'VSTD20'), ('BXP', 'VSTD20'), ('BSX', 'VSTD20'), ('BMY', 'VSTD20'), ('AVGO', 'VSTD20'), ('BR', 'VSTD20'), ('BRO', 'VSTD20'), ('BG', 'VSTD20'), ('CHRW', 'VSTD20'), ('CDNS', 'VSTD20'), ('CZR', 'VSTD20'), ('CPT', 'VSTD20'), ('CPB', 'VSTD20'), ('COF', 'VSTD20'), ('CAH', 'VSTD20'), ('KMX', 'VSTD20'), ('CCL', 'VSTD20'), ('CARR', 'VSTD20'), ('CTLT', 'VSTD20'), ('CAT', 'VSTD20'), ('CBOE', 'VSTD20'), ('CBRE', 'VSTD20'), ('CDW', 'VSTD20'), ('CE', 'VSTD20'), ('CNC', 'VSTD20'), ('CNP', 'VSTD20'), ('CDAY', 'VSTD20'), ('CF', 'VSTD20'), ('CRL', 'VSTD20'), ('SCHW', 'VSTD20'), ('CHTR', 'VSTD20'), ('CVX', 'VSTD20'), ('CMG', 'VSTD20'), ('CB', 'VSTD20'), ('CHD', 'VSTD20'), ('CI', 'VSTD20'), ('CINF', 'VSTD20'), ('CTAS', 'VSTD20'), ('CSCO', 'VSTD20'), ('C', 'VSTD20'), ('CFG', 'VSTD20'), ('CLX', 'VSTD20'), ('CME', 'VSTD20'), ('CMS', 'VSTD20'), ('KO', 'VSTD20'), ('CTSH', 'VSTD20'), ('CL', 'VSTD20'), ('CMCSA', 'VSTD20'), ('CMA', 'VSTD20'), ('CAG', 'VSTD20'), ('COP', 'VSTD20'), ('ED', 'VSTD20'), ('STZ', 'VSTD20'), ('CEG', 'VSTD20'), ('COO', 'VSTD20'), ('CPRT', 'VSTD20'), ('GLW', 'VSTD20'), ('CTVA', 'VSTD20'), ('CSGP', 'VSTD20'), ('COST', 'VSTD20'), ('CTRA', 'VSTD20'), ('CCI', 'VSTD20'), ('CSX', 'VSTD20'), ('CMI', 'VSTD20'), ('CVS', 'VSTD20'), ('DHI', 'VSTD20'), ('DHR', 'VSTD20'), ('DRI', 'VSTD20'), ('DVA', 'VSTD20'), ('DE', 'VSTD20'), ('DAL', 'VSTD20'), ('XRAY', 'VSTD20'), ('DVN', 'VSTD20'), ('DXCM', 'VSTD20'), ('FANG', 'VSTD20'), ('DLR', 'VSTD20'), ('DFS', 'VSTD20'), ('DISH', 'VSTD20'), ('DIS', 'VSTD20'), ('DG', 'VSTD20'), ('DLTR', 'VSTD20'), ('D', 'VSTD20'), ('DPZ', 'VSTD20'), ('DOV', 'VSTD20'), ('DOW', 'VSTD20'), ('DTE', 'VSTD20'), ('DUK', 'VSTD20'), ('DD', 'VSTD20'), ('DXC', 'VSTD20'), ('EMN', 'VSTD20'), ('ETN', 'VSTD20'), ('EBAY', 'VSTD20'), ('ECL', 'VSTD20'), ('EIX', 'VSTD20'), ('EW', 'VSTD20'), ('EA', 'VSTD20'), ('ELV', 'VSTD20'), ('LLY', 'VSTD20'), ('EMR', 'VSTD20'), ('ENPH', 'VSTD20'), ('ETR', 'VSTD20'), ('EOG', 'VSTD20'), ('EPAM', 'VSTD20'), ('EQT', 'VSTD20'), ('EFX', 'VSTD20'), ('EQIX', 'VSTD20'), ('EQR', 'VSTD20'), ('ESS', 'VSTD20'), ('EL', 'VSTD20'), ('ETSY', 'VSTD20'), ('RE', 'VSTD20'), ('EVRG', 'VSTD20'), ('ES', 'VSTD20'), ('EXC', 'VSTD20'), ('EXPE', 'VSTD20'), ('EXPD', 'VSTD20'), ('EXR', 'VSTD20'), ('XOM', 'VSTD20'), ('FFIV', 'VSTD20'), ('FDS', 'VSTD20'), ('FICO', 'VSTD20'), ('FAST', 'VSTD20'), ('FRT', 'VSTD20'), ('FDX', 'VSTD20'), ('FITB', 'VSTD20'), ('FRC', 'VSTD20'), ('FSLR', 'VSTD20'), ('FE', 'VSTD20'), ('FIS', 'VSTD20'), ('FISV', 'VSTD20'), ('FLT', 'VSTD20'), ('FMC', 'VSTD20'), ('F', 'VSTD20'), ('FTNT', 'VSTD20'), ('FTV', 'VSTD20'), ('FOXA', 'VSTD20'), ('FOX', 'VSTD20'), ('BEN', 'VSTD20'), ('FCX', 'VSTD20'), ('GRMN', 'VSTD20'), ('IT', 'VSTD20'), ('GEN', 'VSTD20'), ('GNRC', 'VSTD20'), ('GD', 'VSTD20'), ('GE', 'VSTD20'), ('GIS', 'VSTD20'), ('GM', 'VSTD20'), ('GPC', 'VSTD20'), ('GILD', 'VSTD20'), ('GL', 'VSTD20'), ('GPN', 'VSTD20'), ('GS', 'VSTD20'), ('HAL', 'VSTD20'), ('HIG', 'VSTD20'), ('HAS', 'VSTD20'), ('HCA', 'VSTD20'), ('PEAK', 'VSTD20'), ('HSIC', 'VSTD20'), ('HSY', 'VSTD20'), ('HES', 'VSTD20'), ('HPE', 'VSTD20'), ('HLT', 'VSTD20'), ('HOLX', 'VSTD20'), ('HD', 'VSTD20'), ('HON', 'VSTD20'), ('HRL', 'VSTD20'), ('HST', 'VSTD20'), ('HWM', 'VSTD20'), ('HPQ', 'VSTD20'), ('HUM', 'VSTD20'), ('HBAN', 'VSTD20'), ('HII', 'VSTD20'), ('IBM', 'VSTD20'), ('IEX', 'VSTD20'), ('IDXX', 'VSTD20'), ('ITW', 'VSTD20'), ('ILMN', 'VSTD20'), ('INCY', 'VSTD20'), ('IR', 'VSTD20'), ('PODD', 'VSTD20'), ('INTC', 'VSTD20'), ('ICE', 'VSTD20'), ('IFF', 'VSTD20'), ('IP', 'VSTD20'), ('IPG', 'VSTD20'), ('INTU', 'VSTD20'), ('ISRG', 'VSTD20'), ('IVZ', 'VSTD20'), ('INVH', 'VSTD20'), ('IQV', 'VSTD20'), ('IRM', 'VSTD20'), ('JBHT', 'VSTD20'), ('JKHY', 'VSTD20'), ('J', 'VSTD20'), ('JNJ', 'VSTD20'), ('JCI', 'VSTD20'), ('JPM', 'VSTD20'), ('JNPR', 'VSTD20'), ('K', 'VSTD20'), ('KDP', 'VSTD20'), ('KEY', 'VSTD20'), ('KEYS', 'VSTD20'), ('KMB', 'VSTD20'), ('KIM', 'VSTD20'), ('KMI', 'VSTD20'), ('KLAC', 'VSTD20'), ('KHC', 'VSTD20'), ('KR', 'VSTD20'), ('LHX', 'VSTD20'), ('LH', 'VSTD20'), ('LRCX', 'VSTD20'), ('LW', 'VSTD20'), ('LVS', 'VSTD20'), ('LDOS', 'VSTD20'), ('LEN', 'VSTD20'), ('LNC', 'VSTD20'), ('LIN', 'VSTD20'), ('LYV', 'VSTD20'), ('LKQ', 'VSTD20'), ('LMT', 'VSTD20'), ('L', 'VSTD20'), ('LOW', 'VSTD20'), ('LYB', 'VSTD20'), ('MTB', 'VSTD20'), ('MRO', 'VSTD20'), ('MPC', 'VSTD20'), ('MKTX', 'VSTD20'), ('MAR', 'VSTD20'), ('MMC', 'VSTD20'), ('MLM', 'VSTD20'), ('MAS', 'VSTD20'), ('MA', 'VSTD20'), ('MTCH', 'VSTD20'), ('MKC', 'VSTD20'), ('MCD', 'VSTD20'), ('MCK', 'VSTD20'), ('MDT', 'VSTD20'), ('MRK', 'VSTD20'), ('META', 'VSTD20'), ('MET', 'VSTD20'), ('MTD', 'VSTD20'), ('MGM', 'VSTD20'), ('MCHP', 'VSTD20'), ('MU', 'VSTD20'), ('MSFT', 'VSTD20'), ('MAA', 'VSTD20'), ('MRNA', 'VSTD20'), ('MHK', 'VSTD20'), ('MOH', 'VSTD20'), ('TAP', 'VSTD20'), ('MDLZ', 'VSTD20'), ('MPWR', 'VSTD20'), ('MNST', 'VSTD20'), ('MCO', 'VSTD20'), ('MS', 'VSTD20'), ('MOS', 'VSTD20'), ('MSI', 'VSTD20'), ('MSCI', 'VSTD20'), ('NDAQ', 'VSTD20'), ('NTAP', 'VSTD20'), ('NFLX', 'VSTD20'), ('NWL', 'VSTD20'), ('NEM', 'VSTD20'), ('NWSA', 'VSTD20'), ('NWS', 'VSTD20'), ('NEE', 'VSTD20'), ('NKE', 'VSTD20'), ('NI', 'VSTD20'), ('NDSN', 'VSTD20'), ('NSC', 'VSTD20'), ('NTRS', 'VSTD20'), ('NOC', 'VSTD20'), ('NCLH', 'VSTD20'), ('NRG', 'VSTD20'), ('NUE', 'VSTD20'), ('NVDA', 'VSTD20'), ('NVR', 'VSTD20'), ('NXPI', 'VSTD20'), ('ORLY', 'VSTD20'), ('OXY', 'VSTD20'), ('ODFL', 'VSTD20'), ('OMC', 'VSTD20'), ('ON', 'VSTD20'), ('OKE', 'VSTD20'), ('ORCL', 'VSTD20'), ('OGN', 'VSTD20'), ('OTIS', 'VSTD20'), ('PCAR', 'VSTD20'), ('PKG', 'VSTD20'), ('PARA', 'VSTD20'), ('PH', 'VSTD20'), ('PAYX', 'VSTD20'), ('PAYC', 'VSTD20'), ('PYPL', 'VSTD20'), ('PNR', 'VSTD20'), ('PEP', 'VSTD20'), ('PKI', 'VSTD20'), ('PFE', 'VSTD20'), ('PCG', 'VSTD20'), ('PM', 'VSTD20'), ('PSX', 'VSTD20'), ('PNW', 'VSTD20'), ('PXD', 'VSTD20'), ('PNC', 'VSTD20'), ('POOL', 'VSTD20'), ('PPG', 'VSTD20'), ('PPL', 'VSTD20'), ('PFG', 'VSTD20'), ('PG', 'VSTD20'), ('PGR', 'VSTD20'), ('PLD', 'VSTD20'), ('PRU', 'VSTD20'), ('PEG', 'VSTD20'), ('PTC', 'VSTD20'), ('PSA', 'VSTD20'), ('PHM', 'VSTD20'), ('QRVO', 'VSTD20'), ('PWR', 'VSTD20'), ('QCOM', 'VSTD20'), ('DGX', 'VSTD20'), ('RL', 'VSTD20'), ('RJF', 'VSTD20'), ('RTX', 'VSTD20'), ('O', 'VSTD20'), ('REG', 'VSTD20'), ('REGN', 'VSTD20'), ('RF', 'VSTD20'), ('RSG', 'VSTD20'), ('RMD', 'VSTD20'), ('RHI', 'VSTD20'), ('ROK', 'VSTD20'), ('ROL', 'VSTD20'), ('ROP', 'VSTD20'), ('ROST', 'VSTD20'), ('RCL', 'VSTD20'), ('SPGI', 'VSTD20'), ('CRM', 'VSTD20'), ('SBAC', 'VSTD20'), ('SLB', 'VSTD20'), ('STX', 'VSTD20'), ('SEE', 'VSTD20'), ('SRE', 'VSTD20'), ('NOW', 'VSTD20'), ('SHW', 'VSTD20'), ('SPG', 'VSTD20'), ('SWKS', 'VSTD20'), ('SJM', 'VSTD20'), ('SNA', 'VSTD20'), ('SEDG', 'VSTD20'), ('SO', 'VSTD20'), ('LUV', 'VSTD20'), ('SWK', 'VSTD20'), ('SBUX', 'VSTD20'), ('STT', 'VSTD20'), ('STLD', 'VSTD20'), ('STE', 'VSTD20'), ('SYK', 'VSTD20'), ('SYF', 'VSTD20'), ('SNPS', 'VSTD20'), ('SYY', 'VSTD20'), ('TMUS', 'VSTD20'), ('TROW', 'VSTD20'), ('TTWO', 'VSTD20'), ('TPR', 'VSTD20'), ('TRGP', 'VSTD20'), ('TGT', 'VSTD20'), ('TEL', 'VSTD20'), ('TDY', 'VSTD20'), ('TFX', 'VSTD20'), ('TER', 'VSTD20'), ('TSLA', 'VSTD20'), ('TXN', 'VSTD20'), ('TXT', 'VSTD20'), ('TMO', 'VSTD20'), ('TJX', 'VSTD20'), ('TSCO', 'VSTD20'), ('TT', 'VSTD20'), ('TDG', 'VSTD20'), ('TRV', 'VSTD20'), ('TRMB', 'VSTD20'), ('TFC', 'VSTD20'), ('TYL', 'VSTD20'), ('TSN', 'VSTD20'), ('USB', 'VSTD20'), ('UDR', 'VSTD20'), ('ULTA', 'VSTD20'), ('UNP', 'VSTD20'), ('UAL', 'VSTD20'), ('UPS', 'VSTD20'), ('URI', 'VSTD20'), ('UNH', 'VSTD20'), ('UHS', 'VSTD20'), ('VLO', 'VSTD20'), ('VTR', 'VSTD20'), ('VRSN', 'VSTD20'), ('VRSK', 'VSTD20'), ('VZ', 'VSTD20'), ('VRTX', 'VSTD20'), ('VFC', 'VSTD20'), ('VTRS', 'VSTD20'), ('VICI', 'VSTD20'), ('V', 'VSTD20'), ('VMC', 'VSTD20'), ('WAB', 'VSTD20'), ('WBA', 'VSTD20'), ('WMT', 'VSTD20'), ('WBD', 'VSTD20'), ('WM', 'VSTD20'), ('WAT', 'VSTD20'), ('WEC', 'VSTD20'), ('WFC', 'VSTD20'), ('WELL', 'VSTD20'), ('WST', 'VSTD20'), ('WDC', 'VSTD20'), ('WRK', 'VSTD20'), ('WY', 'VSTD20'), ('WHR', 'VSTD20'), ('WMB', 'VSTD20'), ('WTW', 'VSTD20'), ('GWW', 'VSTD20'), ('WYNN', 'VSTD20'), ('XEL', 'VSTD20'), ('XYL', 'VSTD20'), ('YUM', 'VSTD20'), ('ZBRA', 'VSTD20'), ('ZBH', 'VSTD20'), ('ZION', 'VSTD20'), ('ZTS', 'VSTD20'), ('MMM', 'V20'), ('AOS', 'V20'), ('ABT', 'V20'), ('ABBV', 'V20'), ('ACN', 'V20'), ('ATVI', 'V20'), ('ADM', 'V20'), ('ADBE', 'V20'), ('ADP', 'V20'), ('AAP', 'V20'), ('AES', 'V20'), ('AFL', 'V20'), ('A', 'V20'), ('APD', 'V20'), ('AKAM', 'V20'), ('ALK', 'V20'), ('ALB', 'V20'), ('ARE', 'V20'), ('ALGN', 'V20'), ('ALLE', 'V20'), ('LNT', 'V20'), ('ALL', 'V20'), ('GOOGL', 'V20'), ('GOOG', 'V20'), ('MO', 'V20'), ('AMZN', 'V20'), ('AMCR', 'V20'), ('AMD', 'V20'), ('AEE', 'V20'), ('AAL', 'V20'), ('AEP', 'V20'), ('AXP', 'V20'), ('AIG', 'V20'), ('AMT', 'V20'), ('AWK', 'V20'), ('AMP', 'V20'), ('ABC', 'V20'), ('AME', 'V20'), ('AMGN', 'V20'), ('APH', 'V20'), ('ADI', 'V20'), ('ANSS', 'V20'), ('AON', 'V20'), ('APA', 'V20'), ('AAPL', 'V20'), ('AMAT', 'V20'), ('APTV', 'V20'), ('ACGL', 'V20'), ('ANET', 'V20'), ('AJG', 'V20'), ('AIZ', 'V20'), ('T', 'V20'), ('ATO', 'V20'), ('ADSK', 'V20'), ('AZO', 'V20'), ('AVB', 'V20'), ('AVY', 'V20'), ('BKR', 'V20'), ('BALL', 'V20'), ('BAC', 'V20'), ('BBWI', 'V20'), ('BAX', 'V20'), ('BDX', 'V20'), ('WRB', 'V20'), ('BBY', 'V20'), ('BIO', 'V20'), ('TECH', 'V20'), ('BIIB', 'V20'), ('BLK', 'V20'), ('BK', 'V20'), ('BA', 'V20'), ('BKNG', 'V20'), ('BWA', 'V20'), ('BXP', 'V20'), ('BSX', 'V20'), ('BMY', 'V20'), ('AVGO', 'V20'), ('BR', 'V20'), ('BRO', 'V20'), ('BG', 'V20'), ('CHRW', 'V20'), ('CDNS', 'V20'), ('CZR', 'V20'), ('CPT', 'V20'), ('CPB', 'V20'), ('COF', 'V20'), ('CAH', 'V20'), ('KMX', 'V20'), ('CCL', 'V20'), ('CARR', 'V20'), ('CTLT', 'V20'), ('CAT', 'V20'), ('CBOE', 'V20'), ('CBRE', 'V20'), ('CDW', 'V20'), ('CE', 'V20'), ('CNC', 'V20'), ('CNP', 'V20'), ('CDAY', 'V20'), ('CF', 'V20'), ('CRL', 'V20'), ('SCHW', 'V20'), ('CHTR', 'V20'), ('CVX', 'V20'), ('CMG', 'V20'), ('CB', 'V20'), ('CHD', 'V20'), ('CI', 'V20'), ('CINF', 'V20'), ('CTAS', 'V20'), ('CSCO', 'V20'), ('C', 'V20'), ('CFG', 'V20'), ('CLX', 'V20'), ('CME', 'V20'), ('CMS', 'V20'), ('KO', 'V20'), ('CTSH', 'V20'), ('CL', 'V20'), ('CMCSA', 'V20'), ('CMA', 'V20'), ('CAG', 'V20'), ('COP', 'V20'), ('ED', 'V20'), ('STZ', 'V20'), ('CEG', 'V20'), ('COO', 'V20'), ('CPRT', 'V20'), ('GLW', 'V20'), ('CTVA', 'V20'), ('CSGP', 'V20'), ('COST', 'V20'), ('CTRA', 'V20'), ('CCI', 'V20'), ('CSX', 'V20'), ('CMI', 'V20'), ('CVS', 'V20'), ('DHI', 'V20'), ('DHR', 'V20'), ('DRI', 'V20'), ('DVA', 'V20'), ('DE', 'V20'), ('DAL', 'V20'), ('XRAY', 'V20'), ('DVN', 'V20'), ('DXCM', 'V20'), ('FANG', 'V20'), ('DLR', 'V20'), ('DFS', 'V20'), ('DISH', 'V20'), ('DIS', 'V20'), ('DG', 'V20'), ('DLTR', 'V20'), ('D', 'V20'), ('DPZ', 'V20'), ('DOV', 'V20'), ('DOW', 'V20'), ('DTE', 'V20'), ('DUK', 'V20'), ('DD', 'V20'), ('DXC', 'V20'), ('EMN', 'V20'), ('ETN', 'V20'), ('EBAY', 'V20'), ('ECL', 'V20'), ('EIX', 'V20'), ('EW', 'V20'), ('EA', 'V20'), ('ELV', 'V20'), ('LLY', 'V20'), ('EMR', 'V20'), ('ENPH', 'V20'), ('ETR', 'V20'), ('EOG', 'V20'), ('EPAM', 'V20'), ('EQT', 'V20'), ('EFX', 'V20'), ('EQIX', 'V20'), ('EQR', 'V20'), ('ESS', 'V20'), ('EL', 'V20'), ('ETSY', 'V20'), ('RE', 'V20'), ('EVRG', 'V20'), ('ES', 'V20'), ('EXC', 'V20'), ('EXPE', 'V20'), ('EXPD', 'V20'), ('EXR', 'V20'), ('XOM', 'V20'), ('FFIV', 'V20'), ('FDS', 'V20'), ('FICO', 'V20'), ('FAST', 'V20'), ('FRT', 'V20'), ('FDX', 'V20'), ('FITB', 'V20'), ('FRC', 'V20'), ('FSLR', 'V20'), ('FE', 'V20'), ('FIS', 'V20'), ('FISV', 'V20'), ('FLT', 'V20'), ('FMC', 'V20'), ('F', 'V20'), ('FTNT', 'V20'), ('FTV', 'V20'), ('FOXA', 'V20'), ('FOX', 'V20'), ('BEN', 'V20'), ('FCX', 'V20'), ('GRMN', 'V20'), ('IT', 'V20'), ('GEN', 'V20'), ('GNRC', 'V20'), ('GD', 'V20'), ('GE', 'V20'), ('GIS', 'V20'), ('GM', 'V20'), ('GPC', 'V20'), ('GILD', 'V20'), ('GL', 'V20'), ('GPN', 'V20'), ('GS', 'V20'), ('HAL', 'V20'), ('HIG', 'V20'), ('HAS', 'V20'), ('HCA', 'V20'), ('PEAK', 'V20'), ('HSIC', 'V20'), ('HSY', 'V20'), ('HES', 'V20'), ('HPE', 'V20'), ('HLT', 'V20'), ('HOLX', 'V20'), ('HD', 'V20'), ('HON', 'V20'), ('HRL', 'V20'), ('HST', 'V20'), ('HWM', 'V20'), ('HPQ', 'V20'), ('HUM', 'V20'), ('HBAN', 'V20'), ('HII', 'V20'), ('IBM', 'V20'), ('IEX', 'V20'), ('IDXX', 'V20'), ('ITW', 'V20'), ('ILMN', 'V20'), ('INCY', 'V20'), ('IR', 'V20'), ('PODD', 'V20'), ('INTC', 'V20'), ('ICE', 'V20'), ('IFF', 'V20'), ('IP', 'V20'), ('IPG', 'V20'), ('INTU', 'V20'), ('ISRG', 'V20'), ('IVZ', 'V20'), ('INVH', 'V20'), ('IQV', 'V20'), ('IRM', 'V20'), ('JBHT', 'V20'), ('JKHY', 'V20'), ('J', 'V20'), ('JNJ', 'V20'), ('JCI', 'V20'), ('JPM', 'V20'), ('JNPR', 'V20'), ('K', 'V20'), ('KDP', 'V20'), ('KEY', 'V20'), ('KEYS', 'V20'), ('KMB', 'V20'), ('KIM', 'V20'), ('KMI', 'V20'), ('KLAC', 'V20'), ('KHC', 'V20'), ('KR', 'V20'), ('LHX', 'V20'), ('LH', 'V20'), ('LRCX', 'V20'), ('LW', 'V20'), ('LVS', 'V20'), ('LDOS', 'V20'), ('LEN', 'V20'), ('LNC', 'V20'), ('LIN', 'V20'), ('LYV', 'V20'), ('LKQ', 'V20'), ('LMT', 'V20'), ('L', 'V20'), ('LOW', 'V20'), ('LYB', 'V20'), ('MTB', 'V20'), ('MRO', 'V20'), ('MPC', 'V20'), ('MKTX', 'V20'), ('MAR', 'V20'), ('MMC', 'V20'), ('MLM', 'V20'), ('MAS', 'V20'), ('MA', 'V20'), ('MTCH', 'V20'), ('MKC', 'V20'), ('MCD', 'V20'), ('MCK', 'V20'), ('MDT', 'V20'), ('MRK', 'V20'), ('META', 'V20'), ('MET', 'V20'), ('MTD', 'V20'), ('MGM', 'V20'), ('MCHP', 'V20'), ('MU', 'V20'), ('MSFT', 'V20'), ('MAA', 'V20'), ('MRNA', 'V20'), ('MHK', 'V20'), ('MOH', 'V20'), ('TAP', 'V20'), ('MDLZ', 'V20'), ('MPWR', 'V20'), ('MNST', 'V20'), ('MCO', 'V20'), ('MS', 'V20'), ('MOS', 'V20'), ('MSI', 'V20'), ('MSCI', 'V20'), ('NDAQ', 'V20'), ('NTAP', 'V20'), ('NFLX', 'V20'), ('NWL', 'V20'), ('NEM', 'V20'), ('NWSA', 'V20'), ('NWS', 'V20'), ('NEE', 'V20'), ('NKE', 'V20'), ('NI', 'V20'), ('NDSN', 'V20'), ('NSC', 'V20'), ('NTRS', 'V20'), ('NOC', 'V20'), ('NCLH', 'V20'), ('NRG', 'V20'), ('NUE', 'V20'), ('NVDA', 'V20'), ('NVR', 'V20'), ('NXPI', 'V20'), ('ORLY', 'V20'), ('OXY', 'V20'), ('ODFL', 'V20'), ('OMC', 'V20'), ('ON', 'V20'), ('OKE', 'V20'), ('ORCL', 'V20'), ('OGN', 'V20'), ('OTIS', 'V20'), ('PCAR', 'V20'), ('PKG', 'V20'), ('PARA', 'V20'), ('PH', 'V20'), ('PAYX', 'V20'), ('PAYC', 'V20'), ('PYPL', 'V20'), ('PNR', 'V20'), ('PEP', 'V20'), ('PKI', 'V20'), ('PFE', 'V20'), ('PCG', 'V20'), ('PM', 'V20'), ('PSX', 'V20'), ('PNW', 'V20'), ('PXD', 'V20'), ('PNC', 'V20'), ('POOL', 'V20'), ('PPG', 'V20'), ('PPL', 'V20'), ('PFG', 'V20'), ('PG', 'V20'), ('PGR', 'V20'), ('PLD', 'V20'), ('PRU', 'V20'), ('PEG', 'V20'), ('PTC', 'V20'), ('PSA', 'V20'), ('PHM', 'V20'), ('QRVO', 'V20'), ('PWR', 'V20'), ('QCOM', 'V20'), ('DGX', 'V20'), ('RL', 'V20'), ('RJF', 'V20'), ('RTX', 'V20'), ('O', 'V20'), ('REG', 'V20'), ('REGN', 'V20'), ('RF', 'V20'), ('RSG', 'V20'), ('RMD', 'V20'), ('RHI', 'V20'), ('ROK', 'V20'), ('ROL', 'V20'), ('ROP', 'V20'), ('ROST', 'V20'), ('RCL', 'V20'), ('SPGI', 'V20'), ('CRM', 'V20'), ('SBAC', 'V20'), ('SLB', 'V20'), ('STX', 'V20'), ('SEE', 'V20'), ('SRE', 'V20'), ('NOW', 'V20'), ('SHW', 'V20'), ('SPG', 'V20'), ('SWKS', 'V20'), ('SJM', 'V20'), ('SNA', 'V20'), ('SEDG', 'V20'), ('SO', 'V20'), ('LUV', 'V20'), ('SWK', 'V20'), ('SBUX', 'V20'), ('STT', 'V20'), ('STLD', 'V20'), ('STE', 'V20'), ('SYK', 'V20'), ('SYF', 'V20'), ('SNPS', 'V20'), ('SYY', 'V20'), ('TMUS', 'V20'), ('TROW', 'V20'), ('TTWO', 'V20'), ('TPR', 'V20'), ('TRGP', 'V20'), ('TGT', 'V20'), ('TEL', 'V20'), ('TDY', 'V20'), ('TFX', 'V20'), ('TER', 'V20'), ('TSLA', 'V20'), ('TXN', 'V20'), ('TXT', 'V20'), ('TMO', 'V20'), ('TJX', 'V20'), ('TSCO', 'V20'), ('TT', 'V20'), ('TDG', 'V20'), ('TRV', 'V20'), ('TRMB', 'V20'), ('TFC', 'V20'), ('TYL', 'V20'), ('TSN', 'V20'), ('USB', 'V20'), ('UDR', 'V20'), ('ULTA', 'V20'), ('UNP', 'V20'), ('UAL', 'V20'), ('UPS', 'V20'), ('URI', 'V20'), ('UNH', 'V20'), ('UHS', 'V20'), ('VLO', 'V20'), ('VTR', 'V20'), ('VRSN', 'V20'), ('VRSK', 'V20'), ('VZ', 'V20'), ('VRTX', 'V20'), ('VFC', 'V20'), ('VTRS', 'V20'), ('VICI', 'V20'), ('V', 'V20'), ('VMC', 'V20'), ('WAB', 'V20'), ('WBA', 'V20'), ('WMT', 'V20'), ('WBD', 'V20'), ('WM', 'V20'), ('WAT', 'V20'), ('WEC', 'V20'), ('WFC', 'V20'), ('WELL', 'V20'), ('WST', 'V20'), ('WDC', 'V20'), ('WRK', 'V20'), ('WY', 'V20'), ('WHR', 'V20'), ('WMB', 'V20'), ('WTW', 'V20'), ('GWW', 'V20'), ('WYNN', 'V20'), ('XEL', 'V20'), ('XYL', 'V20'), ('YUM', 'V20'), ('ZBRA', 'V20'), ('ZBH', 'V20'), ('ZION', 'V20'), ('ZTS', 'V20'), ('MMM', 'AR'), ('AOS', 'AR'), ('ABT', 'AR'), ('ABBV', 'AR'), ('ACN', 'AR'), ('ATVI', 'AR'), ('ADM', 'AR'), ('ADBE', 'AR'), ('ADP', 'AR'), ('AAP', 'AR'), ('AES', 'AR'), ('AFL', 'AR'), ('A', 'AR'), ('APD', 'AR'), ('AKAM', 'AR'), ('ALK', 'AR'), ('ALB', 'AR'), ('ARE', 'AR'), ('ALGN', 'AR'), ('ALLE', 'AR'), ('LNT', 'AR'), ('ALL', 'AR'), ('GOOGL', 'AR'), ('GOOG', 'AR'), ('MO', 'AR'), ('AMZN', 'AR'), ('AMCR', 'AR'), ('AMD', 'AR'), ('AEE', 'AR'), ('AAL', 'AR'), ('AEP', 'AR'), ('AXP', 'AR'), ('AIG', 'AR'), ('AMT', 'AR'), ('AWK', 'AR'), ('AMP', 'AR'), ('ABC', 'AR'), ('AME', 'AR'), ('AMGN', 'AR'), ('APH', 'AR'), ('ADI', 'AR'), ('ANSS', 'AR'), ('AON', 'AR'), ('APA', 'AR'), ('AAPL', 'AR'), ('AMAT', 'AR'), ('APTV', 'AR'), ('ACGL', 'AR'), ('ANET', 'AR'), ('AJG', 'AR'), ('AIZ', 'AR'), ('T', 'AR'), ('ATO', 'AR'), ('ADSK', 'AR'), ('AZO', 'AR'), ('AVB', 'AR'), ('AVY', 'AR'), ('BKR', 'AR'), ('BALL', 'AR'), ('BAC', 'AR'), ('BBWI', 'AR'), ('BAX', 'AR'), ('BDX', 'AR'), ('WRB', 'AR'), ('BBY', 'AR'), ('BIO', 'AR'), ('TECH', 'AR'), ('BIIB', 'AR'), ('BLK', 'AR'), ('BK', 'AR'), ('BA', 'AR'), ('BKNG', 'AR'), ('BWA', 'AR'), ('BXP', 'AR'), ('BSX', 'AR'), ('BMY', 'AR'), ('AVGO', 'AR'), ('BR', 'AR'), ('BRO', 'AR'), ('BG', 'AR'), ('CHRW', 'AR'), ('CDNS', 'AR'), ('CZR', 'AR'), ('CPT', 'AR'), ('CPB', 'AR'), ('COF', 'AR'), ('CAH', 'AR'), ('KMX', 'AR'), ('CCL', 'AR'), ('CARR', 'AR'), ('CTLT', 'AR'), ('CAT', 'AR'), ('CBOE', 'AR'), ('CBRE', 'AR'), ('CDW', 'AR'), ('CE', 'AR'), ('CNC', 'AR'), ('CNP', 'AR'), ('CDAY', 'AR'), ('CF', 'AR'), ('CRL', 'AR'), ('SCHW', 'AR'), ('CHTR', 'AR'), ('CVX', 'AR'), ('CMG', 'AR'), ('CB', 'AR'), ('CHD', 'AR'), ('CI', 'AR'), ('CINF', 'AR'), ('CTAS', 'AR'), ('CSCO', 'AR'), ('C', 'AR'), ('CFG', 'AR'), ('CLX', 'AR'), ('CME', 'AR'), ('CMS', 'AR'), ('KO', 'AR'), ('CTSH', 'AR'), ('CL', 'AR'), ('CMCSA', 'AR'), ('CMA', 'AR'), ('CAG', 'AR'), ('COP', 'AR'), ('ED', 'AR'), ('STZ', 'AR'), ('CEG', 'AR'), ('COO', 'AR'), ('CPRT', 'AR'), ('GLW', 'AR'), ('CTVA', 'AR'), ('CSGP', 'AR'), ('COST', 'AR'), ('CTRA', 'AR'), ('CCI', 'AR'), ('CSX', 'AR'), ('CMI', 'AR'), ('CVS', 'AR'), ('DHI', 'AR'), ('DHR', 'AR'), ('DRI', 'AR'), ('DVA', 'AR'), ('DE', 'AR'), ('DAL', 'AR'), ('XRAY', 'AR'), ('DVN', 'AR'), ('DXCM', 'AR'), ('FANG', 'AR'), ('DLR', 'AR'), ('DFS', 'AR'), ('DISH', 'AR'), ('DIS', 'AR'), ('DG', 'AR'), ('DLTR', 'AR'), ('D', 'AR'), ('DPZ', 'AR'), ('DOV', 'AR'), ('DOW', 'AR'), ('DTE', 'AR'), ('DUK', 'AR'), ('DD', 'AR'), ('DXC', 'AR'), ('EMN', 'AR'), ('ETN', 'AR'), ('EBAY', 'AR'), ('ECL', 'AR'), ('EIX', 'AR'), ('EW', 'AR'), ('EA', 'AR'), ('ELV', 'AR'), ('LLY', 'AR'), ('EMR', 'AR'), ('ENPH', 'AR'), ('ETR', 'AR'), ('EOG', 'AR'), ('EPAM', 'AR'), ('EQT', 'AR'), ('EFX', 'AR'), ('EQIX', 'AR'), ('EQR', 'AR'), ('ESS', 'AR'), ('EL', 'AR'), ('ETSY', 'AR'), ('RE', 'AR'), ('EVRG', 'AR'), ('ES', 'AR'), ('EXC', 'AR'), ('EXPE', 'AR'), ('EXPD', 'AR'), ('EXR', 'AR'), ('XOM', 'AR'), ('FFIV', 'AR'), ('FDS', 'AR'), ('FICO', 'AR'), ('FAST', 'AR'), ('FRT', 'AR'), ('FDX', 'AR'), ('FITB', 'AR'), ('FRC', 'AR'), ('FSLR', 'AR'), ('FE', 'AR'), ('FIS', 'AR'), ('FISV', 'AR'), ('FLT', 'AR'), ('FMC', 'AR'), ('F', 'AR'), ('FTNT', 'AR'), ('FTV', 'AR'), ('FOXA', 'AR'), ('FOX', 'AR'), ('BEN', 'AR'), ('FCX', 'AR'), ('GRMN', 'AR'), ('IT', 'AR'), ('GEN', 'AR'), ('GNRC', 'AR'), ('GD', 'AR'), ('GE', 'AR'), ('GIS', 'AR'), ('GM', 'AR'), ('GPC', 'AR'), ('GILD', 'AR'), ('GL', 'AR'), ('GPN', 'AR'), ('GS', 'AR'), ('HAL', 'AR'), ('HIG', 'AR'), ('HAS', 'AR'), ('HCA', 'AR'), ('PEAK', 'AR'), ('HSIC', 'AR'), ('HSY', 'AR'), ('HES', 'AR'), ('HPE', 'AR'), ('HLT', 'AR'), ('HOLX', 'AR'), ('HD', 'AR'), ('HON', 'AR'), ('HRL', 'AR'), ('HST', 'AR'), ('HWM', 'AR'), ('HPQ', 'AR'), ('HUM', 'AR'), ('HBAN', 'AR'), ('HII', 'AR'), ('IBM', 'AR'), ('IEX', 'AR'), ('IDXX', 'AR'), ('ITW', 'AR'), ('ILMN', 'AR'), ('INCY', 'AR'), ('IR', 'AR'), ('PODD', 'AR'), ('INTC', 'AR'), ('ICE', 'AR'), ('IFF', 'AR'), ('IP', 'AR'), ('IPG', 'AR'), ('INTU', 'AR'), ('ISRG', 'AR'), ('IVZ', 'AR'), ('INVH', 'AR'), ('IQV', 'AR'), ('IRM', 'AR'), ('JBHT', 'AR'), ('JKHY', 'AR'), ('J', 'AR'), ('JNJ', 'AR'), ('JCI', 'AR'), ('JPM', 'AR'), ('JNPR', 'AR'), ('K', 'AR'), ('KDP', 'AR'), ('KEY', 'AR'), ('KEYS', 'AR'), ('KMB', 'AR'), ('KIM', 'AR'), ('KMI', 'AR'), ('KLAC', 'AR'), ('KHC', 'AR'), ('KR', 'AR'), ('LHX', 'AR'), ('LH', 'AR'), ('LRCX', 'AR'), ('LW', 'AR'), ('LVS', 'AR'), ('LDOS', 'AR'), ('LEN', 'AR'), ('LNC', 'AR'), ('LIN', 'AR'), ('LYV', 'AR'), ('LKQ', 'AR'), ('LMT', 'AR'), ('L', 'AR'), ('LOW', 'AR'), ('LYB', 'AR'), ('MTB', 'AR'), ('MRO', 'AR'), ('MPC', 'AR'), ('MKTX', 'AR'), ('MAR', 'AR'), ('MMC', 'AR'), ('MLM', 'AR'), ('MAS', 'AR'), ('MA', 'AR'), ('MTCH', 'AR'), ('MKC', 'AR'), ('MCD', 'AR'), ('MCK', 'AR'), ('MDT', 'AR'), ('MRK', 'AR'), ('META', 'AR'), ('MET', 'AR'), ('MTD', 'AR'), ('MGM', 'AR'), ('MCHP', 'AR'), ('MU', 'AR'), ('MSFT', 'AR'), ('MAA', 'AR'), ('MRNA', 'AR'), ('MHK', 'AR'), ('MOH', 'AR'), ('TAP', 'AR'), ('MDLZ', 'AR'), ('MPWR', 'AR'), ('MNST', 'AR'), ('MCO', 'AR'), ('MS', 'AR'), ('MOS', 'AR'), ('MSI', 'AR'), ('MSCI', 'AR'), ('NDAQ', 'AR'), ('NTAP', 'AR'), ('NFLX', 'AR'), ('NWL', 'AR'), ('NEM', 'AR'), ('NWSA', 'AR'), ('NWS', 'AR'), ('NEE', 'AR'), ('NKE', 'AR'), ('NI', 'AR'), ('NDSN', 'AR'), ('NSC', 'AR'), ('NTRS', 'AR'), ('NOC', 'AR'), ('NCLH', 'AR'), ('NRG', 'AR'), ('NUE', 'AR'), ('NVDA', 'AR'), ('NVR', 'AR'), ('NXPI', 'AR'), ('ORLY', 'AR'), ('OXY', 'AR'), ('ODFL', 'AR'), ('OMC', 'AR'), ('ON', 'AR'), ('OKE', 'AR'), ('ORCL', 'AR'), ('OGN', 'AR'), ('OTIS', 'AR'), ('PCAR', 'AR'), ('PKG', 'AR'), ('PARA', 'AR'), ('PH', 'AR'), ('PAYX', 'AR'), ('PAYC', 'AR'), ('PYPL', 'AR'), ('PNR', 'AR'), ('PEP', 'AR'), ('PKI', 'AR'), ('PFE', 'AR'), ('PCG', 'AR'), ('PM', 'AR'), ('PSX', 'AR'), ('PNW', 'AR'), ('PXD', 'AR'), ('PNC', 'AR'), ('POOL', 'AR'), ('PPG', 'AR'), ('PPL', 'AR'), ('PFG', 'AR'), ('PG', 'AR'), ('PGR', 'AR'), ('PLD', 'AR'), ('PRU', 'AR'), ('PEG', 'AR'), ('PTC', 'AR'), ('PSA', 'AR'), ('PHM', 'AR'), ('QRVO', 'AR'), ('PWR', 'AR'), ('QCOM', 'AR'), ('DGX', 'AR'), ('RL', 'AR'), ('RJF', 'AR'), ('RTX', 'AR'), ('O', 'AR'), ('REG', 'AR'), ('REGN', 'AR'), ('RF', 'AR'), ('RSG', 'AR'), ('RMD', 'AR'), ('RHI', 'AR'), ('ROK', 'AR'), ('ROL', 'AR'), ('ROP', 'AR'), ('ROST', 'AR'), ('RCL', 'AR'), ('SPGI', 'AR'), ('CRM', 'AR'), ('SBAC', 'AR'), ('SLB', 'AR'), ('STX', 'AR'), ('SEE', 'AR'), ('SRE', 'AR'), ('NOW', 'AR'), ('SHW', 'AR'), ('SPG', 'AR'), ('SWKS', 'AR'), ('SJM', 'AR'), ('SNA', 'AR'), ('SEDG', 'AR'), ('SO', 'AR'), ('LUV', 'AR'), ('SWK', 'AR'), ('SBUX', 'AR'), ('STT', 'AR'), ('STLD', 'AR'), ('STE', 'AR'), ('SYK', 'AR'), ('SYF', 'AR'), ('SNPS', 'AR'), ('SYY', 'AR'), ('TMUS', 'AR'), ('TROW', 'AR'), ('TTWO', 'AR'), ('TPR', 'AR'), ('TRGP', 'AR'), ('TGT', 'AR'), ('TEL', 'AR'), ('TDY', 'AR'), ('TFX', 'AR'), ('TER', 'AR'), ('TSLA', 'AR'), ('TXN', 'AR'), ('TXT', 'AR'), ('TMO', 'AR'), ('TJX', 'AR'), ('TSCO', 'AR'), ('TT', 'AR'), ('TDG', 'AR'), ('TRV', 'AR'), ('TRMB', 'AR'), ('TFC', 'AR'), ('TYL', 'AR'), ('TSN', 'AR'), ('USB', 'AR'), ('UDR', 'AR'), ('ULTA', 'AR'), ('UNP', 'AR'), ('UAL', 'AR'), ('UPS', 'AR'), ('URI', 'AR'), ('UNH', 'AR'), ('UHS', 'AR'), ('VLO', 'AR'), ('VTR', 'AR'), ('VRSN', 'AR'), ('VRSK', 'AR'), ('VZ', 'AR'), ('VRTX', 'AR'), ('VFC', 'AR'), ('VTRS', 'AR'), ('VICI', 'AR'), ('V', 'AR'), ('VMC', 'AR'), ('WAB', 'AR'), ('WBA', 'AR'), ('WMT', 'AR'), ('WBD', 'AR'), ('WM', 'AR'), ('WAT', 'AR'), ('WEC', 'AR'), ('WFC', 'AR'), ('WELL', 'AR'), ('WST', 'AR'), ('WDC', 'AR'), ('WRK', 'AR'), ('WY', 'AR'), ('WHR', 'AR'), ('WMB', 'AR'), ('WTW', 'AR'), ('GWW', 'AR'), ('WYNN', 'AR'), ('XEL', 'AR'), ('XYL', 'AR'), ('YUM', 'AR'), ('ZBRA', 'AR'), ('ZBH', 'AR'), ('ZION', 'AR'), ('ZTS', 'AR'), ('MMM', 'BR'), ('AOS', 'BR'), ('ABT', 'BR'), ('ABBV', 'BR'), ('ACN', 'BR'), ('ATVI', 'BR'), ('ADM', 'BR'), ('ADBE', 'BR'), ('ADP', 'BR'), ('AAP', 'BR'), ('AES', 'BR'), ('AFL', 'BR'), ('A', 'BR'), ('APD', 'BR'), ('AKAM', 'BR'), ('ALK', 'BR'), ('ALB', 'BR'), ('ARE', 'BR'), ('ALGN', 'BR'), ('ALLE', 'BR'), ('LNT', 'BR'), ('ALL', 'BR'), ('GOOGL', 'BR'), ('GOOG', 'BR'), ('MO', 'BR'), ('AMZN', 'BR'), ('AMCR', 'BR'), ('AMD', 'BR'), ('AEE', 'BR'), ('AAL', 'BR'), ('AEP', 'BR'), ('AXP', 'BR'), ('AIG', 'BR'), ('AMT', 'BR'), ('AWK', 'BR'), ('AMP', 'BR'), ('ABC', 'BR'), ('AME', 'BR'), ('AMGN', 'BR'), ('APH', 'BR'), ('ADI', 'BR'), ('ANSS', 'BR'), ('AON', 'BR'), ('APA', 'BR'), ('AAPL', 'BR'), ('AMAT', 'BR'), ('APTV', 'BR'), ('ACGL', 'BR'), ('ANET', 'BR'), ('AJG', 'BR'), ('AIZ', 'BR'), ('T', 'BR'), ('ATO', 'BR'), ('ADSK', 'BR'), ('AZO', 'BR'), ('AVB', 'BR'), ('AVY', 'BR'), ('BKR', 'BR'), ('BALL', 'BR'), ('BAC', 'BR'), ('BBWI', 'BR'), ('BAX', 'BR'), ('BDX', 'BR'), ('WRB', 'BR'), ('BBY', 'BR'), ('BIO', 'BR'), ('TECH', 'BR'), ('BIIB', 'BR'), ('BLK', 'BR'), ('BK', 'BR'), ('BA', 'BR'), ('BKNG', 'BR'), ('BWA', 'BR'), ('BXP', 'BR'), ('BSX', 'BR'), ('BMY', 'BR'), ('AVGO', 'BR'), ('BR', 'BR'), ('BRO', 'BR'), ('BG', 'BR'), ('CHRW', 'BR'), ('CDNS', 'BR'), ('CZR', 'BR'), ('CPT', 'BR'), ('CPB', 'BR'), ('COF', 'BR'), ('CAH', 'BR'), ('KMX', 'BR'), ('CCL', 'BR'), ('CARR', 'BR'), ('CTLT', 'BR'), ('CAT', 'BR'), ('CBOE', 'BR'), ('CBRE', 'BR'), ('CDW', 'BR'), ('CE', 'BR'), ('CNC', 'BR'), ('CNP', 'BR'), ('CDAY', 'BR'), ('CF', 'BR'), ('CRL', 'BR'), ('SCHW', 'BR'), ('CHTR', 'BR'), ('CVX', 'BR'), ('CMG', 'BR'), ('CB', 'BR'), ('CHD', 'BR'), ('CI', 'BR'), ('CINF', 'BR'), ('CTAS', 'BR'), ('CSCO', 'BR'), ('C', 'BR'), ('CFG', 'BR'), ('CLX', 'BR'), ('CME', 'BR'), ('CMS', 'BR'), ('KO', 'BR'), ('CTSH', 'BR'), ('CL', 'BR'), ('CMCSA', 'BR'), ('CMA', 'BR'), ('CAG', 'BR'), ('COP', 'BR'), ('ED', 'BR'), ('STZ', 'BR'), ('CEG', 'BR'), ('COO', 'BR'), ('CPRT', 'BR'), ('GLW', 'BR'), ('CTVA', 'BR'), ('CSGP', 'BR'), ('COST', 'BR'), ('CTRA', 'BR'), ('CCI', 'BR'), ('CSX', 'BR'), ('CMI', 'BR'), ('CVS', 'BR'), ('DHI', 'BR'), ('DHR', 'BR'), ('DRI', 'BR'), ('DVA', 'BR'), ('DE', 'BR'), ('DAL', 'BR'), ('XRAY', 'BR'), ('DVN', 'BR'), ('DXCM', 'BR'), ('FANG', 'BR'), ('DLR', 'BR'), ('DFS', 'BR'), ('DISH', 'BR'), ('DIS', 'BR'), ('DG', 'BR'), ('DLTR', 'BR'), ('D', 'BR'), ('DPZ', 'BR'), ('DOV', 'BR'), ('DOW', 'BR'), ('DTE', 'BR'), ('DUK', 'BR'), ('DD', 'BR'), ('DXC', 'BR'), ('EMN', 'BR'), ('ETN', 'BR'), ('EBAY', 'BR'), ('ECL', 'BR'), ('EIX', 'BR'), ('EW', 'BR'), ('EA', 'BR'), ('ELV', 'BR'), ('LLY', 'BR'), ('EMR', 'BR'), ('ENPH', 'BR'), ('ETR', 'BR'), ('EOG', 'BR'), ('EPAM', 'BR'), ('EQT', 'BR'), ('EFX', 'BR'), ('EQIX', 'BR'), ('EQR', 'BR'), ('ESS', 'BR'), ('EL', 'BR'), ('ETSY', 'BR'), ('RE', 'BR'), ('EVRG', 'BR'), ('ES', 'BR'), ('EXC', 'BR'), ('EXPE', 'BR'), ('EXPD', 'BR'), ('EXR', 'BR'), ('XOM', 'BR'), ('FFIV', 'BR'), ('FDS', 'BR'), ('FICO', 'BR'), ('FAST', 'BR'), ('FRT', 'BR'), ('FDX', 'BR'), ('FITB', 'BR'), ('FRC', 'BR'), ('FSLR', 'BR'), ('FE', 'BR'), ('FIS', 'BR'), ('FISV', 'BR'), ('FLT', 'BR'), ('FMC', 'BR'), ('F', 'BR'), ('FTNT', 'BR'), ('FTV', 'BR'), ('FOXA', 'BR'), ('FOX', 'BR'), ('BEN', 'BR'), ('FCX', 'BR'), ('GRMN', 'BR'), ('IT', 'BR'), ('GEN', 'BR'), ('GNRC', 'BR'), ('GD', 'BR'), ('GE', 'BR'), ('GIS', 'BR'), ('GM', 'BR'), ('GPC', 'BR'), ('GILD', 'BR'), ('GL', 'BR'), ('GPN', 'BR'), ('GS', 'BR'), ('HAL', 'BR'), ('HIG', 'BR'), ('HAS', 'BR'), ('HCA', 'BR'), ('PEAK', 'BR'), ('HSIC', 'BR'), ('HSY', 'BR'), ('HES', 'BR'), ('HPE', 'BR'), ('HLT', 'BR'), ('HOLX', 'BR'), ('HD', 'BR'), ('HON', 'BR'), ('HRL', 'BR'), ('HST', 'BR'), ('HWM', 'BR'), ('HPQ', 'BR'), ('HUM', 'BR'), ('HBAN', 'BR'), ('HII', 'BR'), ('IBM', 'BR'), ('IEX', 'BR'), ('IDXX', 'BR'), ('ITW', 'BR'), ('ILMN', 'BR'), ('INCY', 'BR'), ('IR', 'BR'), ('PODD', 'BR'), ('INTC', 'BR'), ('ICE', 'BR'), ('IFF', 'BR'), ('IP', 'BR'), ('IPG', 'BR'), ('INTU', 'BR'), ('ISRG', 'BR'), ('IVZ', 'BR'), ('INVH', 'BR'), ('IQV', 'BR'), ('IRM', 'BR'), ('JBHT', 'BR'), ('JKHY', 'BR'), ('J', 'BR'), ('JNJ', 'BR'), ('JCI', 'BR'), ('JPM', 'BR'), ('JNPR', 'BR'), ('K', 'BR'), ('KDP', 'BR'), ('KEY', 'BR'), ('KEYS', 'BR'), ('KMB', 'BR'), ('KIM', 'BR'), ('KMI', 'BR'), ('KLAC', 'BR'), ('KHC', 'BR'), ('KR', 'BR'), ('LHX', 'BR'), ('LH', 'BR'), ('LRCX', 'BR'), ('LW', 'BR'), ('LVS', 'BR'), ('LDOS', 'BR'), ('LEN', 'BR'), ('LNC', 'BR'), ('LIN', 'BR'), ('LYV', 'BR'), ('LKQ', 'BR'), ('LMT', 'BR'), ('L', 'BR'), ('LOW', 'BR'), ('LYB', 'BR'), ('MTB', 'BR'), ('MRO', 'BR'), ('MPC', 'BR'), ('MKTX', 'BR'), ('MAR', 'BR'), ('MMC', 'BR'), ('MLM', 'BR'), ('MAS', 'BR'), ('MA', 'BR'), ('MTCH', 'BR'), ('MKC', 'BR'), ('MCD', 'BR'), ('MCK', 'BR'), ('MDT', 'BR'), ('MRK', 'BR'), ('META', 'BR'), ('MET', 'BR'), ('MTD', 'BR'), ('MGM', 'BR'), ('MCHP', 'BR'), ('MU', 'BR'), ('MSFT', 'BR'), ('MAA', 'BR'), ('MRNA', 'BR'), ('MHK', 'BR'), ('MOH', 'BR'), ('TAP', 'BR'), ('MDLZ', 'BR'), ('MPWR', 'BR'), ('MNST', 'BR'), ('MCO', 'BR'), ('MS', 'BR'), ('MOS', 'BR'), ('MSI', 'BR'), ('MSCI', 'BR'), ('NDAQ', 'BR'), ('NTAP', 'BR'), ('NFLX', 'BR'), ('NWL', 'BR'), ('NEM', 'BR'), ('NWSA', 'BR'), ('NWS', 'BR'), ('NEE', 'BR'), ('NKE', 'BR'), ('NI', 'BR'), ('NDSN', 'BR'), ('NSC', 'BR'), ('NTRS', 'BR'), ('NOC', 'BR'), ('NCLH', 'BR'), ('NRG', 'BR'), ('NUE', 'BR'), ('NVDA', 'BR'), ('NVR', 'BR'), ('NXPI', 'BR'), ('ORLY', 'BR'), ('OXY', 'BR'), ('ODFL', 'BR'), ('OMC', 'BR'), ('ON', 'BR'), ('OKE', 'BR'), ('ORCL', 'BR'), ('OGN', 'BR'), ('OTIS', 'BR'), ('PCAR', 'BR'), ('PKG', 'BR'), ('PARA', 'BR'), ('PH', 'BR'), ('PAYX', 'BR'), ('PAYC', 'BR'), ('PYPL', 'BR'), ('PNR', 'BR'), ('PEP', 'BR'), ('PKI', 'BR'), ('PFE', 'BR'), ('PCG', 'BR'), ('PM', 'BR'), ('PSX', 'BR'), ('PNW', 'BR'), ('PXD', 'BR'), ('PNC', 'BR'), ('POOL', 'BR'), ('PPG', 'BR'), ('PPL', 'BR'), ('PFG', 'BR'), ('PG', 'BR'), ('PGR', 'BR'), ('PLD', 'BR'), ('PRU', 'BR'), ('PEG', 'BR'), ('PTC', 'BR'), ('PSA', 'BR'), ('PHM', 'BR'), ('QRVO', 'BR'), ('PWR', 'BR'), ('QCOM', 'BR'), ('DGX', 'BR'), ('RL', 'BR'), ('RJF', 'BR'), ('RTX', 'BR'), ('O', 'BR'), ('REG', 'BR'), ('REGN', 'BR'), ('RF', 'BR'), ('RSG', 'BR'), ('RMD', 'BR'), ('RHI', 'BR'), ('ROK', 'BR'), ('ROL', 'BR'), ('ROP', 'BR'), ('ROST', 'BR'), ('RCL', 'BR'), ('SPGI', 'BR'), ('CRM', 'BR'), ('SBAC', 'BR'), ('SLB', 'BR'), ('STX', 'BR'), ('SEE', 'BR'), ('SRE', 'BR'), ('NOW', 'BR'), ('SHW', 'BR'), ('SPG', 'BR'), ('SWKS', 'BR'), ('SJM', 'BR'), ('SNA', 'BR'), ('SEDG', 'BR'), ('SO', 'BR'), ('LUV', 'BR'), ('SWK', 'BR'), ('SBUX', 'BR'), ('STT', 'BR'), ('STLD', 'BR'), ('STE', 'BR'), ('SYK', 'BR'), ('SYF', 'BR'), ('SNPS', 'BR'), ('SYY', 'BR'), ('TMUS', 'BR'), ('TROW', 'BR'), ('TTWO', 'BR'), ('TPR', 'BR'), ('TRGP', 'BR'), ('TGT', 'BR'), ('TEL', 'BR'), ('TDY', 'BR'), ('TFX', 'BR'), ('TER', 'BR'), ('TSLA', 'BR'), ('TXN', 'BR'), ('TXT', 'BR'), ('TMO', 'BR'), ('TJX', 'BR'), ('TSCO', 'BR'), ('TT', 'BR'), ('TDG', 'BR'), ('TRV', 'BR'), ('TRMB', 'BR'), ('TFC', 'BR'), ('TYL', 'BR'), ('TSN', 'BR'), ('USB', 'BR'), ('UDR', 'BR'), ('ULTA', 'BR'), ('UNP', 'BR'), ('UAL', 'BR'), ('UPS', 'BR'), ('URI', 'BR'), ('UNH', 'BR'), ('UHS', 'BR'), ('VLO', 'BR'), ('VTR', 'BR'), ('VRSN', 'BR'), ('VRSK', 'BR'), ('VZ', 'BR'), ('VRTX', 'BR'), ('VFC', 'BR'), ('VTRS', 'BR'), ('VICI', 'BR'), ('V', 'BR'), ('VMC', 'BR'), ('WAB', 'BR'), ('WBA', 'BR'), ('WMT', 'BR'), ('WBD', 'BR'), ('WM', 'BR'), ('WAT', 'BR'), ('WEC', 'BR'), ('WFC', 'BR'), ('WELL', 'BR'), ('WST', 'BR'), ('WDC', 'BR'), ('WRK', 'BR'), ('WY', 'BR'), ('WHR', 'BR'), ('WMB', 'BR'), ('WTW', 'BR'), ('GWW', 'BR'), ('WYNN', 'BR'), ('XEL', 'BR'), ('XYL', 'BR'), ('YUM', 'BR'), ('ZBRA', 'BR'), ('ZBH', 'BR'), ('ZION', 'BR'), ('ZTS', 'BR'), ('MMM', 'AU'), ('AOS', 'AU'), ('ABT', 'AU'), ('ABBV', 'AU'), ('ACN', 'AU'), ('ATVI', 'AU'), ('ADM', 'AU'), ('ADBE', 'AU'), ('ADP', 'AU'), ('AAP', 'AU'), ('AES', 'AU'), ('AFL', 'AU'), ('A', 'AU'), ('APD', 'AU'), ('AKAM', 'AU'), ('ALK', 'AU'), ('ALB', 'AU'), ('ARE', 'AU'), ('ALGN', 'AU'), ('ALLE', 'AU'), ('LNT', 'AU'), ('ALL', 'AU'), ('GOOGL', 'AU'), ('GOOG', 'AU'), ('MO', 'AU'), ('AMZN', 'AU'), ('AMCR', 'AU'), ('AMD', 'AU'), ('AEE', 'AU'), ('AAL', 'AU'), ('AEP', 'AU'), ('AXP', 'AU'), ('AIG', 'AU'), ('AMT', 'AU'), ('AWK', 'AU'), ('AMP', 'AU'), ('ABC', 'AU'), ('AME', 'AU'), ('AMGN', 'AU'), ('APH', 'AU'), ('ADI', 'AU'), ('ANSS', 'AU'), ('AON', 'AU'), ('APA', 'AU'), ('AAPL', 'AU'), ('AMAT', 'AU'), ('APTV', 'AU'), ('ACGL', 'AU'), ('ANET', 'AU'), ('AJG', 'AU'), ('AIZ', 'AU'), ('T', 'AU'), ('ATO', 'AU'), ('ADSK', 'AU'), ('AZO', 'AU'), ('AVB', 'AU'), ('AVY', 'AU'), ('BKR', 'AU'), ('BALL', 'AU'), ('BAC', 'AU'), ('BBWI', 'AU'), ('BAX', 'AU'), ('BDX', 'AU'), ('WRB', 'AU'), ('BBY', 'AU'), ('BIO', 'AU'), ('TECH', 'AU'), ('BIIB', 'AU'), ('BLK', 'AU'), ('BK', 'AU'), ('BA', 'AU'), ('BKNG', 'AU'), ('BWA', 'AU'), ('BXP', 'AU'), ('BSX', 'AU'), ('BMY', 'AU'), ('AVGO', 'AU'), ('BR', 'AU'), ('BRO', 'AU'), ('BG', 'AU'), ('CHRW', 'AU'), ('CDNS', 'AU'), ('CZR', 'AU'), ('CPT', 'AU'), ('CPB', 'AU'), ('COF', 'AU'), ('CAH', 'AU'), ('KMX', 'AU'), ('CCL', 'AU'), ('CARR', 'AU'), ('CTLT', 'AU'), ('CAT', 'AU'), ('CBOE', 'AU'), ('CBRE', 'AU'), ('CDW', 'AU'), ('CE', 'AU'), ('CNC', 'AU'), ('CNP', 'AU'), ('CDAY', 'AU'), ('CF', 'AU'), ('CRL', 'AU'), ('SCHW', 'AU'), ('CHTR', 'AU'), ('CVX', 'AU'), ('CMG', 'AU'), ('CB', 'AU'), ('CHD', 'AU'), ('CI', 'AU'), ('CINF', 'AU'), ('CTAS', 'AU'), ('CSCO', 'AU'), ('C', 'AU'), ('CFG', 'AU'), ('CLX', 'AU'), ('CME', 'AU'), ('CMS', 'AU'), ('KO', 'AU'), ('CTSH', 'AU'), ('CL', 'AU'), ('CMCSA', 'AU'), ('CMA', 'AU'), ('CAG', 'AU'), ('COP', 'AU'), ('ED', 'AU'), ('STZ', 'AU'), ('CEG', 'AU'), ('COO', 'AU'), ('CPRT', 'AU'), ('GLW', 'AU'), ('CTVA', 'AU'), ('CSGP', 'AU'), ('COST', 'AU'), ('CTRA', 'AU'), ('CCI', 'AU'), ('CSX', 'AU'), ('CMI', 'AU'), ('CVS', 'AU'), ('DHI', 'AU'), ('DHR', 'AU'), ('DRI', 'AU'), ('DVA', 'AU'), ('DE', 'AU'), ('DAL', 'AU'), ('XRAY', 'AU'), ('DVN', 'AU'), ('DXCM', 'AU'), ('FANG', 'AU'), ('DLR', 'AU'), ('DFS', 'AU'), ('DISH', 'AU'), ('DIS', 'AU'), ('DG', 'AU'), ('DLTR', 'AU'), ('D', 'AU'), ('DPZ', 'AU'), ('DOV', 'AU'), ('DOW', 'AU'), ('DTE', 'AU'), ('DUK', 'AU'), ('DD', 'AU'), ('DXC', 'AU'), ('EMN', 'AU'), ('ETN', 'AU'), ('EBAY', 'AU'), ('ECL', 'AU'), ('EIX', 'AU'), ('EW', 'AU'), ('EA', 'AU'), ('ELV', 'AU'), ('LLY', 'AU'), ('EMR', 'AU'), ('ENPH', 'AU'), ('ETR', 'AU'), ('EOG', 'AU'), ('EPAM', 'AU'), ('EQT', 'AU'), ('EFX', 'AU'), ('EQIX', 'AU'), ('EQR', 'AU'), ('ESS', 'AU'), ('EL', 'AU'), ('ETSY', 'AU'), ('RE', 'AU'), ('EVRG', 'AU'), ('ES', 'AU'), ('EXC', 'AU'), ('EXPE', 'AU'), ('EXPD', 'AU'), ('EXR', 'AU'), ('XOM', 'AU'), ('FFIV', 'AU'), ('FDS', 'AU'), ('FICO', 'AU'), ('FAST', 'AU'), ('FRT', 'AU'), ('FDX', 'AU'), ('FITB', 'AU'), ('FRC', 'AU'), ('FSLR', 'AU'), ('FE', 'AU'), ('FIS', 'AU'), ('FISV', 'AU'), ('FLT', 'AU'), ('FMC', 'AU'), ('F', 'AU'), ('FTNT', 'AU'), ('FTV', 'AU'), ('FOXA', 'AU'), ('FOX', 'AU'), ('BEN', 'AU'), ('FCX', 'AU'), ('GRMN', 'AU'), ('IT', 'AU'), ('GEN', 'AU'), ('GNRC', 'AU'), ('GD', 'AU'), ('GE', 'AU'), ('GIS', 'AU'), ('GM', 'AU'), ('GPC', 'AU'), ('GILD', 'AU'), ('GL', 'AU'), ('GPN', 'AU'), ('GS', 'AU'), ('HAL', 'AU'), ('HIG', 'AU'), ('HAS', 'AU'), ('HCA', 'AU'), ('PEAK', 'AU'), ('HSIC', 'AU'), ('HSY', 'AU'), ('HES', 'AU'), ('HPE', 'AU'), ('HLT', 'AU'), ('HOLX', 'AU'), ('HD', 'AU'), ('HON', 'AU'), ('HRL', 'AU'), ('HST', 'AU'), ('HWM', 'AU'), ('HPQ', 'AU'), ('HUM', 'AU'), ('HBAN', 'AU'), ('HII', 'AU'), ('IBM', 'AU'), ('IEX', 'AU'), ('IDXX', 'AU'), ('ITW', 'AU'), ('ILMN', 'AU'), ('INCY', 'AU'), ('IR', 'AU'), ('PODD', 'AU'), ('INTC', 'AU'), ('ICE', 'AU'), ('IFF', 'AU'), ('IP', 'AU'), ('IPG', 'AU'), ('INTU', 'AU'), ('ISRG', 'AU'), ('IVZ', 'AU'), ('INVH', 'AU'), ('IQV', 'AU'), ('IRM', 'AU'), ('JBHT', 'AU'), ('JKHY', 'AU'), ('J', 'AU'), ('JNJ', 'AU'), ('JCI', 'AU'), ('JPM', 'AU'), ('JNPR', 'AU'), ('K', 'AU'), ('KDP', 'AU'), ('KEY', 'AU'), ('KEYS', 'AU'), ('KMB', 'AU'), ('KIM', 'AU'), ('KMI', 'AU'), ('KLAC', 'AU'), ('KHC', 'AU'), ('KR', 'AU'), ('LHX', 'AU'), ('LH', 'AU'), ('LRCX', 'AU'), ('LW', 'AU'), ('LVS', 'AU'), ('LDOS', 'AU'), ('LEN', 'AU'), ('LNC', 'AU'), ('LIN', 'AU'), ('LYV', 'AU'), ('LKQ', 'AU'), ('LMT', 'AU'), ('L', 'AU'), ('LOW', 'AU'), ('LYB', 'AU'), ('MTB', 'AU'), ('MRO', 'AU'), ('MPC', 'AU'), ('MKTX', 'AU'), ('MAR', 'AU'), ('MMC', 'AU'), ('MLM', 'AU'), ('MAS', 'AU'), ('MA', 'AU'), ('MTCH', 'AU'), ('MKC', 'AU'), ('MCD', 'AU'), ('MCK', 'AU'), ('MDT', 'AU'), ('MRK', 'AU'), ('META', 'AU'), ('MET', 'AU'), ('MTD', 'AU'), ('MGM', 'AU'), ('MCHP', 'AU'), ('MU', 'AU'), ('MSFT', 'AU'), ('MAA', 'AU'), ('MRNA', 'AU'), ('MHK', 'AU'), ('MOH', 'AU'), ('TAP', 'AU'), ('MDLZ', 'AU'), ('MPWR', 'AU'), ('MNST', 'AU'), ('MCO', 'AU'), ('MS', 'AU'), ('MOS', 'AU'), ('MSI', 'AU'), ('MSCI', 'AU'), ('NDAQ', 'AU'), ('NTAP', 'AU'), ('NFLX', 'AU'), ('NWL', 'AU'), ('NEM', 'AU'), ('NWSA', 'AU'), ('NWS', 'AU'), ('NEE', 'AU'), ('NKE', 'AU'), ('NI', 'AU'), ('NDSN', 'AU'), ('NSC', 'AU'), ('NTRS', 'AU'), ('NOC', 'AU'), ('NCLH', 'AU'), ('NRG', 'AU'), ('NUE', 'AU'), ('NVDA', 'AU'), ('NVR', 'AU'), ('NXPI', 'AU'), ('ORLY', 'AU'), ('OXY', 'AU'), ('ODFL', 'AU'), ('OMC', 'AU'), ('ON', 'AU'), ('OKE', 'AU'), ('ORCL', 'AU'), ('OGN', 'AU'), ('OTIS', 'AU'), ('PCAR', 'AU'), ('PKG', 'AU'), ('PARA', 'AU'), ('PH', 'AU'), ('PAYX', 'AU'), ('PAYC', 'AU'), ('PYPL', 'AU'), ('PNR', 'AU'), ('PEP', 'AU'), ('PKI', 'AU'), ('PFE', 'AU'), ('PCG', 'AU'), ('PM', 'AU'), ('PSX', 'AU'), ('PNW', 'AU'), ('PXD', 'AU'), ('PNC', 'AU'), ('POOL', 'AU'), ('PPG', 'AU'), ('PPL', 'AU'), ('PFG', 'AU'), ('PG', 'AU'), ('PGR', 'AU'), ('PLD', 'AU'), ('PRU', 'AU'), ('PEG', 'AU'), ('PTC', 'AU'), ('PSA', 'AU'), ('PHM', 'AU'), ('QRVO', 'AU'), ('PWR', 'AU'), ('QCOM', 'AU'), ('DGX', 'AU'), ('RL', 'AU'), ('RJF', 'AU'), ('RTX', 'AU'), ('O', 'AU'), ('REG', 'AU'), ('REGN', 'AU'), ('RF', 'AU'), ('RSG', 'AU'), ('RMD', 'AU'), ('RHI', 'AU'), ('ROK', 'AU'), ('ROL', 'AU'), ('ROP', 'AU'), ('ROST', 'AU'), ('RCL', 'AU'), ('SPGI', 'AU'), ('CRM', 'AU'), ('SBAC', 'AU'), ('SLB', 'AU'), ('STX', 'AU'), ('SEE', 'AU'), ('SRE', 'AU'), ('NOW', 'AU'), ('SHW', 'AU'), ('SPG', 'AU'), ('SWKS', 'AU'), ('SJM', 'AU'), ('SNA', 'AU'), ('SEDG', 'AU'), ('SO', 'AU'), ('LUV', 'AU'), ('SWK', 'AU'), ('SBUX', 'AU'), ('STT', 'AU'), ('STLD', 'AU'), ('STE', 'AU'), ('SYK', 'AU'), ('SYF', 'AU'), ('SNPS', 'AU'), ('SYY', 'AU'), ('TMUS', 'AU'), ('TROW', 'AU'), ('TTWO', 'AU'), ('TPR', 'AU'), ('TRGP', 'AU'), ('TGT', 'AU'), ('TEL', 'AU'), ('TDY', 'AU'), ('TFX', 'AU'), ('TER', 'AU'), ('TSLA', 'AU'), ('TXN', 'AU'), ('TXT', 'AU'), ('TMO', 'AU'), ('TJX', 'AU'), ('TSCO', 'AU'), ('TT', 'AU'), ('TDG', 'AU'), ('TRV', 'AU'), ('TRMB', 'AU'), ('TFC', 'AU'), ('TYL', 'AU'), ('TSN', 'AU'), ('USB', 'AU'), ('UDR', 'AU'), ('ULTA', 'AU'), ('UNP', 'AU'), ('UAL', 'AU'), ('UPS', 'AU'), ('URI', 'AU'), ('UNH', 'AU'), ('UHS', 'AU'), ('VLO', 'AU'), ('VTR', 'AU'), ('VRSN', 'AU'), ('VRSK', 'AU'), ('VZ', 'AU'), ('VRTX', 'AU'), ('VFC', 'AU'), ('VTRS', 'AU'), ('VICI', 'AU'), ('V', 'AU'), ('VMC', 'AU'), ('WAB', 'AU'), ('WBA', 'AU'), ('WMT', 'AU'), ('WBD', 'AU'), ('WM', 'AU'), ('WAT', 'AU'), ('WEC', 'AU'), ('WFC', 'AU'), ('WELL', 'AU'), ('WST', 'AU'), ('WDC', 'AU'), ('WRK', 'AU'), ('WY', 'AU'), ('WHR', 'AU'), ('WMB', 'AU'), ('WTW', 'AU'), ('GWW', 'AU'), ('WYNN', 'AU'), ('XEL', 'AU'), ('XYL', 'AU'), ('YUM', 'AU'), ('ZBRA', 'AU'), ('ZBH', 'AU'), ('ZION', 'AU'), ('ZTS', 'AU'), ('MMM', 'AD'), ('AOS', 'AD'), ('ABT', 'AD'), ('ABBV', 'AD'), ('ACN', 'AD'), ('ATVI', 'AD'), ('ADM', 'AD'), ('ADBE', 'AD'), ('ADP', 'AD'), ('AAP', 'AD'), ('AES', 'AD'), ('AFL', 'AD'), ('A', 'AD'), ('APD', 'AD'), ('AKAM', 'AD'), ('ALK', 'AD'), ('ALB', 'AD'), ('ARE', 'AD'), ('ALGN', 'AD'), ('ALLE', 'AD'), ('LNT', 'AD'), ('ALL', 'AD'), ('GOOGL', 'AD'), ('GOOG', 'AD'), ('MO', 'AD'), ('AMZN', 'AD'), ('AMCR', 'AD'), ('AMD', 'AD'), ('AEE', 'AD'), ('AAL', 'AD'), ('AEP', 'AD'), ('AXP', 'AD'), ('AIG', 'AD'), ('AMT', 'AD'), ('AWK', 'AD'), ('AMP', 'AD'), ('ABC', 'AD'), ('AME', 'AD'), ('AMGN', 'AD'), ('APH', 'AD'), ('ADI', 'AD'), ('ANSS', 'AD'), ('AON', 'AD'), ('APA', 'AD'), ('AAPL', 'AD'), ('AMAT', 'AD'), ('APTV', 'AD'), ('ACGL', 'AD'), ('ANET', 'AD'), ('AJG', 'AD'), ('AIZ', 'AD'), ('T', 'AD'), ('ATO', 'AD'), ('ADSK', 'AD'), ('AZO', 'AD'), ('AVB', 'AD'), ('AVY', 'AD'), ('BKR', 'AD'), ('BALL', 'AD'), ('BAC', 'AD'), ('BBWI', 'AD'), ('BAX', 'AD'), ('BDX', 'AD'), ('WRB', 'AD'), ('BBY', 'AD'), ('BIO', 'AD'), ('TECH', 'AD'), ('BIIB', 'AD'), ('BLK', 'AD'), ('BK', 'AD'), ('BA', 'AD'), ('BKNG', 'AD'), ('BWA', 'AD'), ('BXP', 'AD'), ('BSX', 'AD'), ('BMY', 'AD'), ('AVGO', 'AD'), ('BR', 'AD'), ('BRO', 'AD'), ('BG', 'AD'), ('CHRW', 'AD'), ('CDNS', 'AD'), ('CZR', 'AD'), ('CPT', 'AD'), ('CPB', 'AD'), ('COF', 'AD'), ('CAH', 'AD'), ('KMX', 'AD'), ('CCL', 'AD'), ('CARR', 'AD'), ('CTLT', 'AD'), ('CAT', 'AD'), ('CBOE', 'AD'), ('CBRE', 'AD'), ('CDW', 'AD'), ('CE', 'AD'), ('CNC', 'AD'), ('CNP', 'AD'), ('CDAY', 'AD'), ('CF', 'AD'), ('CRL', 'AD'), ('SCHW', 'AD'), ('CHTR', 'AD'), ('CVX', 'AD'), ('CMG', 'AD'), ('CB', 'AD'), ('CHD', 'AD'), ('CI', 'AD'), ('CINF', 'AD'), ('CTAS', 'AD'), ('CSCO', 'AD'), ('C', 'AD'), ('CFG', 'AD'), ('CLX', 'AD'), ('CME', 'AD'), ('CMS', 'AD'), ('KO', 'AD'), ('CTSH', 'AD'), ('CL', 'AD'), ('CMCSA', 'AD'), ('CMA', 'AD'), ('CAG', 'AD'), ('COP', 'AD'), ('ED', 'AD'), ('STZ', 'AD'), ('CEG', 'AD'), ('COO', 'AD'), ('CPRT', 'AD'), ('GLW', 'AD'), ('CTVA', 'AD'), ('CSGP', 'AD'), ('COST', 'AD'), ('CTRA', 'AD'), ('CCI', 'AD'), ('CSX', 'AD'), ('CMI', 'AD'), ('CVS', 'AD'), ('DHI', 'AD'), ('DHR', 'AD'), ('DRI', 'AD'), ('DVA', 'AD'), ('DE', 'AD'), ('DAL', 'AD'), ('XRAY', 'AD'), ('DVN', 'AD'), ('DXCM', 'AD'), ('FANG', 'AD'), ('DLR', 'AD'), ('DFS', 'AD'), ('DISH', 'AD'), ('DIS', 'AD'), ('DG', 'AD'), ('DLTR', 'AD'), ('D', 'AD'), ('DPZ', 'AD'), ('DOV', 'AD'), ('DOW', 'AD'), ('DTE', 'AD'), ('DUK', 'AD'), ('DD', 'AD'), ('DXC', 'AD'), ('EMN', 'AD'), ('ETN', 'AD'), ('EBAY', 'AD'), ('ECL', 'AD'), ('EIX', 'AD'), ('EW', 'AD'), ('EA', 'AD'), ('ELV', 'AD'), ('LLY', 'AD'), ('EMR', 'AD'), ('ENPH', 'AD'), ('ETR', 'AD'), ('EOG', 'AD'), ('EPAM', 'AD'), ('EQT', 'AD'), ('EFX', 'AD'), ('EQIX', 'AD'), ('EQR', 'AD'), ('ESS', 'AD'), ('EL', 'AD'), ('ETSY', 'AD'), ('RE', 'AD'), ('EVRG', 'AD'), ('ES', 'AD'), ('EXC', 'AD'), ('EXPE', 'AD'), ('EXPD', 'AD'), ('EXR', 'AD'), ('XOM', 'AD'), ('FFIV', 'AD'), ('FDS', 'AD'), ('FICO', 'AD'), ('FAST', 'AD'), ('FRT', 'AD'), ('FDX', 'AD'), ('FITB', 'AD'), ('FRC', 'AD'), ('FSLR', 'AD'), ('FE', 'AD'), ('FIS', 'AD'), ('FISV', 'AD'), ('FLT', 'AD'), ('FMC', 'AD'), ('F', 'AD'), ('FTNT', 'AD'), ('FTV', 'AD'), ('FOXA', 'AD'), ('FOX', 'AD'), ('BEN', 'AD'), ('FCX', 'AD'), ('GRMN', 'AD'), ('IT', 'AD'), ('GEN', 'AD'), ('GNRC', 'AD'), ('GD', 'AD'), ('GE', 'AD'), ('GIS', 'AD'), ('GM', 'AD'), ('GPC', 'AD'), ('GILD', 'AD'), ('GL', 'AD'), ('GPN', 'AD'), ('GS', 'AD'), ('HAL', 'AD'), ('HIG', 'AD'), ('HAS', 'AD'), ('HCA', 'AD'), ('PEAK', 'AD'), ('HSIC', 'AD'), ('HSY', 'AD'), ('HES', 'AD'), ('HPE', 'AD'), ('HLT', 'AD'), ('HOLX', 'AD'), ('HD', 'AD'), ('HON', 'AD'), ('HRL', 'AD'), ('HST', 'AD'), ('HWM', 'AD'), ('HPQ', 'AD'), ('HUM', 'AD'), ('HBAN', 'AD'), ('HII', 'AD'), ('IBM', 'AD'), ('IEX', 'AD'), ('IDXX', 'AD'), ('ITW', 'AD'), ('ILMN', 'AD'), ('INCY', 'AD'), ('IR', 'AD'), ('PODD', 'AD'), ('INTC', 'AD'), ('ICE', 'AD'), ('IFF', 'AD'), ('IP', 'AD'), ('IPG', 'AD'), ('INTU', 'AD'), ('ISRG', 'AD'), ('IVZ', 'AD'), ('INVH', 'AD'), ('IQV', 'AD'), ('IRM', 'AD'), ('JBHT', 'AD'), ('JKHY', 'AD'), ('J', 'AD'), ('JNJ', 'AD'), ('JCI', 'AD'), ('JPM', 'AD'), ('JNPR', 'AD'), ('K', 'AD'), ('KDP', 'AD'), ('KEY', 'AD'), ('KEYS', 'AD'), ('KMB', 'AD'), ('KIM', 'AD'), ('KMI', 'AD'), ('KLAC', 'AD'), ('KHC', 'AD'), ('KR', 'AD'), ('LHX', 'AD'), ('LH', 'AD'), ('LRCX', 'AD'), ('LW', 'AD'), ('LVS', 'AD'), ('LDOS', 'AD'), ('LEN', 'AD'), ('LNC', 'AD'), ('LIN', 'AD'), ('LYV', 'AD'), ('LKQ', 'AD'), ('LMT', 'AD'), ('L', 'AD'), ('LOW', 'AD'), ('LYB', 'AD'), ('MTB', 'AD'), ('MRO', 'AD'), ('MPC', 'AD'), ('MKTX', 'AD'), ('MAR', 'AD'), ('MMC', 'AD'), ('MLM', 'AD'), ('MAS', 'AD'), ('MA', 'AD'), ('MTCH', 'AD'), ('MKC', 'AD'), ('MCD', 'AD'), ('MCK', 'AD'), ('MDT', 'AD'), ('MRK', 'AD'), ('META', 'AD'), ('MET', 'AD'), ('MTD', 'AD'), ('MGM', 'AD'), ('MCHP', 'AD'), ('MU', 'AD'), ('MSFT', 'AD'), ('MAA', 'AD'), ('MRNA', 'AD'), ('MHK', 'AD'), ('MOH', 'AD'), ('TAP', 'AD'), ('MDLZ', 'AD'), ('MPWR', 'AD'), ('MNST', 'AD'), ('MCO', 'AD'), ('MS', 'AD'), ('MOS', 'AD'), ('MSI', 'AD'), ('MSCI', 'AD'), ('NDAQ', 'AD'), ('NTAP', 'AD'), ('NFLX', 'AD'), ('NWL', 'AD'), ('NEM', 'AD'), ('NWSA', 'AD'), ('NWS', 'AD'), ('NEE', 'AD'), ('NKE', 'AD'), ('NI', 'AD'), ('NDSN', 'AD'), ('NSC', 'AD'), ('NTRS', 'AD'), ('NOC', 'AD'), ('NCLH', 'AD'), ('NRG', 'AD'), ('NUE', 'AD'), ('NVDA', 'AD'), ('NVR', 'AD'), ('NXPI', 'AD'), ('ORLY', 'AD'), ('OXY', 'AD'), ('ODFL', 'AD'), ('OMC', 'AD'), ('ON', 'AD'), ('OKE', 'AD'), ('ORCL', 'AD'), ('OGN', 'AD'), ('OTIS', 'AD'), ('PCAR', 'AD'), ('PKG', 'AD'), ('PARA', 'AD'), ('PH', 'AD'), ('PAYX', 'AD'), ('PAYC', 'AD'), ('PYPL', 'AD'), ('PNR', 'AD'), ('PEP', 'AD'), ('PKI', 'AD'), ('PFE', 'AD'), ('PCG', 'AD'), ('PM', 'AD'), ('PSX', 'AD'), ('PNW', 'AD'), ('PXD', 'AD'), ('PNC', 'AD'), ('POOL', 'AD'), ('PPG', 'AD'), ('PPL', 'AD'), ('PFG', 'AD'), ('PG', 'AD'), ('PGR', 'AD'), ('PLD', 'AD'), ('PRU', 'AD'), ('PEG', 'AD'), ('PTC', 'AD'), ('PSA', 'AD'), ('PHM', 'AD'), ('QRVO', 'AD'), ('PWR', 'AD'), ('QCOM', 'AD'), ('DGX', 'AD'), ('RL', 'AD'), ('RJF', 'AD'), ('RTX', 'AD'), ('O', 'AD'), ('REG', 'AD'), ('REGN', 'AD'), ('RF', 'AD'), ('RSG', 'AD'), ('RMD', 'AD'), ('RHI', 'AD'), ('ROK', 'AD'), ('ROL', 'AD'), ('ROP', 'AD'), ('ROST', 'AD'), ('RCL', 'AD'), ('SPGI', 'AD'), ('CRM', 'AD'), ('SBAC', 'AD'), ('SLB', 'AD'), ('STX', 'AD'), ('SEE', 'AD'), ('SRE', 'AD'), ('NOW', 'AD'), ('SHW', 'AD'), ('SPG', 'AD'), ('SWKS', 'AD'), ('SJM', 'AD'), ('SNA', 'AD'), ('SEDG', 'AD'), ('SO', 'AD'), ('LUV', 'AD'), ('SWK', 'AD'), ('SBUX', 'AD'), ('STT', 'AD'), ('STLD', 'AD'), ('STE', 'AD'), ('SYK', 'AD'), ('SYF', 'AD'), ('SNPS', 'AD'), ('SYY', 'AD'), ('TMUS', 'AD'), ('TROW', 'AD'), ('TTWO', 'AD'), ('TPR', 'AD'), ('TRGP', 'AD'), ('TGT', 'AD'), ('TEL', 'AD'), ('TDY', 'AD'), ('TFX', 'AD'), ('TER', 'AD'), ('TSLA', 'AD'), ('TXN', 'AD'), ('TXT', 'AD'), ('TMO', 'AD'), ('TJX', 'AD'), ('TSCO', 'AD'), ('TT', 'AD'), ('TDG', 'AD'), ('TRV', 'AD'), ('TRMB', 'AD'), ('TFC', 'AD'), ('TYL', 'AD'), ('TSN', 'AD'), ('USB', 'AD'), ('UDR', 'AD'), ('ULTA', 'AD'), ('UNP', 'AD'), ('UAL', 'AD'), ('UPS', 'AD'), ('URI', 'AD'), ('UNH', 'AD'), ('UHS', 'AD'), ('VLO', 'AD'), ('VTR', 'AD'), ('VRSN', 'AD'), ('VRSK', 'AD'), ('VZ', 'AD'), ('VRTX', 'AD'), ('VFC', 'AD'), ('VTRS', 'AD'), ('VICI', 'AD'), ('V', 'AD'), ('VMC', 'AD'), ('WAB', 'AD'), ('WBA', 'AD'), ('WMT', 'AD'), ('WBD', 'AD'), ('WM', 'AD'), ('WAT', 'AD'), ('WEC', 'AD'), ('WFC', 'AD'), ('WELL', 'AD'), ('WST', 'AD'), ('WDC', 'AD'), ('WRK', 'AD'), ('WY', 'AD'), ('WHR', 'AD'), ('WMB', 'AD'), ('WTW', 'AD'), ('GWW', 'AD'), ('WYNN', 'AD'), ('XEL', 'AD'), ('XYL', 'AD'), ('YUM', 'AD'), ('ZBRA', 'AD'), ('ZBH', 'AD'), ('ZION', 'AD'), ('ZTS', 'AD')]\n"
          ]
        }
      ],
      "source": [
        "# Select features (columns) to be involved intro training and predictions\n",
        "cols = list(multi_factor)\n",
        "\n",
        "# Extract dates (will be used in visualization)\n",
        "datelist_train = multi_factor.index.values\n",
        "print('Training set shape == {}'.format(multi_factor.shape))\n",
        "print('All timestamps == {}'.format(len(datelist_train)))\n",
        "print('Featured selected: {}'.format(cols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "23feb6203fe74ed5ad5412e53c3835d8",
            "f2fdae44a22040e0b3c60654ba6b0353",
            "fd54f23a6c20497091414e821e46724c",
            "958dde2f5a1c439ca3408b436520b9f9",
            "c352d92a7118454da967cdda387e4bbe",
            "8ec5cae9e4184336a6c79a95ae46e0f8",
            "3f3efb60c6bc482698f30f0619a9350a",
            "5194fbdc39c740cba6d8920a87a212b9",
            "2bf7e40db1d64962804bb56f72f407db",
            "53c2584ec2104f5b90763de9905975ae",
            "b1c34a090910476fa7f5e7ac9aceb995"
          ]
        },
        "id": "LnHd9MnO98m6",
        "outputId": "886fd5ba-979e-4568-ba27-aa2a7b2fbb8a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23feb6203fe74ed5ad5412e53c3835d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_dataset (276, 500)\n",
            "x_dataset (276, 9, 500)\n"
          ]
        }
      ],
      "source": [
        "# get x_dataset, y_dataset\n",
        "multi_factor = multi_factor.astype(float)\n",
        "label_df = label_df.astype(float)\n",
        "x_dataset = []\n",
        "y_dataset = []\n",
        "\n",
        "for ticker in tqdm(SP500_ticker):\n",
        "  #print(ticker)\n",
        "  y_dataset.append(label_df[ticker])\n",
        "  temp = []\n",
        "  for tech in Technical_list:\n",
        "    temp.append(multi_factor[ticker][tech])\n",
        "  x_dataset.append(temp)\n",
        "\n",
        "y_dataset = np.array(y_dataset).T\n",
        "x_dataset = np.array(x_dataset).T\n",
        "\n",
        "print('y_dataset',y_dataset.shape)\n",
        "print('x_dataset',x_dataset.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_point = x_dataset.shape[0]-26\n",
        "\n",
        "#Preparation of test set\n",
        "x_train = x_dataset[0:train_point]\n",
        "y_train = y_dataset[0:train_point]\n",
        "\n",
        "x_test = x_dataset[train_point:]\n",
        "y_test = y_dataset[train_point:]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hg1zzb4mKHV",
        "outputId": "9dbe2f14-a666-4e81-bcba-19e47c4f2b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(250, 9, 500)\n",
            "(250, 500)\n",
            "(26, 9, 500)\n",
            "(26, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "2pOtLvBroqV3",
        "outputId": "319daa83-22e8-42e1-8261-447ef21e38b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# normalize the dataset\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nx_dataset = scaler.fit_transform(x_dataset)\\ny_dataset = scaler.fit_transform(y_dataset)\\nx_dataset.shape\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "n_future = 1   # Number of month we want top predict into the future\n",
        "n_past = 5     # Number of past month we want to use to predict the future\n",
        "\n",
        "'''\n",
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "x_dataset = scaler.fit_transform(x_dataset)\n",
        "y_dataset = scaler.fit_transform(y_dataset)\n",
        "x_dataset.shape\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmiDD4jKu0pK",
        "outputId": "123abef0-38a3-43fe-afbb-10d6df24ff1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(271, 5, 9, 500)\n",
            "(271, 500)\n"
          ]
        }
      ],
      "source": [
        "#Preparation of training set\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i in range(n_past, len(x_dataset) - n_future +1):\n",
        "  #print(i)\n",
        "  X.append(x_dataset[i - n_past:i,:])\n",
        "Y = y_dataset[n_past:]\n",
        "X, Y = np.array(X), np.array(Y)\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw3RFFmTyS7p",
        "outputId": "0ec5981f-f26f-4713-a0fb-f629a0fbeb16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(245, 5, 9, 500)\n",
            "(245, 500)\n",
            "(26, 5, 9, 500)\n",
            "(26, 500)\n"
          ]
        }
      ],
      "source": [
        "train_point = X.shape[0]-26\n",
        "\n",
        "#Preparation of test set\n",
        "x_train = X[0:train_point]\n",
        "y_train = Y[0:train_point]\n",
        "\n",
        "x_test = X[train_point:]\n",
        "y_test = Y[train_point:]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_dataset.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMHmNjyMkm74",
        "outputId": "54293ddd-d99b-4b04-c9cd-44ed63bd7d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGMRRVPl2znm"
      },
      "outputs": [],
      "source": [
        "# Initializing the Neural Network based on LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Adding 1st LSTM layer\n",
        "model.add(LSTM(units=1024, return_sequences=True, input_shape=( x_dataset.shape[1],x_dataset.shape[2])))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Adding 2nd LSTM layer\n",
        "model.add(LSTM(units=800, return_sequences=False))\n",
        "\n",
        "# Adding Dropout\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=512, activation='linear'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=500, activation='linear'))\n",
        "\n",
        "# Compiling the Neural Network\n",
        "model.compile(optimizer = Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "#model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkv80ta5Y9iy",
        "outputId": "09c4be99-03c2-4f0c-8221-123924354e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 11.7372\n",
            "Epoch 1: val_loss improved from inf to 2.14305, saving model to /content/drive/My Drive/FYP Data/weights.h5\n",
            "20/20 [==============================] - 11s 204ms/step - loss: 10.3345 - val_loss: 2.1431 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.5768\n",
            "Epoch 2: val_loss improved from 2.14305 to 1.58194, saving model to /content/drive/My Drive/FYP Data/weights.h5\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 1.5380 - val_loss: 1.5819 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 1.2121\n",
            "Epoch 3: val_loss did not improve from 1.58194\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 1.2114 - val_loss: 1.5941 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 1.1677\n",
            "Epoch 4: val_loss improved from 1.58194 to 1.50137, saving model to /content/drive/My Drive/FYP Data/weights.h5\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 1.1607 - val_loss: 1.5014 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 1.1203\n",
            "Epoch 5: val_loss did not improve from 1.50137\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 1.1102 - val_loss: 1.5601 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 1.0751\n",
            "Epoch 6: val_loss improved from 1.50137 to 1.48306, saving model to /content/drive/My Drive/FYP Data/weights.h5\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 1.0880 - val_loss: 1.4831 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.0762\n",
            "Epoch 7: val_loss did not improve from 1.48306\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 1.0762 - val_loss: 1.5228 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 1.0614\n",
            "Epoch 8: val_loss did not improve from 1.48306\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 1.0643 - val_loss: 1.5399 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 1.0688\n",
            "Epoch 9: val_loss did not improve from 1.48306\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 1.0705 - val_loss: 1.5037 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 1.0613\n",
            "Epoch 10: val_loss did not improve from 1.48306\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 1.0638 - val_loss: 1.5077 - lr: 0.0100\n",
            "CPU times: user 7.85 s, sys: 1.11 s, total: 8.97 s\n",
            "Wall time: 14.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
        "mcp = ModelCheckpoint(filepath='/content/drive/My Drive/FYP Data/weights.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
        "\n",
        "tb = TensorBoard('logs')\n",
        "\n",
        "history = model.fit(x_train, y_train, shuffle=True, epochs=10, callbacks=[es, rlr, mcp, tb], validation_split=0.2, verbose=1, batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43KXScI_3dkI",
        "outputId": "eed8374f-2373-4c02-cf90-3e94a28e1ec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10211084030855161"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/My Drive/FYP Data/weights.h5')\n",
        "#Model Evaluation\n",
        "predictions = model.predict(x_test)\n",
        "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsnatmsM3yh3"
      },
      "outputs": [],
      "source": [
        "#profit test\n",
        "test_period = time[n_past+245:]\n",
        "\n",
        "#calculate the top 10 stock we picked\n",
        "stock_selection_index = np.argsort(predictions)[:,-30:]\n",
        "stock_selection = []\n",
        "for index in stock_selection_index:\n",
        "  stock_list = []\n",
        "  for stock_i in index:\n",
        "    stock_list.append(SP500_ticker[stock_i])\n",
        "  stock_selection.append(stock_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_selection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9JDvsbtxAi2",
        "outputId": "23a7432a-0308-4272-98cd-73d25f55e146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'BDX',\n",
              "  'FDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'ARE',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'BDX',\n",
              "  'FDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'EIX',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'YUM',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'BDX',\n",
              "  'FDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'BDX',\n",
              "  'FDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'EIX',\n",
              "  'TSN',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'YUM',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'NEM',\n",
              "  'CI',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'BDX',\n",
              "  'FDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'YUM',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM']]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#S&P 500\n",
        "SP_start = 3638.35\n",
        "SP_end = 3839.5\n",
        "print(\"S&P 500 earn \", SP_end - SP_start)\n",
        "print(\"S&P 500 earn % \", (SP_end - SP_start)*100/SP_start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j_LI8A7Q-RC",
        "outputId": "418299cc-7eae-4c8b-e591-d71506aa1e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S&P 500 earn  201.1500000000001\n",
            "S&P 500 earn %  5.528604999519015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_data = pd.read_csv((\"drive/My Drive/FYP Data/price.csv\"),index_col = 0,header = [0,1])\n",
        "\n",
        "#trading simulate\n",
        "original_money = 0\n",
        "trading = 0\n",
        "for stock in stock_selection[0]:\n",
        "  original_money = original_money + stock_data[stock][\"Close\"][test_period[0]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[0]])\n",
        "\n",
        "\n",
        "trading = - original_money\n",
        "i = 0\n",
        "\n",
        "for stock_list in stock_selection:\n",
        "  if i==0 or 25:\n",
        "    i = i + 1\n",
        "    continue\n",
        "\n",
        "  for stock in stock_list:\n",
        "    trading = trading + stock_data[stock][\"Close\"][test_period[i-1]] - stock_data[stock][\"Close\"][test_period[i]]\n",
        "    #print(trading)\n",
        "  \n",
        "  i = i + 1\n",
        "\n",
        "end_money = 0\n",
        "\n",
        "for stock in stock_selection[-1]:\n",
        "  trading = trading + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  end_money = end_money + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[-1]])\n",
        "\n",
        "print('The money earned by LSTM with only Technical data is ',trading)\n",
        "print('The money earned by LSTM with only Technical data is %',trading*100/original_money)\n",
        "print('The money earned by LSTM with only Technical data is %(unchange)',(end_money-original_money)*100/original_money)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRjUlNhuRPwV",
        "outputId": "092b995e-f70f-4d0e-98c1-b1a29533a3db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The money earned by LSTM with only Technical data is  364.3528289794922\n",
            "The money earned by LSTM with only Technical data is % 10.3114235691007\n",
            "The money earned by LSTM with only Technical data is %(unchange) 10.3114235691007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('LSTM model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "Upgpszs6RI1d",
        "outputId": "7ee18067-69c2-4ffc-dbc6-a46672a6c40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'val_loss', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_selection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD9_OnOhnM3S",
        "outputId": "0bdd705e-c5e4-4d38-c8d7-04c2e5283aea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'BDX',\n",
              "  'FDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'ARE',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'BDX',\n",
              "  'FDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'EIX',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'YUM',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'BDX',\n",
              "  'FDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'BDX',\n",
              "  'FDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'EIX',\n",
              "  'TSN',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'YUM',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'NEM',\n",
              "  'CI',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'BDX',\n",
              "  'FDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'ARE',\n",
              "  'ROP',\n",
              "  'YUM',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM'],\n",
              " ['PKI',\n",
              "  'WEC',\n",
              "  'HAL',\n",
              "  'CI',\n",
              "  'NEM',\n",
              "  'KR',\n",
              "  'FDX',\n",
              "  'BDX',\n",
              "  'TTWO',\n",
              "  'STZ',\n",
              "  'MO',\n",
              "  'PXD',\n",
              "  'CPRT',\n",
              "  'TSN',\n",
              "  'EIX',\n",
              "  'SO',\n",
              "  'HSY',\n",
              "  'BALL',\n",
              "  'SRE',\n",
              "  'ACGL',\n",
              "  'CTSH',\n",
              "  'YUM',\n",
              "  'ROP',\n",
              "  'ARE',\n",
              "  'XEL',\n",
              "  'STLD',\n",
              "  'MKC',\n",
              "  'UNP',\n",
              "  'EW',\n",
              "  'XOM']]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXOa8Mcl36fM"
      },
      "outputs": [],
      "source": [
        "df_stock_selection = pd.DataFrame (stock_selection)\n",
        "df_stock_selection.to_csv(\"drive/My Drive/FYP Data/LSTM_Tech_long_123_new.csv\",index=True, header=True )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GRU with Technical Data"
      ],
      "metadata": {
        "id": "9Py2rZh1gbEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# The GRU architecture\n",
        "regressorGRU = Sequential()\n",
        "# First GRU layer with Dropout regularisation\n",
        "regressorGRU.add(GRU(units=1024, return_sequences=True, input_shape=(x_dataset.shape[1],x_dataset.shape[2]), activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# Second GRU layer\n",
        "regressorGRU.add(GRU(units=512, return_sequences=True, input_shape=(x_dataset.shape[1],x_dataset.shape[2]), activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# Third GRU layer\n",
        "regressorGRU.add(GRU(units=512, return_sequences=True, input_shape=(x_dataset.shape[1],x_dataset.shape[2]), activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# Fourth GRU layer\n",
        "regressorGRU.add(GRU(units=500, activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# The output layer\n",
        "regressorGRU.add(Dense(units=1024))\n",
        "# The output layer\n",
        "regressorGRU.add(Dense(units=512))\n",
        "# The output layer\n",
        "regressorGRU.add(Dense(units=500))\n",
        "# Compiling the RNN\n",
        "regressorGRU.compile(optimizer = Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "#regressorGRU.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
        "mcp = ModelCheckpoint(filepath='/content/drive/My Drive/FYP Data/weights_GRU_Techincal.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
        "\n",
        "tb = TensorBoard('logs')\n",
        "\n",
        "# Fitting to the training set\n",
        "history = regressorGRU.fit(x_train, y_train, shuffle=False, epochs=10, callbacks=[es, rlr, mcp, tb], validation_split=0.2, verbose=1, batch_size=10)"
      ],
      "metadata": {
        "id": "lLTYfNHngalB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bac00c3-84ef-4a50-a4d5-0fcc0a38990e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 917.6290 \n",
            "Epoch 1: val_loss improved from inf to 30.98263, saving model to /content/drive/My Drive/FYP Data/weights_GRU_Techincal.h5\n",
            "20/20 [==============================] - 8s 196ms/step - loss: 880.0453 - val_loss: 30.9826 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 76.6453\n",
            "Epoch 2: val_loss improved from 30.98263 to 20.64087, saving model to /content/drive/My Drive/FYP Data/weights_GRU_Techincal.h5\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 71.1983 - val_loss: 20.6409 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 30.2903\n",
            "Epoch 3: val_loss improved from 20.64087 to 10.73813, saving model to /content/drive/My Drive/FYP Data/weights_GRU_Techincal.h5\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 26.7685 - val_loss: 10.7381 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 5.2757\n",
            "Epoch 4: val_loss improved from 10.73813 to 1.72631, saving model to /content/drive/My Drive/FYP Data/weights_GRU_Techincal.h5\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 5.2757 - val_loss: 1.7263 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 2.3253\n",
            "Epoch 5: val_loss improved from 1.72631 to 1.62876, saving model to /content/drive/My Drive/FYP Data/weights_GRU_Techincal.h5\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 2.3325 - val_loss: 1.6288 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 1.5059\n",
            "Epoch 6: val_loss improved from 1.62876 to 1.48100, saving model to /content/drive/My Drive/FYP Data/weights_GRU_Techincal.h5\n",
            "20/20 [==============================] - 1s 33ms/step - loss: 1.5793 - val_loss: 1.4810 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 1.4343\n",
            "Epoch 7: val_loss improved from 1.48100 to 1.46772, saving model to /content/drive/My Drive/FYP Data/weights_GRU_Techincal.h5\n",
            "20/20 [==============================] - 1s 53ms/step - loss: 1.5130 - val_loss: 1.4677 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 1.3966\n",
            "Epoch 8: val_loss did not improve from 1.46772\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 1.4545 - val_loss: 1.4734 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 1.3009\n",
            "Epoch 9: val_loss did not improve from 1.46772\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 1.3740 - val_loss: 1.4783 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 1.2699\n",
            "Epoch 10: val_loss did not improve from 1.46772\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 1.3440 - val_loss: 1.4770 - lr: 0.0100\n",
            "CPU times: user 11.3 s, sys: 801 ms, total: 12.1 s\n",
            "Wall time: 14.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regressorGRU = keras.models.load_model('/content/drive/My Drive/FYP Data/weights_GRU_Techincal.h5')\n",
        "#Model Evaluation\n",
        "predictions = regressorGRU.predict(x_test)\n",
        "#predictions = scaler.inverse_transform(predictions)\n",
        "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "rmse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIJxhS3nh4Kh",
        "outputId": "6e3d0691-98fc-4d91-ad31-878ae29b342e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 997ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1801603451050245"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#profit test\n",
        "test_period = time[n_past+245:]\n",
        "\n",
        "#calculate the top 10 stock we picked\n",
        "stock_selection_index = np.argsort(predictions)[:,-30:]\n",
        "stock_selection = []\n",
        "for index in stock_selection_index:\n",
        "  stock_list = []\n",
        "  for stock_i in index:\n",
        "    stock_list.append(SP500_ticker[stock_i])\n",
        "  stock_selection.append(stock_list)"
      ],
      "metadata": {
        "id": "ZlJ5uzyuG_s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_selection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICCNREGKxXnz",
        "outputId": "b5fe06c7-b2ef-4b18-e2e4-0cd3cec2a38d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR'],\n",
              " ['NI',\n",
              "  'PTC',\n",
              "  'ALGN',\n",
              "  'DPZ',\n",
              "  'TSCO',\n",
              "  'EXPD',\n",
              "  'CL',\n",
              "  'ROP',\n",
              "  'WBA',\n",
              "  'NFLX',\n",
              "  'ES',\n",
              "  'IP',\n",
              "  'AME',\n",
              "  'VTR',\n",
              "  'GL',\n",
              "  'ALL',\n",
              "  'NKE',\n",
              "  'HRL',\n",
              "  'BIO',\n",
              "  'PXD',\n",
              "  'CSGP',\n",
              "  'APA',\n",
              "  'MO',\n",
              "  'BWA',\n",
              "  'ZBH',\n",
              "  'AOS',\n",
              "  'SHW',\n",
              "  'BALL',\n",
              "  'MSI',\n",
              "  'TPR']]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trading simulate\n",
        "original_money = 0\n",
        "trading = 0\n",
        "for stock in stock_selection[0]:\n",
        "  original_money = original_money + stock_data[stock][\"Close\"][test_period[0]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[0]])\n",
        "\n",
        "\n",
        "trading = - original_money\n",
        "i = 0\n",
        "\n",
        "for stock_list in stock_selection:\n",
        "  if i==0 or 25:\n",
        "    i = i + 1\n",
        "    continue\n",
        "\n",
        "  for stock in stock_list:\n",
        "    trading = trading + stock_data[stock][\"Close\"][test_period[i-1]] - stock_data[stock][\"Close\"][test_period[i]]\n",
        "    #print(trading)\n",
        "  \n",
        "  i = i + 1\n",
        "\n",
        "end_money = 0\n",
        "\n",
        "for stock in stock_selection[-1]:\n",
        "  trading = trading + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  end_money = end_money + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[-1]])\n",
        "\n",
        "print('The money earned by GRU with only Technical data is ',trading)\n",
        "print('The money earned by GRU with only Technical data is %',trading*100/original_money)\n",
        "print('The money earned by GRU with only Technical data is %(unchange)',(end_money-original_money)*100/original_money)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNU_XRPmKRF7",
        "outputId": "5a391334-dce5-47cc-ad91-0a1693b81f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The money earned by GRU with only Technical data is  -296.919810295105\n",
            "The money earned by GRU with only Technical data is % -6.564027020235213\n",
            "The money earned by GRU with only Technical data is %(unchange) -6.564027020235213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('GRU model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "SQtKWkp3D-TM",
        "outputId": "1a20a75d-2ab9-47ef-9ecd-2d982587eeb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'val_loss', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_stock_selection = pd.DataFrame (stock_selection)\n",
        "df_stock_selection.to_csv(\"drive/My Drive/FYP Data/GRU_Tech_long_123_new.csv\",index=True, header=True )"
      ],
      "metadata": {
        "id": "pI0BGUz5xmN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "0sePGF1LjhxT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "LAIH8vkwptqL",
        "outputId": "2e55c470-7441-4edd-cace-c0818b8c6ad5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 FOXA                                                         \\\n",
              "                 Open       High        Low      Close  Adj Close     Volume   \n",
              "Date                                                                           \n",
              "2000-01-31        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-02-29        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-03-31        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-04-28        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-05-31        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "...               ...        ...        ...        ...        ...        ...   \n",
              "2022-08-31  34.400002  34.689999  34.160000  34.180000  33.940510  2479900.0   \n",
              "2022-09-30  30.719999  31.360001  30.549999  30.680000  30.465034  3276000.0   \n",
              "2022-10-31  28.840000  29.000000  28.469999  28.870001  28.667717  3363700.0   \n",
              "2022-11-30  31.629999  32.465000  31.250000  32.450001  32.222633  4222200.0   \n",
              "2022-12-30  30.299999  30.459999  29.920000  30.370001  30.157207  2620900.0   \n",
              "\n",
              "                   ZTS                                      ...             \\\n",
              "                  Open        High         Low       Close  ...    peRatio   \n",
              "Date                                                        ...              \n",
              "2000-01-31         NaN         NaN         NaN         NaN  ...   0.000000   \n",
              "2000-02-29         NaN         NaN         NaN         NaN  ...   0.000000   \n",
              "2000-03-31         NaN         NaN         NaN         NaN  ...   0.000000   \n",
              "2000-04-28         NaN         NaN         NaN         NaN  ...   0.000000   \n",
              "2000-05-31         NaN         NaN         NaN         NaN  ...   0.000000   \n",
              "...                ...         ...         ...         ...  ...        ...   \n",
              "2022-08-31  158.160004  159.410004  156.210007  156.529999  ...  38.179726   \n",
              "2022-09-30  150.419998  152.029999  148.039993  148.289993  ...  32.783583   \n",
              "2022-10-31  152.110001  153.339996  149.839996  150.779999  ...  32.783583   \n",
              "2022-11-30  148.089996  154.179993  146.910004  154.139999  ...  32.783583   \n",
              "2022-12-30  147.199997  147.789993  144.740005  146.550003  ...  37.264629   \n",
              "\n",
              "                                                                       \\\n",
              "              pbRatio  evToSales receivablesTurnover payablesTurnover   \n",
              "Date                                                                    \n",
              "2000-01-31   0.000000   0.000000            0.000000         0.000000   \n",
              "2000-02-29   0.000000   0.000000            0.000000         0.000000   \n",
              "2000-03-31   0.000000   0.000000            0.000000         0.000000   \n",
              "2000-04-28   0.000000   0.000000            0.000000         0.000000   \n",
              "2000-05-31   0.000000   0.000000            0.000000         0.000000   \n",
              "...               ...        ...                 ...              ...   \n",
              "2022-08-31  17.639367  41.361745            1.589466         1.453488   \n",
              "2022-09-30  14.876702  36.771260            1.683768         1.627346   \n",
              "2022-10-31  14.876702  36.771260            1.683768         1.627346   \n",
              "2022-11-30  14.876702  36.771260            1.683768         1.627346   \n",
              "2022-12-30  15.599541  35.232831            1.679012         1.612346   \n",
              "\n",
              "                                                                     \\\n",
              "           debtToAssets inventoryTurnover       roe revenuePerShare   \n",
              "Date                                                                  \n",
              "2000-01-31     0.000000          0.000000  0.000000        0.000000   \n",
              "2000-02-29     0.000000          0.000000  0.000000        0.000000   \n",
              "2000-03-31     0.000000          0.000000  0.000000        0.000000   \n",
              "2000-04-28     0.000000          0.000000  0.000000        0.000000   \n",
              "2000-05-31     0.000000          0.000000  0.000000        0.000000   \n",
              "...                 ...               ...       ...             ...   \n",
              "2022-08-31     0.667393          0.283447  0.115502        4.365957   \n",
              "2022-09-30     0.659061          0.263569  0.113446        4.279607   \n",
              "2022-10-31     0.659061          0.263569  0.113446        4.279607   \n",
              "2022-11-30     0.659061          0.263569  0.113446        4.279607   \n",
              "2022-12-30     0.704992          0.278465  0.104654        4.350691   \n",
              "\n",
              "                         \n",
              "           cashPerShare  \n",
              "Date                     \n",
              "2000-01-31     0.000000  \n",
              "2000-02-29     0.000000  \n",
              "2000-03-31     0.000000  \n",
              "2000-04-28     0.000000  \n",
              "2000-05-31     0.000000  \n",
              "...                 ...  \n",
              "2022-08-31     5.634043  \n",
              "2022-09-30     5.350577  \n",
              "2022-10-31     5.350577  \n",
              "2022-11-30     5.350577  \n",
              "2022-12-30     7.637169  \n",
              "\n",
              "[276 rows x 12000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b59a89b0-73e1-4267-b912-728bbb0a5eb8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">FOXA</th>\n",
              "      <th colspan=\"15\" halign=\"left\">ZTS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>...</th>\n",
              "      <th>peRatio</th>\n",
              "      <th>pbRatio</th>\n",
              "      <th>evToSales</th>\n",
              "      <th>receivablesTurnover</th>\n",
              "      <th>payablesTurnover</th>\n",
              "      <th>debtToAssets</th>\n",
              "      <th>inventoryTurnover</th>\n",
              "      <th>roe</th>\n",
              "      <th>revenuePerShare</th>\n",
              "      <th>cashPerShare</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-29</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-04-28</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-05-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>34.400002</td>\n",
              "      <td>34.689999</td>\n",
              "      <td>34.160000</td>\n",
              "      <td>34.180000</td>\n",
              "      <td>33.940510</td>\n",
              "      <td>2479900.0</td>\n",
              "      <td>158.160004</td>\n",
              "      <td>159.410004</td>\n",
              "      <td>156.210007</td>\n",
              "      <td>156.529999</td>\n",
              "      <td>...</td>\n",
              "      <td>38.179726</td>\n",
              "      <td>17.639367</td>\n",
              "      <td>41.361745</td>\n",
              "      <td>1.589466</td>\n",
              "      <td>1.453488</td>\n",
              "      <td>0.667393</td>\n",
              "      <td>0.283447</td>\n",
              "      <td>0.115502</td>\n",
              "      <td>4.365957</td>\n",
              "      <td>5.634043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>30.719999</td>\n",
              "      <td>31.360001</td>\n",
              "      <td>30.549999</td>\n",
              "      <td>30.680000</td>\n",
              "      <td>30.465034</td>\n",
              "      <td>3276000.0</td>\n",
              "      <td>150.419998</td>\n",
              "      <td>152.029999</td>\n",
              "      <td>148.039993</td>\n",
              "      <td>148.289993</td>\n",
              "      <td>...</td>\n",
              "      <td>32.783583</td>\n",
              "      <td>14.876702</td>\n",
              "      <td>36.771260</td>\n",
              "      <td>1.683768</td>\n",
              "      <td>1.627346</td>\n",
              "      <td>0.659061</td>\n",
              "      <td>0.263569</td>\n",
              "      <td>0.113446</td>\n",
              "      <td>4.279607</td>\n",
              "      <td>5.350577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>28.840000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>28.469999</td>\n",
              "      <td>28.870001</td>\n",
              "      <td>28.667717</td>\n",
              "      <td>3363700.0</td>\n",
              "      <td>152.110001</td>\n",
              "      <td>153.339996</td>\n",
              "      <td>149.839996</td>\n",
              "      <td>150.779999</td>\n",
              "      <td>...</td>\n",
              "      <td>32.783583</td>\n",
              "      <td>14.876702</td>\n",
              "      <td>36.771260</td>\n",
              "      <td>1.683768</td>\n",
              "      <td>1.627346</td>\n",
              "      <td>0.659061</td>\n",
              "      <td>0.263569</td>\n",
              "      <td>0.113446</td>\n",
              "      <td>4.279607</td>\n",
              "      <td>5.350577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>31.629999</td>\n",
              "      <td>32.465000</td>\n",
              "      <td>31.250000</td>\n",
              "      <td>32.450001</td>\n",
              "      <td>32.222633</td>\n",
              "      <td>4222200.0</td>\n",
              "      <td>148.089996</td>\n",
              "      <td>154.179993</td>\n",
              "      <td>146.910004</td>\n",
              "      <td>154.139999</td>\n",
              "      <td>...</td>\n",
              "      <td>32.783583</td>\n",
              "      <td>14.876702</td>\n",
              "      <td>36.771260</td>\n",
              "      <td>1.683768</td>\n",
              "      <td>1.627346</td>\n",
              "      <td>0.659061</td>\n",
              "      <td>0.263569</td>\n",
              "      <td>0.113446</td>\n",
              "      <td>4.279607</td>\n",
              "      <td>5.350577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>30.299999</td>\n",
              "      <td>30.459999</td>\n",
              "      <td>29.920000</td>\n",
              "      <td>30.370001</td>\n",
              "      <td>30.157207</td>\n",
              "      <td>2620900.0</td>\n",
              "      <td>147.199997</td>\n",
              "      <td>147.789993</td>\n",
              "      <td>144.740005</td>\n",
              "      <td>146.550003</td>\n",
              "      <td>...</td>\n",
              "      <td>37.264629</td>\n",
              "      <td>15.599541</td>\n",
              "      <td>35.232831</td>\n",
              "      <td>1.679012</td>\n",
              "      <td>1.612346</td>\n",
              "      <td>0.704992</td>\n",
              "      <td>0.278465</td>\n",
              "      <td>0.104654</td>\n",
              "      <td>4.350691</td>\n",
              "      <td>7.637169</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>276 rows Ã— 12000 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b59a89b0-73e1-4267-b912-728bbb0a5eb8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b59a89b0-73e1-4267-b912-728bbb0a5eb8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b59a89b0-73e1-4267-b912-728bbb0a5eb8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "#read data\n",
        "multi_factor_data = pd.read_csv(\"drive/My Drive/FYP Data/multi_factor_data_improved.csv\",index_col = 0,header = [0,1])\n",
        "multi_factor_data = multi_factor_data[84:]\n",
        "multi_factor_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKESTwAWvpx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3d904a-0806-4f94-ab7c-b3e16bcf51bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['2000-01-31', '2000-02-29', '2000-03-31', '2000-04-28',\n",
              "       '2000-05-31', '2000-06-30', '2000-07-31', '2000-08-31',\n",
              "       '2000-09-29', '2000-10-31', '2000-11-30', '2000-12-29',\n",
              "       '2001-01-31', '2001-02-28', '2001-03-30', '2001-04-30',\n",
              "       '2001-05-31', '2001-06-29', '2001-07-31', '2001-08-31',\n",
              "       '2001-09-28', '2001-10-31', '2001-11-30', '2001-12-31',\n",
              "       '2002-01-31', '2002-02-28', '2002-03-28', '2002-04-30',\n",
              "       '2002-05-31', '2002-06-28', '2002-07-31', '2002-08-30',\n",
              "       '2002-09-30', '2002-10-31', '2002-11-29', '2002-12-31',\n",
              "       '2003-01-31', '2003-02-28', '2003-03-31', '2003-04-30',\n",
              "       '2003-05-30', '2003-06-30', '2003-07-31', '2003-08-29',\n",
              "       '2003-09-30', '2003-10-31', '2003-11-28', '2003-12-31',\n",
              "       '2004-01-30', '2004-02-27', '2004-03-31', '2004-04-30',\n",
              "       '2004-05-28', '2004-06-30', '2004-07-30', '2004-08-31',\n",
              "       '2004-09-30', '2004-10-29', '2004-11-30', '2004-12-31',\n",
              "       '2005-01-31', '2005-02-28', '2005-03-31', '2005-04-29',\n",
              "       '2005-05-31', '2005-06-30', '2005-07-29', '2005-08-31',\n",
              "       '2005-09-30', '2005-10-31', '2005-11-30', '2005-12-30',\n",
              "       '2006-01-31', '2006-02-28', '2006-03-31', '2006-04-28',\n",
              "       '2006-05-31', '2006-06-30', '2006-07-31', '2006-08-31',\n",
              "       '2006-09-29', '2006-10-31', '2006-11-30', '2006-12-29',\n",
              "       '2007-01-31', '2007-02-28', '2007-03-30', '2007-04-30',\n",
              "       '2007-05-31', '2007-06-29', '2007-07-31', '2007-08-31',\n",
              "       '2007-09-28', '2007-10-31', '2007-11-30', '2007-12-31',\n",
              "       '2008-01-31', '2008-02-29', '2008-03-31', '2008-04-30',\n",
              "       '2008-05-30', '2008-06-30', '2008-07-31', '2008-08-29',\n",
              "       '2008-09-30', '2008-10-31', '2008-11-28', '2008-12-31',\n",
              "       '2009-01-30', '2009-02-27', '2009-03-31', '2009-04-30',\n",
              "       '2009-05-29', '2009-06-30', '2009-07-31', '2009-08-31',\n",
              "       '2009-09-30', '2009-10-30', '2009-11-30', '2009-12-31',\n",
              "       '2010-01-29', '2010-02-26', '2010-03-31', '2010-04-30',\n",
              "       '2010-05-28', '2010-06-30', '2010-07-30', '2010-08-31',\n",
              "       '2010-09-30', '2010-10-29', '2010-11-30', '2010-12-31',\n",
              "       '2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',\n",
              "       '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',\n",
              "       '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30',\n",
              "       '2012-01-31', '2012-02-29', '2012-03-30', '2012-04-30',\n",
              "       '2012-05-31', '2012-06-29', '2012-07-31', '2012-08-31',\n",
              "       '2012-09-28', '2012-10-31', '2012-11-30', '2012-12-31',\n",
              "       '2013-01-31', '2013-02-28', '2013-03-28', '2013-04-30',\n",
              "       '2013-05-31', '2013-06-28', '2013-07-31', '2013-08-30',\n",
              "       '2013-09-30', '2013-10-31', '2013-11-29', '2013-12-31',\n",
              "       '2014-01-31', '2014-02-28', '2014-03-31', '2014-04-30',\n",
              "       '2014-05-30', '2014-06-30', '2014-07-31', '2014-08-29',\n",
              "       '2014-09-30', '2014-10-31', '2014-11-28', '2014-12-31',\n",
              "       '2015-01-30', '2015-02-27', '2015-03-31', '2015-04-30',\n",
              "       '2015-05-29', '2015-06-30', '2015-07-31', '2015-08-31',\n",
              "       '2015-09-30', '2015-10-30', '2015-11-30', '2015-12-31',\n",
              "       '2016-01-29', '2016-02-29', '2016-03-31', '2016-04-29',\n",
              "       '2016-05-31', '2016-06-30', '2016-07-29', '2016-08-31',\n",
              "       '2016-09-30', '2016-10-31', '2016-11-30', '2016-12-30',\n",
              "       '2017-01-31', '2017-02-28', '2017-03-31', '2017-04-28',\n",
              "       '2017-05-31', '2017-06-30', '2017-07-31', '2017-08-31',\n",
              "       '2017-09-29', '2017-10-31', '2017-11-30', '2017-12-29',\n",
              "       '2018-01-31', '2018-02-28', '2018-03-29', '2018-04-30',\n",
              "       '2018-05-31', '2018-06-29', '2018-07-31', '2018-08-31',\n",
              "       '2018-09-28', '2018-10-31', '2018-11-30', '2018-12-31',\n",
              "       '2019-01-31', '2019-02-28', '2019-03-29', '2019-04-30',\n",
              "       '2019-05-31', '2019-06-28', '2019-07-31', '2019-08-30',\n",
              "       '2019-09-30', '2019-10-31', '2019-11-29', '2019-12-31',\n",
              "       '2020-01-31', '2020-02-28', '2020-03-31', '2020-04-30',\n",
              "       '2020-05-29', '2020-06-30', '2020-07-31', '2020-08-31',\n",
              "       '2020-09-30', '2020-10-30', '2020-11-30', '2020-12-31',\n",
              "       '2021-01-29', '2021-02-26', '2021-03-31', '2021-04-30',\n",
              "       '2021-05-28', '2021-06-30', '2021-07-30', '2021-08-31',\n",
              "       '2021-09-30', '2021-10-29', '2021-11-30', '2021-12-31',\n",
              "       '2022-01-31', '2022-02-28', '2022-03-31', '2022-04-29',\n",
              "       '2022-05-31', '2022-06-30', '2022-07-29', '2022-08-31',\n",
              "       '2022-09-30', '2022-10-31', '2022-11-30', '2022-12-30'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "multi_factor_data[np.isnan(multi_factor_data)] = 0\n",
        "#get time list\n",
        "\n",
        "time = multi_factor_data.index.values\n",
        "time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_df = pd.read_csv(\"drive/My Drive/FYP Data/Long_label_1234.csv\",index_col = 0)\n",
        "label_df = label_df.reindex(index=label_df.index[::-1])\n",
        "label_df.reset_index()\n",
        "label_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "8k9mlk87jsUC",
        "outputId": "a92e47f5-be95-4b18-da8e-beef01e07e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            MMM  AOS  ABT  ABBV  ACN  ATVI  ADM  ADBE  ADP  AAP  ...  WTW  \\\n",
              "Date                                                             ...        \n",
              "2000-01-31    2    1    3     0    0     1    1     3    2    0  ...    0   \n",
              "2000-02-29    1    2    2     0    0     1    1     2    2    0  ...    0   \n",
              "2000-03-31    2    3    3     0    0     1    1     3    3    0  ...    0   \n",
              "2000-04-28    2    2    3     0    0     2    3     1    2    0  ...    0   \n",
              "2000-05-31    2    2    3     0    0     3    1     3    2    0  ...    0   \n",
              "...         ...  ...  ...   ...  ...   ...  ...   ...  ...  ...  ...  ...   \n",
              "2022-08-31    1    0    3     3    1     3    2     0    2    2  ...    3   \n",
              "2022-09-30    2    2    0     1    2     0    3     2    1    3  ...    1   \n",
              "2022-10-31    0    3    2     2    1     0    0     2    2    0  ...    3   \n",
              "2022-11-30    1    1    3     3    0     3    1     2    0    2  ...    3   \n",
              "2022-12-30    0    3    0     0    1     0    0     2    0    1  ...    1   \n",
              "\n",
              "            GWW  WYNN  XEL  XYL  YUM  ZBRA  ZBH  ZION  ZTS  \n",
              "Date                                                        \n",
              "2000-01-31    2     0    2    0    2     3    0     2    0  \n",
              "2000-02-29    3     0    2    0    3     1    0     1    0  \n",
              "2000-03-31    1     0    3    0    3     3    0     2    0  \n",
              "2000-04-28    1     0    2    0    1     1    0     3    0  \n",
              "2000-05-31    1     0    1    0    2     1    0     2    0  \n",
              "...         ...   ...  ...  ...  ...   ...  ...   ...  ...  \n",
              "2022-08-31    1     3    0    3    3     0    3     2    3  \n",
              "2022-09-30    3     0    0    3    2     1    1     0    0  \n",
              "2022-10-31    1     3    2    2    2     0    1     0    0  \n",
              "2022-11-30    0     3    3    2    3     1    3     1    1  \n",
              "2022-12-30    1     3    0    0    1     3    0     2    3  \n",
              "\n",
              "[276 rows x 500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb1f010c-77cc-46c9-9194-26e8a4e1d738\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MMM</th>\n",
              "      <th>AOS</th>\n",
              "      <th>ABT</th>\n",
              "      <th>ABBV</th>\n",
              "      <th>ACN</th>\n",
              "      <th>ATVI</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADBE</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AAP</th>\n",
              "      <th>...</th>\n",
              "      <th>WTW</th>\n",
              "      <th>GWW</th>\n",
              "      <th>WYNN</th>\n",
              "      <th>XEL</th>\n",
              "      <th>XYL</th>\n",
              "      <th>YUM</th>\n",
              "      <th>ZBRA</th>\n",
              "      <th>ZBH</th>\n",
              "      <th>ZION</th>\n",
              "      <th>ZTS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-31</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-29</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-31</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-04-28</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-05-31</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>276 rows Ã— 500 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb1f010c-77cc-46c9-9194-26e8a4e1d738')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fb1f010c-77cc-46c9-9194-26e8a4e1d738 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fb1f010c-77cc-46c9-9194-26e8a4e1d738');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "532961c98d67440ca589bc61c0a7ff3d",
            "71ba8353a7b4416d8d733044555bc815",
            "f620b2595d4d4e0ea8ebff8e5ee7e36d",
            "145baa11c9cb41afb1787518a607f3e0",
            "afff8d0761e94b9d945460b700ecc033",
            "1c6b1a9cb3cc494ca31e8dd243d7b5fd",
            "b7806d7262e943ba93e71488f207f6ac",
            "79a2927e56e742a9851b4772179fd6f3",
            "b543d43578ac4528877fb4ccb6e03858",
            "d7108cf7aa5a40e7aaee7ffa5bdc2eba",
            "03bacc9e50b84c6fba35473707682f74"
          ]
        },
        "id": "GP0aecCgv_5O",
        "outputId": "1e46d280-6335-4668-a743-558281b73b10"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "532961c98d67440ca589bc61c0a7ff3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_dataset (276, 500)\n",
            "x_dataset (276, 20, 500)\n"
          ]
        }
      ],
      "source": [
        "# get multifactor list\n",
        "multifactor_list = Technical_list+fundamental_list\n",
        "\n",
        "# get x_dataset, y_dataset\n",
        "multi_factor_data = multi_factor_data.astype(float)\n",
        "label_df = label_df.astype(float)\n",
        "x_dataset = []\n",
        "y_dataset = []\n",
        "temp = []\n",
        "\n",
        "for ticker in tqdm(SP500_ticker):\n",
        "  y_dataset.append(label_df[ticker])\n",
        "  temp = []\n",
        "  for factor in multifactor_list:\n",
        "    temp.append(multi_factor_data[ticker, factor])\n",
        "  x_dataset.append(temp)\n",
        "y_dataset = np.array(y_dataset).T\n",
        "x_dataset = np.array(x_dataset).T\n",
        "\n",
        "print('y_dataset',y_dataset.shape)\n",
        "print('x_dataset',x_dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_point = X.shape[0]-21\n",
        "\n",
        "#Preparation of test set\n",
        "x_train = x_dataset[0:train_point]\n",
        "y_train = y_dataset[0:train_point]\n",
        "\n",
        "x_test = x_dataset[train_point:]\n",
        "y_test = y_dataset[train_point:]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngUEthGFn2zy",
        "outputId": "19fb9245-e1f5-4cce-a462-07591a951865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(250, 20, 500)\n",
            "(250, 500)\n",
            "(26, 20, 500)\n",
            "(26, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz98_PE2fLFR"
      },
      "outputs": [],
      "source": [
        "n_future = 1   # Number of month we want top predict into the future\n",
        "n_past = 5  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOhpsl6kfWmj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c04ad57b-26d5-4b34-bde6-03bf7f20a974"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(276, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "x_dataset = scaler.fit_transform(x_dataset)\n",
        "y_dataset = scaler.fit_transform(y_dataset)\n",
        "x_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAHg9LmufcNh",
        "outputId": "1f1ac237-9832-44d3-b58b-dd405adbfe73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(271, 5, 10000)\n",
            "(271, 500)\n"
          ]
        }
      ],
      "source": [
        "#Preparation of training set\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i in range(n_past, len(x_dataset) - n_future +1):\n",
        "  #print(i)\n",
        "  X.append(x_dataset[i - n_past:i,:])\n",
        "Y = y_dataset[n_past:]\n",
        "X, Y = np.array(X), np.array(Y)\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLn-arunfgCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d19a9354-d07b-4ef0-ebc9-07a943b04d84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(245, 5, 10000)\n",
            "(245, 500)\n",
            "(26, 5, 10000)\n",
            "(26, 500)\n"
          ]
        }
      ],
      "source": [
        "train_point = X.shape[0]-26\n",
        "\n",
        "#Preparation of test set\n",
        "x_train = X[0:train_point]\n",
        "y_train = Y[0:train_point]\n",
        "\n",
        "x_test = X[train_point:]\n",
        "y_test = Y[train_point:]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM"
      ],
      "metadata": {
        "id": "FCXGQ3Z2jYRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the Neural Network based on LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Adding 1st LSTM layer\n",
        "model.add(LSTM(units=1024, return_sequences=True, input_shape=( x_dataset.shape[1], x_dataset.shape[2])))\n",
        "\n",
        "# Adding 2nd LSTM layer\n",
        "model.add(LSTM(units=1024, return_sequences=False))\n",
        "\n",
        "# Adding Dropout\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=512, activation='linear'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=500, activation='linear'))\n",
        "\n",
        "# Compiling the Neural Network\n",
        "model.compile(optimizer = Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "#model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
        "mcp = ModelCheckpoint(filepath='/content/drive/My Drive/FYP Data/model/LSTM_long_123.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
        "\n",
        "tb = TensorBoard('logs')\n",
        "\n",
        "history = model.fit(x_train, y_train, shuffle=True, epochs=10, callbacks=[es, rlr, mcp, tb], validation_split=0.2, verbose=1, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-C-NcpF_Zm_",
        "outputId": "24968898-314b-4155-d37d-a7a453529424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 17.2686\n",
            "Epoch 1: val_loss improved from inf to 4.24114, saving model to /content/drive/My Drive/FYP Data/model/LSTM_long_123.h5\n",
            "20/20 [==============================] - 8s 285ms/step - loss: 17.2686 - val_loss: 4.2411 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 4.4939\n",
            "Epoch 2: val_loss improved from 4.24114 to 1.95563, saving model to /content/drive/My Drive/FYP Data/model/LSTM_long_123.h5\n",
            "20/20 [==============================] - 1s 60ms/step - loss: 4.3382 - val_loss: 1.9556 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.6538\n",
            "Epoch 3: val_loss did not improve from 1.95563\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 1.6538 - val_loss: 2.0424 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4846\n",
            "Epoch 4: val_loss improved from 1.95563 to 1.51674, saving model to /content/drive/My Drive/FYP Data/model/LSTM_long_123.h5\n",
            "20/20 [==============================] - 1s 48ms/step - loss: 1.4794 - val_loss: 1.5167 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3207\n",
            "Epoch 5: val_loss did not improve from 1.51674\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.3254 - val_loss: 1.5921 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.2344\n",
            "Epoch 6: val_loss improved from 1.51674 to 1.45750, saving model to /content/drive/My Drive/FYP Data/model/LSTM_long_123.h5\n",
            "20/20 [==============================] - 1s 49ms/step - loss: 1.2343 - val_loss: 1.4575 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.2050\n",
            "Epoch 7: val_loss did not improve from 1.45750\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 1.2104 - val_loss: 1.4732 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1907\n",
            "Epoch 8: val_loss did not improve from 1.45750\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1862 - val_loss: 1.6124 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1745\n",
            "Epoch 9: val_loss did not improve from 1.45750\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1764 - val_loss: 1.4806 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1287\n",
            "Epoch 10: val_loss improved from 1.45750 to 1.42521, saving model to /content/drive/My Drive/FYP Data/model/LSTM_long_123.h5\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 1.1336 - val_loss: 1.4252 - lr: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Evaluation\n",
        "predictions = model.predict(x_test)\n",
        "#predictions = scaler.inverse_transform(predictions)\n",
        "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "print('rmse', rmse)\n",
        "\n",
        "#profit test\n",
        "test_period = time[n_past+245:]\n",
        "\n",
        "#calculate the top 10 stock we picked\n",
        "stock_selection_index = np.argsort(predictions)[:,-30:]\n",
        "stock_selection = []\n",
        "for index in stock_selection_index:\n",
        "  stock_list = []\n",
        "  for stock_i in index:\n",
        "    stock_list.append(SP500_ticker[stock_i])\n",
        "  stock_selection.append(stock_list)\n",
        "\n",
        "#trading simulate\n",
        "original_money = 0\n",
        "trading = 0\n",
        "test_period = time[n_past+245:]\n",
        "for stock in stock_selection[0]:\n",
        "  original_money = original_money + stock_data[stock][\"Close\"][test_period[0]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[0]])\n",
        "\n",
        "\n",
        "trading = - original_money\n",
        "i = 0\n",
        "\n",
        "for stock_list in stock_selection:\n",
        "  if i==0 or 25:\n",
        "    i = i + 1\n",
        "    continue\n",
        "\n",
        "  for stock in stock_list:\n",
        "    trading = trading + stock_data[stock][\"Close\"][test_period[i-1]] - stock_data[stock][\"Close\"][test_period[i]]\n",
        "    #print(trading)\n",
        "  \n",
        "  i = i + 1\n",
        "\n",
        "end_money = 0\n",
        "\n",
        "for stock in stock_selection[-1]:\n",
        "  trading = trading + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  end_money = end_money + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[-1]])\n",
        "\n",
        "print('The money earned by LSTM with Fundamental and Technical data is ',trading)\n",
        "print('The money earned by LSTM with Fundamental and Technical data is %',trading*100/original_money)\n",
        "print('The money earned by LSTM with Fundamental and Technical data is %(unchange)',(end_money-original_money)*100/original_money)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKMfRN_8_m_2",
        "outputId": "df24d321-a2e5-4001-e0ec-5b81fc30326d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "rmse 0.08685911366028282\n",
            "The money earned by LSTM with Fundamental and Technical data is  578.7831239700317\n",
            "The money earned by LSTM with Fundamental and Technical data is % 5.63520894940951\n",
            "The money earned by LSTM with Fundamental and Technical data is %(unchange) 5.63520894940951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_selection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6BhfbawoRbI",
        "outputId": "3cfeb4e8-9ae1-4504-ea05-0f0751da7bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'OKE',\n",
              "  'EVRG',\n",
              "  'AMZN',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'FICO',\n",
              "  'IDXX',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'HPQ',\n",
              "  'TMO',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'NFLX',\n",
              "  'MGM',\n",
              "  'OKE',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'NFLX',\n",
              "  'MGM',\n",
              "  'OKE',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'NFLX',\n",
              "  'MGM',\n",
              "  'OKE',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'OKE',\n",
              "  'EVRG',\n",
              "  'AMZN',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'FICO',\n",
              "  'TXN',\n",
              "  'IDXX',\n",
              "  'DHI',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'HPQ',\n",
              "  'TMO',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'OKE',\n",
              "  'EVRG',\n",
              "  'AMZN',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'FICO',\n",
              "  'TXN',\n",
              "  'IDXX',\n",
              "  'DHI',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'HPQ',\n",
              "  'TMO',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'OKE',\n",
              "  'EVRG',\n",
              "  'AMZN',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'FICO',\n",
              "  'TXN',\n",
              "  'IDXX',\n",
              "  'DHI',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'HPQ',\n",
              "  'TMO',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'OKE',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'OKE',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'OKE',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'NTAP',\n",
              "  'FICO',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'IDXX',\n",
              "  'DHI',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'NTAP',\n",
              "  'FICO',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'IDXX',\n",
              "  'DHI',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'NTAP',\n",
              "  'FICO',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'IDXX',\n",
              "  'DHI',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'DHI',\n",
              "  'IDXX',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['ARE',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'NFLX',\n",
              "  'MGM',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'IDXX',\n",
              "  'DHI',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'HPQ',\n",
              "  'TMO',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['ARE',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'NFLX',\n",
              "  'MGM',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'IDXX',\n",
              "  'DHI',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'HPQ',\n",
              "  'TMO',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['ARE',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'NFLX',\n",
              "  'MGM',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'FICO',\n",
              "  'NTAP',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'IDXX',\n",
              "  'DHI',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'HPQ',\n",
              "  'TMO',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX'],\n",
              " ['CMS',\n",
              "  'VTRS',\n",
              "  'STZ',\n",
              "  'AMZN',\n",
              "  'EVRG',\n",
              "  'OKE',\n",
              "  'MGM',\n",
              "  'NFLX',\n",
              "  'APH',\n",
              "  'CVS',\n",
              "  'WAB',\n",
              "  'SWK',\n",
              "  'PWR',\n",
              "  'NTAP',\n",
              "  'FICO',\n",
              "  'KLAC',\n",
              "  'TXN',\n",
              "  'IDXX',\n",
              "  'DHI',\n",
              "  'VLO',\n",
              "  'REGN',\n",
              "  'MCO',\n",
              "  'NVR',\n",
              "  'TMO',\n",
              "  'HPQ',\n",
              "  'FFIV',\n",
              "  'SRE',\n",
              "  'ADBE',\n",
              "  'ALGN',\n",
              "  'EQIX']]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_stock_selection = pd.DataFrame (stock_selection)\n",
        "df_stock_selection.to_csv(\"drive/My Drive/FYP Data/LSTM_TF_long_123_new.csv\",index=True, header=True )"
      ],
      "metadata": {
        "id": "pFKYo2rlyXdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GRU"
      ],
      "metadata": {
        "id": "SDhhjryYjcLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# The GRU architecture\n",
        "regressorGRU = Sequential()\n",
        "# First GRU layer with Dropout regularisation\n",
        "regressorGRU.add(GRU(units=1024, return_sequences=True, input_shape=(x_dataset.shape[1], x_dataset.shape[2]), activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# Second GRU layer\n",
        "regressorGRU.add(GRU(units=512, return_sequences=True, input_shape=(x_dataset.shape[1], x_dataset.shape[2]), activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# Third GRU layer\n",
        "regressorGRU.add(GRU(units=500, return_sequences=True, input_shape=(x_dataset.shape[1], x_dataset.shape[2]), activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# Fourth GRU layer\n",
        "regressorGRU.add(GRU(units=500, activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# The output layer\n",
        "regressorGRU.add(Dense(units=500))\n",
        "# Compiling the RNN\n",
        "regressorGRU.compile(optimizer = Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "#regressorGRU.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
        "mcp = ModelCheckpoint(filepath='/content/drive/My Drive/FYP Data/model/GRU_long_123.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
        "\n",
        "tb = TensorBoard('logs')\n",
        "\n",
        "# Fitting to the training set\n",
        "history = regressorGRU.fit(x_train, y_train, shuffle=True, epochs=10, callbacks=[es, rlr, mcp, tb], validation_split=0.2, verbose=1, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG6GEnGkjIlb",
        "outputId": "1ec87f06-5c59-4c8a-b5b3-866eebe4f9aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 2.8994\n",
            "Epoch 1: val_loss improved from inf to 1.73182, saving model to /content/drive/My Drive/FYP Data/model/GRU_long_123.h5\n",
            "20/20 [==============================] - 10s 280ms/step - loss: 2.7733 - val_loss: 1.7318 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4803\n",
            "Epoch 2: val_loss improved from 1.73182 to 1.65950, saving model to /content/drive/My Drive/FYP Data/model/GRU_long_123.h5\n",
            "20/20 [==============================] - 1s 42ms/step - loss: 1.4947 - val_loss: 1.6595 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4747\n",
            "Epoch 3: val_loss improved from 1.65950 to 1.56037, saving model to /content/drive/My Drive/FYP Data/model/GRU_long_123.h5\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 1.4747 - val_loss: 1.5604 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4122\n",
            "Epoch 4: val_loss did not improve from 1.56037\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4136 - val_loss: 1.7544 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4212\n",
            "Epoch 5: val_loss did not improve from 1.56037\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4212 - val_loss: 1.7328 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4172\n",
            "Epoch 6: val_loss did not improve from 1.56037\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4250 - val_loss: 1.6424 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4384\n",
            "Epoch 7: val_loss did not improve from 1.56037\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4319 - val_loss: 1.8356 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4031\n",
            "Epoch 8: val_loss did not improve from 1.56037\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4067 - val_loss: 1.6479 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3819\n",
            "Epoch 9: val_loss did not improve from 1.56037\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3869 - val_loss: 1.7237 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4108\n",
            "Epoch 10: val_loss did not improve from 1.56037\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4108 - val_loss: 1.8452 - lr: 0.0100\n",
            "CPU times: user 12.4 s, sys: 526 ms, total: 12.9 s\n",
            "Wall time: 16 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Evaluation\n",
        "predictions = regressorGRU.predict(x_test)\n",
        "#predictions = scaler.inverse_transform(predictions)\n",
        "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "print('rmse', rmse)\n",
        "\n",
        "#profit test\n",
        "test_period = time[n_past+245:]\n",
        "\n",
        "#calculate the top 10 stock we picked\n",
        "stock_selection_index = np.argsort(predictions)[:,-30:]\n",
        "stock_selection = []\n",
        "for index in stock_selection_index:\n",
        "  stock_list = []\n",
        "  for stock_i in index:\n",
        "    stock_list.append(SP500_ticker[stock_i])\n",
        "  stock_selection.append(stock_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y04vJ8q-kssx",
        "outputId": "0ec017ba-5047-48dd-f34f-7690a8e8acd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "rmse 0.06860474990895735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_selection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFtoqNdxlIBS",
        "outputId": "bec2ec8b-ead3-4d6c-d739-f6a9e8d60252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN'],\n",
              " ['FFIV',\n",
              "  'EA',\n",
              "  'BLK',\n",
              "  'YUM',\n",
              "  'BALL',\n",
              "  'ETN',\n",
              "  'RCL',\n",
              "  'ETR',\n",
              "  'TECH',\n",
              "  'PHM',\n",
              "  'TSN',\n",
              "  'EQIX',\n",
              "  'MCO',\n",
              "  'SYK',\n",
              "  'MRO',\n",
              "  'ATVI',\n",
              "  'JBHT',\n",
              "  'ZBRA',\n",
              "  'AZO',\n",
              "  'AME',\n",
              "  'TMO',\n",
              "  'PKI',\n",
              "  'CAG',\n",
              "  'ISRG',\n",
              "  'MHK',\n",
              "  'GL',\n",
              "  'INCY',\n",
              "  'ALGN',\n",
              "  'CRL',\n",
              "  'GPN']]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trading simulate\n",
        "original_money = 0\n",
        "trading = 0\n",
        "for stock in stock_selection[0]:\n",
        "  original_money = original_money + stock_data[stock][\"Close\"][test_period[0]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[0]])\n",
        "\n",
        "\n",
        "trading = - original_money\n",
        "i = 0\n",
        "\n",
        "for stock_list in stock_selection:\n",
        "  if i==0 or 25:\n",
        "    i = i + 1\n",
        "    continue\n",
        "\n",
        "  for stock in stock_list:\n",
        "    trading = trading + stock_data[stock][\"Close\"][test_period[i-1]] - stock_data[stock][\"Close\"][test_period[i]]\n",
        "    #print(trading)\n",
        "  \n",
        "  i = i + 1\n",
        "\n",
        "end_money = 0\n",
        "\n",
        "for stock in stock_selection[-1]:\n",
        "  trading = trading + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  end_money = end_money + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[-1]])\n",
        "\n",
        "print('The money earned by LSTM with Fundamental and Technical data is ',trading)\n",
        "print('The money earned by LSTM with Fundamental and Technical data is %',trading*100/original_money)\n",
        "print('The money earned by LSTM with Fundamental and Technical data is %(unchange)',(end_money-original_money)*100/original_money)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULokUmRujPeH",
        "outputId": "e2db0706-d7e6-4df0-e584-c4230c06e9f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The money earned by LSTM with Fundamental and Technical data is  963.6957950592041\n",
            "The money earned by LSTM with Fundamental and Technical data is % 14.08091794184479\n",
            "The money earned by LSTM with Fundamental and Technical data is %(unchange) 14.08091794184479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_stock_selection = pd.DataFrame (stock_selection)\n",
        "df_stock_selection.to_csv(\"drive/My Drive/FYP Data/GRU_TF_long_123_new.csv\",index=True, header=True )"
      ],
      "metadata": {
        "id": "QzoauvMvzdCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#original one with all fundamental data"
      ],
      "metadata": {
        "id": "SIXgYeK1a4CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read data\n",
        "multi_factor_data = pd.read_csv(\"drive/My Drive/FYP Data/multi_factor.csv\",index_col = 0,header = [0,1])\n",
        "\n",
        "for ticker in tqdm(SP500_ticker):\n",
        "  if ticker in ['BRK.B','BF.B','GEHC']:\n",
        "    continue\n",
        "  key_metrics_quarterly = fa.key_metrics(ticker, api_key, period=\"quarter\")\n",
        "  key_metrics_quarterly= key_metrics_quarterly.T\n",
        "  #key_metrics_quarterly = key_metrics_quarterly.drop(columns=['period'])\n",
        "  key_metrics_quarterly_new = pd.DataFrame(np.repeat(key_metrics_quarterly.values,3,axis=0))\n",
        "  key_metrics_quarterly_new.columns = key_metrics_quarterly.columns\n",
        "  fundamental = key_metrics_quarterly_new.tail(-2)\n",
        "  fundamental = fundamental.reset_index(drop=True)\n",
        "  fundamental = fundamental.reindex(range(360)).fillna(0)\n",
        "  fundamental = fundamental.reindex(index=fundamental.index[::-1])\n",
        "  fundamental.index = label_df.index\n",
        "  for fu in fundamental_list:\n",
        "    multi_factor_data[ticker, fu] = fundamental[fu]\n",
        "\n",
        "multi_factor_data = multi_factor_data.drop('BRK.B', axis=1)\n",
        "multi_factor_data = multi_factor_data.drop('BF.B', axis=1)\n",
        "multi_factor_data = multi_factor_data.drop('GEHC', axis=1)\n",
        "\n",
        "multi_factor_data.to_csv(\"drive/My Drive/FYP Data/multi_factor_data.csv\",index=True, header=True )\n"
      ],
      "metadata": {
        "id": "zoePjQw7a3RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read data\n",
        "multi_factor_data = pd.read_csv(\"drive/My Drive/FYP Data/multi_factor_data.csv\",index_col = 0,header = [0,1])\n",
        "multi_factor_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8vE5bJ-0eFVk",
        "outputId": "a2413196-ac46-46ad-a6c4-b1228efda8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                JNPR                                   \\\n",
              "                                Open       High        Low      Close   \n",
              "Date                                                                    \n",
              "1993-02-26 00:00:00-05:00   0.000000   0.000000   0.000000   0.000000   \n",
              "1993-03-31 00:00:00-05:00   0.000000   0.000000   0.000000   0.000000   \n",
              "1993-04-30 00:00:00-04:00   0.000000   0.000000   0.000000   0.000000   \n",
              "1993-05-28 00:00:00-04:00   0.000000   0.000000   0.000000   0.000000   \n",
              "1993-06-30 00:00:00-04:00   0.000000   0.000000   0.000000   0.000000   \n",
              "...                              ...        ...        ...        ...   \n",
              "2022-08-31 00:00:00-04:00  28.950001  29.299999  28.370001  28.420000   \n",
              "2022-09-30 00:00:00-04:00  26.180000  26.680000  26.110001  26.120001   \n",
              "2022-10-31 00:00:00-04:00  30.660000  30.799999  30.360001  30.600000   \n",
              "2022-11-30 00:00:00-05:00  31.580000  33.270000  31.490000  33.240002   \n",
              "2022-12-30 00:00:00-05:00  31.790001  32.000000  31.700001  31.959999   \n",
              "\n",
              "                                                       JBHT              \\\n",
              "                           Adj Close     Volume        Open        High   \n",
              "Date                                                                      \n",
              "1993-02-26 00:00:00-05:00   0.000000        0.0    5.375000    5.375000   \n",
              "1993-03-31 00:00:00-05:00   0.000000        0.0    4.750000    4.875000   \n",
              "1993-04-30 00:00:00-04:00   0.000000        0.0    5.000000    5.125000   \n",
              "1993-05-28 00:00:00-04:00   0.000000        0.0    5.312500    5.312500   \n",
              "1993-06-30 00:00:00-04:00   0.000000        0.0    5.125000    5.125000   \n",
              "...                              ...        ...         ...         ...   \n",
              "2022-08-31 00:00:00-04:00  28.232733  5695500.0  175.630005  175.649994   \n",
              "2022-09-30 00:00:00-04:00  25.947889  3139300.0  162.759995  165.309998   \n",
              "2022-10-31 00:00:00-04:00  30.398369  3189000.0  168.339996  172.649994   \n",
              "2022-11-30 00:00:00-05:00  33.240002  7437400.0  179.369995  184.979996   \n",
              "2022-12-30 00:00:00-05:00  31.959999  1755900.0  175.850006  176.270004   \n",
              "\n",
              "                                                   ...             ZTS  \\\n",
              "                                  Low       Close  ... averagePayables   \n",
              "Date                                               ...                   \n",
              "1993-02-26 00:00:00-05:00    5.250000    5.250000  ...             NaN   \n",
              "1993-03-31 00:00:00-05:00    4.625000    4.875000  ...             NaN   \n",
              "1993-04-30 00:00:00-04:00    4.875000    5.125000  ...             NaN   \n",
              "1993-05-28 00:00:00-04:00    5.062500    5.125000  ...             NaN   \n",
              "1993-06-30 00:00:00-04:00    5.062500    5.125000  ...             NaN   \n",
              "...                               ...         ...  ...             ...   \n",
              "2022-08-31 00:00:00-04:00  172.460007  174.020004  ...             NaN   \n",
              "2022-09-30 00:00:00-04:00  156.279999  156.419998  ...             NaN   \n",
              "2022-10-31 00:00:00-04:00  166.880005  171.070007  ...             NaN   \n",
              "2022-11-30 00:00:00-05:00  176.570007  183.889999  ...             NaN   \n",
              "2022-12-30 00:00:00-05:00  172.050003  174.360001  ...             NaN   \n",
              "\n",
              "                                                                 \\\n",
              "                          averageInventory daysSalesOutstanding   \n",
              "Date                                                              \n",
              "1993-02-26 00:00:00-05:00              NaN                  NaN   \n",
              "1993-03-31 00:00:00-05:00              NaN                  NaN   \n",
              "1993-04-30 00:00:00-04:00              NaN                  NaN   \n",
              "1993-05-28 00:00:00-04:00              NaN                  NaN   \n",
              "1993-06-30 00:00:00-04:00              NaN                  NaN   \n",
              "...                                    ...                  ...   \n",
              "2022-08-31 00:00:00-04:00              NaN                  NaN   \n",
              "2022-09-30 00:00:00-04:00              NaN                  NaN   \n",
              "2022-10-31 00:00:00-04:00              NaN                  NaN   \n",
              "2022-11-30 00:00:00-05:00              NaN                  NaN   \n",
              "2022-12-30 00:00:00-05:00              NaN                  NaN   \n",
              "\n",
              "                                                                         \\\n",
              "                          daysPayablesOutstanding daysOfInventoryOnHand   \n",
              "Date                                                                      \n",
              "1993-02-26 00:00:00-05:00                     NaN                   NaN   \n",
              "1993-03-31 00:00:00-05:00                     NaN                   NaN   \n",
              "1993-04-30 00:00:00-04:00                     NaN                   NaN   \n",
              "1993-05-28 00:00:00-04:00                     NaN                   NaN   \n",
              "1993-06-30 00:00:00-04:00                     NaN                   NaN   \n",
              "...                                           ...                   ...   \n",
              "2022-08-31 00:00:00-04:00                     NaN                   NaN   \n",
              "2022-09-30 00:00:00-04:00                     NaN                   NaN   \n",
              "2022-10-31 00:00:00-04:00                     NaN                   NaN   \n",
              "2022-11-30 00:00:00-05:00                     NaN                   NaN   \n",
              "2022-12-30 00:00:00-05:00                     NaN                   NaN   \n",
              "\n",
              "                                                                \\\n",
              "                          receivablesTurnover payablesTurnover   \n",
              "Date                                                             \n",
              "1993-02-26 00:00:00-05:00                 NaN              NaN   \n",
              "1993-03-31 00:00:00-05:00                 NaN              NaN   \n",
              "1993-04-30 00:00:00-04:00                 NaN              NaN   \n",
              "1993-05-28 00:00:00-04:00                 NaN              NaN   \n",
              "1993-06-30 00:00:00-04:00                 NaN              NaN   \n",
              "...                                       ...              ...   \n",
              "2022-08-31 00:00:00-04:00                 NaN              NaN   \n",
              "2022-09-30 00:00:00-04:00                 NaN              NaN   \n",
              "2022-10-31 00:00:00-04:00                 NaN              NaN   \n",
              "2022-11-30 00:00:00-05:00                 NaN              NaN   \n",
              "2022-12-30 00:00:00-05:00                 NaN              NaN   \n",
              "\n",
              "                                                               \n",
              "                          inventoryTurnover roe capexPerShare  \n",
              "Date                                                           \n",
              "1993-02-26 00:00:00-05:00               NaN NaN           NaN  \n",
              "1993-03-31 00:00:00-05:00               NaN NaN           NaN  \n",
              "1993-04-30 00:00:00-04:00               NaN NaN           NaN  \n",
              "1993-05-28 00:00:00-04:00               NaN NaN           NaN  \n",
              "1993-06-30 00:00:00-04:00               NaN NaN           NaN  \n",
              "...                                     ...  ..           ...  \n",
              "2022-08-31 00:00:00-04:00               NaN NaN           NaN  \n",
              "2022-09-30 00:00:00-04:00               NaN NaN           NaN  \n",
              "2022-10-31 00:00:00-04:00               NaN NaN           NaN  \n",
              "2022-11-30 00:00:00-05:00               NaN NaN           NaN  \n",
              "2022-12-30 00:00:00-05:00               NaN NaN           NaN  \n",
              "\n",
              "[359 rows x 34829 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddf44978-fa6a-42b5-aa68-09cfce61ea47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">JNPR</th>\n",
              "      <th colspan=\"4\" halign=\"left\">JBHT</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"10\" halign=\"left\">ZTS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>...</th>\n",
              "      <th>averagePayables</th>\n",
              "      <th>averageInventory</th>\n",
              "      <th>daysSalesOutstanding</th>\n",
              "      <th>daysPayablesOutstanding</th>\n",
              "      <th>daysOfInventoryOnHand</th>\n",
              "      <th>receivablesTurnover</th>\n",
              "      <th>payablesTurnover</th>\n",
              "      <th>inventoryTurnover</th>\n",
              "      <th>roe</th>\n",
              "      <th>capexPerShare</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1993-02-26 00:00:00-05:00</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.375000</td>\n",
              "      <td>5.375000</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-03-31 00:00:00-05:00</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>4.875000</td>\n",
              "      <td>4.625000</td>\n",
              "      <td>4.875000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-04-30 00:00:00-04:00</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.125000</td>\n",
              "      <td>4.875000</td>\n",
              "      <td>5.125000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-05-28 00:00:00-04:00</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.312500</td>\n",
              "      <td>5.312500</td>\n",
              "      <td>5.062500</td>\n",
              "      <td>5.125000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-06-30 00:00:00-04:00</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.125000</td>\n",
              "      <td>5.125000</td>\n",
              "      <td>5.062500</td>\n",
              "      <td>5.125000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31 00:00:00-04:00</th>\n",
              "      <td>28.950001</td>\n",
              "      <td>29.299999</td>\n",
              "      <td>28.370001</td>\n",
              "      <td>28.420000</td>\n",
              "      <td>28.232733</td>\n",
              "      <td>5695500.0</td>\n",
              "      <td>175.630005</td>\n",
              "      <td>175.649994</td>\n",
              "      <td>172.460007</td>\n",
              "      <td>174.020004</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30 00:00:00-04:00</th>\n",
              "      <td>26.180000</td>\n",
              "      <td>26.680000</td>\n",
              "      <td>26.110001</td>\n",
              "      <td>26.120001</td>\n",
              "      <td>25.947889</td>\n",
              "      <td>3139300.0</td>\n",
              "      <td>162.759995</td>\n",
              "      <td>165.309998</td>\n",
              "      <td>156.279999</td>\n",
              "      <td>156.419998</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31 00:00:00-04:00</th>\n",
              "      <td>30.660000</td>\n",
              "      <td>30.799999</td>\n",
              "      <td>30.360001</td>\n",
              "      <td>30.600000</td>\n",
              "      <td>30.398369</td>\n",
              "      <td>3189000.0</td>\n",
              "      <td>168.339996</td>\n",
              "      <td>172.649994</td>\n",
              "      <td>166.880005</td>\n",
              "      <td>171.070007</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30 00:00:00-05:00</th>\n",
              "      <td>31.580000</td>\n",
              "      <td>33.270000</td>\n",
              "      <td>31.490000</td>\n",
              "      <td>33.240002</td>\n",
              "      <td>33.240002</td>\n",
              "      <td>7437400.0</td>\n",
              "      <td>179.369995</td>\n",
              "      <td>184.979996</td>\n",
              "      <td>176.570007</td>\n",
              "      <td>183.889999</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30 00:00:00-05:00</th>\n",
              "      <td>31.790001</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>31.700001</td>\n",
              "      <td>31.959999</td>\n",
              "      <td>31.959999</td>\n",
              "      <td>1755900.0</td>\n",
              "      <td>175.850006</td>\n",
              "      <td>176.270004</td>\n",
              "      <td>172.050003</td>\n",
              "      <td>174.360001</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>359 rows Ã— 34829 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddf44978-fa6a-42b5-aa68-09cfce61ea47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddf44978-fa6a-42b5-aa68-09cfce61ea47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddf44978-fa6a-42b5-aa68-09cfce61ea47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLhhI3cfTQry"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gacg_sDfjyJ"
      },
      "outputs": [],
      "source": [
        "# Initializing the Neural Network based on LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Adding 1st LSTM layer\n",
        "model.add(LSTM(units=1024, return_sequences=True, input_shape=(n_past, x_dataset.shape[1])))\n",
        "\n",
        "# Adding 2nd LSTM layer\n",
        "model.add(LSTM(units=1024, return_sequences=False))\n",
        "\n",
        "# Adding Dropout\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=512, activation='linear'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=500, activation='linear'))\n",
        "\n",
        "# Compiling the Neural Network\n",
        "model.compile(optimizer = Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "#model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIpjRBFWfnZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bdeb24d-ae82-4f98-db6f-ca4d439a54a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 10.2242\n",
            "Epoch 1: val_loss improved from inf to 0.73654, saving model to /content/drive/My Drive/FYP Data/weights_w_fundamental.h5\n",
            "20/20 [==============================] - 7s 203ms/step - loss: 9.9651 - val_loss: 0.7365 - lr: 0.0100\n",
            "Epoch 2/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0817\n",
            "Epoch 2: val_loss improved from 0.73654 to 0.21913, saving model to /content/drive/My Drive/FYP Data/weights_w_fundamental.h5\n",
            "20/20 [==============================] - 1s 74ms/step - loss: 1.0715 - val_loss: 0.2191 - lr: 0.0100\n",
            "Epoch 3/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.5963\n",
            "Epoch 3: val_loss did not improve from 0.21913\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.5858 - val_loss: 0.5226 - lr: 0.0100\n",
            "Epoch 4/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.4623\n",
            "Epoch 4: val_loss did not improve from 0.21913\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.4601 - val_loss: 0.2319 - lr: 0.0100\n",
            "Epoch 5/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.2769\n",
            "Epoch 5: val_loss improved from 0.21913 to 0.17502, saving model to /content/drive/My Drive/FYP Data/weights_w_fundamental.h5\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.2758 - val_loss: 0.1750 - lr: 0.0100\n",
            "Epoch 6/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.2559\n",
            "Epoch 6: val_loss did not improve from 0.17502\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.2531 - val_loss: 0.1892 - lr: 0.0100\n",
            "Epoch 7/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.2209\n",
            "Epoch 7: val_loss did not improve from 0.17502\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.2228 - val_loss: 0.1961 - lr: 0.0100\n",
            "Epoch 8/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.2263\n",
            "Epoch 8: val_loss improved from 0.17502 to 0.16331, saving model to /content/drive/My Drive/FYP Data/weights_w_fundamental.h5\n",
            "20/20 [==============================] - 1s 68ms/step - loss: 0.2269 - val_loss: 0.1633 - lr: 0.0100\n",
            "Epoch 9/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.2047\n",
            "Epoch 9: val_loss improved from 0.16331 to 0.16307, saving model to /content/drive/My Drive/FYP Data/weights_w_fundamental.h5\n",
            "20/20 [==============================] - 1s 69ms/step - loss: 0.2037 - val_loss: 0.1631 - lr: 0.0100\n",
            "Epoch 10/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.1644\n",
            "Epoch 10: val_loss did not improve from 0.16307\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.1637 - val_loss: 0.1700 - lr: 0.0100\n",
            "Epoch 11/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.1990\n",
            "Epoch 11: val_loss did not improve from 0.16307\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.1981 - val_loss: 0.2650 - lr: 0.0100\n",
            "Epoch 12/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.2053\n",
            "Epoch 12: val_loss did not improve from 0.16307\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.2109 - val_loss: 0.5604 - lr: 0.0100\n",
            "Epoch 13/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.3213\n",
            "Epoch 13: val_loss did not improve from 0.16307\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.3171 - val_loss: 0.4650 - lr: 0.0100\n",
            "Epoch 14/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.3021\n",
            "Epoch 14: val_loss did not improve from 0.16307\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.2984 - val_loss: 0.1758 - lr: 0.0100\n",
            "Epoch 15/15\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.2645\n",
            "Epoch 15: val_loss did not improve from 0.16307\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.2618 - val_loss: 0.4694 - lr: 0.0100\n",
            "CPU times: user 13 s, sys: 1.77 s, total: 14.8 s\n",
            "Wall time: 23 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
        "mcp = ModelCheckpoint(filepath='/content/drive/My Drive/FYP Data/weights_w_fundamental.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "tb = TensorBoard('logs')\n",
        "\n",
        "history = model.fit(x_train, y_train, shuffle=True, epochs=15, callbacks=[es, rlr, mcp, tb], validation_split=0.2, verbose=1, batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_6qqRDUDkAP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "5c834ef0-e1cf-4e43-ba86-bbab858b94e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'val_loss', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxlkxsqGgCS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f09d24d-4013-403d-b5d3-313443be2ce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.009829873807871571"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ],
      "source": [
        "#Model Evaluation\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "print('rmse', rmse)\n",
        "\n",
        "#profit test\n",
        "test_period = time[n_past+325:]\n",
        "\n",
        "#calculate the top 10 stock we picked\n",
        "stock_selection_index = np.argsort(predictions)[:,-30:]\n",
        "stock_selection = []\n",
        "for index in stock_selection_index:\n",
        "  stock_list = []\n",
        "  for stock_i in index:\n",
        "    stock_list.append(SP500_ticker[stock_i])\n",
        "  stock_selection.append(stock_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trading simulate\n",
        "original_money = 0\n",
        "trading = 0\n",
        "for stock in stock_selection[0]:\n",
        "  original_money = original_money + stock_data[stock][\"Close\"][test_period[0]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[0]])\n",
        "\n",
        "\n",
        "trading = - original_money\n",
        "i = 0\n",
        "\n",
        "for stock_list in stock_selection:\n",
        "  if i==0 or 25:\n",
        "    i = i + 1\n",
        "    continue\n",
        "\n",
        "  for stock in stock_list:\n",
        "    trading = trading + stock_data[stock][\"Close\"][test_period[i-1]] - stock_data[stock][\"Close\"][test_period[i]]\n",
        "    #print(trading)\n",
        "  \n",
        "  i = i + 1\n",
        "\n",
        "end_money = 0\n",
        "\n",
        "for stock in stock_selection[-1]:\n",
        "  trading = trading + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  end_money = end_money + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[-1]])\n",
        "\n",
        "print('The money earned by LSTM with Fundamental and Technical data is ',trading)\n",
        "print('The money earned by LSTM with Fundamental and Technical data is %',trading*100/original_money)\n",
        "print('The money earned by LSTM with Fundamental and Technical data is %(unchange)',(end_money-original_money)*100/original_money)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtLi7x4BqB4d",
        "outputId": "8844740a-6382-49fe-9cf8-7462d94affcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The money earned by LSTM with Fundamental and Technical data is  -30.203195571899414\n",
            "The money earned by LSTM with Fundamental and Technical data is % -0.4763363847814673\n",
            "The money earned by LSTM with Fundamental and Technical data is %(unchange) -0.4763363847814673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzNmigWXSDnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef14e8dc-8bff-4d12-d9f3-4574399af5b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'URI',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BBWI',\n",
              "  'BKNG',\n",
              "  'ARE',\n",
              "  'ADBE',\n",
              "  'CSGP',\n",
              "  'FFIV',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'MCO',\n",
              "  'CTSH',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'URI',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BBWI',\n",
              "  'BKNG',\n",
              "  'ARE',\n",
              "  'ADBE',\n",
              "  'CSGP',\n",
              "  'FFIV',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'MCO',\n",
              "  'CTSH',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'URI',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BBWI',\n",
              "  'BKNG',\n",
              "  'ARE',\n",
              "  'ADBE',\n",
              "  'CSGP',\n",
              "  'FFIV',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'MCO',\n",
              "  'CTSH',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'URI',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BBWI',\n",
              "  'BKNG',\n",
              "  'ARE',\n",
              "  'ADBE',\n",
              "  'CSGP',\n",
              "  'FFIV',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'MCO',\n",
              "  'CTSH',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'URI',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BBWI',\n",
              "  'BKNG',\n",
              "  'ARE',\n",
              "  'ADBE',\n",
              "  'CSGP',\n",
              "  'FFIV',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'MCO',\n",
              "  'CTSH',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'URI',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BBWI',\n",
              "  'BKNG',\n",
              "  'ARE',\n",
              "  'ADBE',\n",
              "  'CSGP',\n",
              "  'FFIV',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'MCO',\n",
              "  'CTSH',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'URI',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BBWI',\n",
              "  'BKNG',\n",
              "  'ARE',\n",
              "  'ADBE',\n",
              "  'CSGP',\n",
              "  'FFIV',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'MCO',\n",
              "  'CTSH',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'URI',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BBWI',\n",
              "  'BKNG',\n",
              "  'ARE',\n",
              "  'ADBE',\n",
              "  'CSGP',\n",
              "  'FFIV',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'MCO',\n",
              "  'CTSH',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['BWA',\n",
              "  'URI',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL'],\n",
              " ['URI',\n",
              "  'BWA',\n",
              "  'EMN',\n",
              "  'UNH',\n",
              "  'TXT',\n",
              "  'FMC',\n",
              "  'EIX',\n",
              "  'AMZN',\n",
              "  'BKNG',\n",
              "  'BBWI',\n",
              "  'ARE',\n",
              "  'FFIV',\n",
              "  'CSGP',\n",
              "  'ADBE',\n",
              "  'SWKS',\n",
              "  'CI',\n",
              "  'VFC',\n",
              "  'ODFL',\n",
              "  'CTSH',\n",
              "  'MCO',\n",
              "  'JBHT',\n",
              "  'ROST',\n",
              "  'CPRT',\n",
              "  'WYNN',\n",
              "  'MTCH',\n",
              "  'MNST',\n",
              "  'VTR',\n",
              "  'AMT',\n",
              "  'CTRA',\n",
              "  'TYL']]"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ],
      "source": [
        "stock_selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWEoAWAUTUwu"
      },
      "source": [
        "# GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qu8buIGvJIL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4ee8fa-8b36-43ef-d426-20ab669f251c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "24/26 [==========================>...] - ETA: 0s - loss: 0.8176\n",
            "Epoch 1: val_loss improved from inf to 0.26238, saving model to weights_GRU.h5\n",
            "26/26 [==============================] - 6s 68ms/step - loss: 0.7818 - val_loss: 0.2624 - lr: 0.0100\n",
            "Epoch 2/15\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.3403\n",
            "Epoch 2: val_loss improved from 0.26238 to 0.25451, saving model to weights_GRU.h5\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.3398 - val_loss: 0.2545 - lr: 0.0100\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.3233\n",
            "Epoch 3: val_loss improved from 0.25451 to 0.25248, saving model to weights_GRU.h5\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.3233 - val_loss: 0.2525 - lr: 0.0100\n",
            "Epoch 4/15\n",
            "24/26 [==========================>...] - ETA: 0s - loss: 0.3050\n",
            "Epoch 4: val_loss improved from 0.25248 to 0.24879, saving model to weights_GRU.h5\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.3037 - val_loss: 0.2488 - lr: 0.0100\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.2854\n",
            "Epoch 5: val_loss did not improve from 0.24879\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.2854 - val_loss: 0.2604 - lr: 0.0100\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.2748\n",
            "Epoch 6: val_loss improved from 0.24879 to 0.24842, saving model to weights_GRU.h5\n",
            "26/26 [==============================] - 1s 35ms/step - loss: 0.2748 - val_loss: 0.2484 - lr: 0.0100\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.2646\n",
            "Epoch 7: val_loss did not improve from 0.24842\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.2646 - val_loss: 0.2522 - lr: 0.0100\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.2678\n",
            "Epoch 8: val_loss did not improve from 0.24842\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.2678 - val_loss: 0.2599 - lr: 0.0100\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.2611\n",
            "Epoch 9: val_loss did not improve from 0.24842\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.2611 - val_loss: 0.2541 - lr: 0.0100\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.2587\n",
            "Epoch 10: val_loss did not improve from 0.24842\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.2587 - val_loss: 0.2593 - lr: 0.0100\n",
            "Epoch 11/15\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.2544\n",
            "Epoch 11: val_loss did not improve from 0.24842\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.2541 - val_loss: 0.2525 - lr: 0.0100\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.2641\n",
            "Epoch 12: val_loss did not improve from 0.24842\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.2641 - val_loss: 0.2491 - lr: 0.0100\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.2554\n",
            "Epoch 13: val_loss did not improve from 0.24842\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.2554 - val_loss: 0.2534 - lr: 0.0100\n",
            "Epoch 14/15\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.2484\n",
            "Epoch 14: val_loss did not improve from 0.24842\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.2487 - val_loss: 0.2527 - lr: 0.0100\n",
            "Epoch 15/15\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.2480\n",
            "Epoch 15: val_loss did not improve from 0.24842\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.2480 - val_loss: 0.2564 - lr: 0.0100\n",
            "CPU times: user 14.5 s, sys: 1.73 s, total: 16.3 s\n",
            "Wall time: 15 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# The GRU architecture\n",
        "regressorGRU = Sequential()\n",
        "# First GRU layer with Dropout regularisation\n",
        "regressorGRU.add(GRU(units=1024, return_sequences=True, input_shape=(n_past, x_dataset.shape[1]), activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# Second GRU layer\n",
        "regressorGRU.add(GRU(units=512, return_sequences=True, input_shape=(n_past, x_dataset.shape[1]), activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# Third GRU layer\n",
        "regressorGRU.add(GRU(units=500, return_sequences=True, input_shape=(n_past, x_dataset.shape[1]), activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# Fourth GRU layer\n",
        "regressorGRU.add(GRU(units=500, activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# The output layer\n",
        "regressorGRU.add(Dense(units=500))\n",
        "# Compiling the RNN\n",
        "regressorGRU.compile(optimizer = Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "#regressorGRU.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
        "mcp = ModelCheckpoint(filepath='/content/drive/My Drive/FYP Data/weights_GRU.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "tb = TensorBoard('logs')\n",
        "\n",
        "# Fitting to the training set\n",
        "history = regressorGRU.fit(x_train, y_train, shuffle=True, epochs=15, callbacks=[es, rlr, mcp, tb], validation_split=0.2, verbose=1, batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k18JxryGwTeA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "facbb028-fbc7-4279-b859-4300439abaff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-7b47c2667c38>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Model Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressorGRU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \"\"\"\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         X = check_array(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ],
      "source": [
        "#Model Evaluation\n",
        "predictions = regressorGRU.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhiBTi0XxwRT"
      },
      "outputs": [],
      "source": [
        "#calculate the top 10 stock we picked\n",
        "stock_selection_index = np.argsort(predictions)[:,-30:]\n",
        "stock_selection = []\n",
        "for index in stock_selection_index:\n",
        "  stock_list = []\n",
        "  for stock_i in index:\n",
        "    stock_list.append(SP500_ticker[stock_i])\n",
        "  stock_selection.append(stock_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trading simulate\n",
        "original_money = 0\n",
        "trading = 0\n",
        "for stock in stock_selection[0]:\n",
        "  original_money = original_money + stock_data[stock][\"Close\"][test_period[0]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[0]])\n",
        "\n",
        "\n",
        "trading = - original_money\n",
        "i = 0\n",
        "\n",
        "for stock_list in stock_selection:\n",
        "  if i==0 or 25:\n",
        "    i = i + 1\n",
        "    continue\n",
        "\n",
        "  for stock in stock_list:\n",
        "    trading = trading + stock_data[stock][\"Close\"][test_period[i-1]] - stock_data[stock][\"Close\"][test_period[i]]\n",
        "    #print(trading)\n",
        "  \n",
        "  i = i + 1\n",
        "\n",
        "end_money = 0\n",
        "\n",
        "for stock in stock_selection[-1]:\n",
        "  trading = trading + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  end_money = end_money + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[-1]])\n",
        "\n",
        "print('The money earned by LSTM with Fundamental and Technical data is ',trading)\n",
        "print('The money earned by LSTM with Fundamental and Technical data is %',trading*100/original_money)\n",
        "print('The money earned by LSTM with Fundamental and Technical data is %(unchange)',(end_money-original_money)*100/original_money)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nDjgM7Frat-",
        "outputId": "463ef93f-4247-43a9-8557-c7c4d7a0fa0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The money earned by LSTM with Fundamental and Technical data is  301.037314414978\n",
            "The money earned by LSTM with Fundamental and Technical data is % 8.04436665883254\n",
            "The money earned by LSTM with Fundamental and Technical data is %(unchange) 8.04436665883254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OcbYONwxwJl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "637c3d19-6d2a-4827-d7da-7a585b67f897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'val_loss', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('GRU model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rolling strategies"
      ],
      "metadata": {
        "id": "xDPva-iTzrGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GRU"
      ],
      "metadata": {
        "id": "VXUg95E_09De"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
        "mcp = ModelCheckpoint(filepath='/content/drive/My Drive/FYP Data/model/GRU_long_fintune_123.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
        "predictions = []\n",
        "\n",
        "for i in tqdm(range(26)):\n",
        "  if i == 0:\n",
        "    GRU_model = keras.models.load_model('/content/drive/My Drive/FYP Data/model/GRU_long_123.h5')\n",
        "  else:\n",
        "    GRU_model = keras.models.load_model('/content/drive/My Drive/FYP Data/model/GRU_long_fintune_123.h5')\n",
        "  prediction = GRU_model.predict(x_test[i:i+1])\n",
        "  predictions.append(prediction)\n",
        "  x_train = x_dataset[i:train_point+i]\n",
        "  y_train = y_dataset[i:train_point+i]\n",
        "\n",
        "  #fintune model\n",
        "  history = GRU_model.fit(x_train, y_train, shuffle=True, epochs=10, callbacks=[es, rlr, mcp, tb], validation_split=0.2, verbose=1, batch_size=10)\n",
        "\n",
        "predictions = np.vstack([predictions[i] for i in range(26)])\n",
        "#Model Evaluation\n",
        "#predictions = scaler.inverse_transform(predictions)\n",
        "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "print('rmse', rmse)\n",
        "\n",
        "#profit test\n",
        "test_period = time[n_past+train_point:]\n",
        "\n",
        "#calculate the top 10 stock we picked\n",
        "stock_selection_index = np.argsort(predictions)[:,-30:]\n",
        "stock_selection = []\n",
        "for index in stock_selection_index:\n",
        "  stock_list = []\n",
        "  for stock_i in index:\n",
        "    stock_list.append(SP500_ticker[stock_i])\n",
        "  stock_selection.append(stock_list)\n",
        "\n",
        "#trading simulate\n",
        "original_money = 0\n",
        "trading = 0\n",
        "for stock in stock_selection[0]:\n",
        "  original_money = original_money + stock_data[stock][\"Close\"][test_period[0]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[0]])\n",
        "\n",
        "\n",
        "trading = - original_money\n",
        "i = 0\n",
        "\n",
        "for stock_list in stock_selection:\n",
        "  if i==0 or 25:\n",
        "    i = i + 1\n",
        "    continue\n",
        "\n",
        "  for stock in stock_list:\n",
        "    trading = trading + stock_data[stock][\"Close\"][test_period[i-1]] - stock_data[stock][\"Close\"][test_period[i]]\n",
        "    #print(trading)\n",
        "  \n",
        "  i = i + 1\n",
        "\n",
        "end_money = 0\n",
        "\n",
        "for stock in stock_selection[-1]:\n",
        "  trading = trading + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  end_money = end_money + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[-1]])\n",
        "\n",
        "print('The money earned by GRU with Fundamental and Technical data is ',trading)\n",
        "print('The money earned by GRU with Fundamental and Technical data is %',trading*100/original_money)\n",
        "print('The money earned by GRU with Fundamental and Technical data is %(unchange)',(end_money-original_money)*100/original_money)\n"
      ],
      "metadata": {
        "id": "Nq8k9aTIBQ0M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "620c2af3075b4ecfb7addabf248b7f16",
            "deb6b4c4f5a34324b02b615cc3295bff",
            "0bb6f564907d49e19e34e31ca75892ea",
            "bf36acb0f3fe47ffb8772b344fa99d5c",
            "328268cb36aa4dfea7adccfe854414de",
            "447dbb959e6d4bf18bccf2fe927cfcf7",
            "573649a3fa444cbd95ad0c9c8b13c690",
            "e28cdf2772824dbf8f223c3df85a5b77",
            "6e4298c243ab4f5ba54193747daa97d7",
            "327deda11ff0445ebfb583218b57ed08",
            "789fb395675942938f228ffde5f8fcd0"
          ]
        },
        "outputId": "ab98810d-cb61-4ae5-bf8a-24351712c72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/26 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "620c2af3075b4ecfb7addabf248b7f16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 1/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4592\n",
            "Epoch 1: val_loss improved from inf to 1.67061, saving model to /content/drive/My Drive/FYP Data/model/GRU_long_fintune_123.h5\n",
            "20/20 [==============================] - 4s 102ms/step - loss: 1.4644 - val_loss: 1.6706 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4546\n",
            "Epoch 2: val_loss did not improve from 1.67061\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4582 - val_loss: 1.7021 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4555\n",
            "Epoch 3: val_loss did not improve from 1.67061\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4543 - val_loss: 2.0432 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4409\n",
            "Epoch 4: val_loss did not improve from 1.67061\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4373 - val_loss: 1.6771 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4295\n",
            "Epoch 5: val_loss did not improve from 1.67061\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4200 - val_loss: 1.7777 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4465\n",
            "Epoch 6: val_loss did not improve from 1.67061\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4465 - val_loss: 1.8027 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3936\n",
            "Epoch 7: val_loss improved from 1.67061 to 1.66309, saving model to /content/drive/My Drive/FYP Data/model/GRU_long_fintune_123.h5\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 1.4006 - val_loss: 1.6631 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3922\n",
            "Epoch 8: val_loss did not improve from 1.66309\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3941 - val_loss: 1.6895 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3931\n",
            "Epoch 9: val_loss did not improve from 1.66309\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3997 - val_loss: 1.7612 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4275\n",
            "Epoch 10: val_loss did not improve from 1.66309\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4132 - val_loss: 1.7726 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4211\n",
            "Epoch 1: val_loss did not improve from 1.66309\n",
            "20/20 [==============================] - 4s 82ms/step - loss: 1.4035 - val_loss: 1.8935 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4200\n",
            "Epoch 2: val_loss improved from 1.66309 to 1.62643, saving model to /content/drive/My Drive/FYP Data/model/GRU_long_fintune_123.h5\n",
            "20/20 [==============================] - 2s 99ms/step - loss: 1.4200 - val_loss: 1.6264 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4328\n",
            "Epoch 3: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.4299 - val_loss: 1.6846 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4060\n",
            "Epoch 4: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 1.3940 - val_loss: 1.8994 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4058\n",
            "Epoch 5: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4107 - val_loss: 1.9279 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3878\n",
            "Epoch 6: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3812 - val_loss: 1.8663 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4066\n",
            "Epoch 7: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 1.4066 - val_loss: 2.0032 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.3789\n",
            "Epoch 8: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 1.3772 - val_loss: 1.7312 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4140\n",
            "Epoch 9: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.4140 - val_loss: 1.9743 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3489\n",
            "Epoch 10: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.3546 - val_loss: 1.8742 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 1/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3690\n",
            "Epoch 1: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 5s 82ms/step - loss: 1.3911 - val_loss: 1.8498 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3891\n",
            "Epoch 2: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3798 - val_loss: 1.7587 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3977\n",
            "Epoch 3: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4067 - val_loss: 1.6321 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.3965\n",
            "Epoch 4: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3965 - val_loss: 1.7249 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3948\n",
            "Epoch 5: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3887 - val_loss: 1.6976 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4345\n",
            "Epoch 6: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4158 - val_loss: 1.7134 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4148\n",
            "Epoch 7: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4092 - val_loss: 1.6893 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4296\n",
            "Epoch 8: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4296 - val_loss: 1.6994 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3784\n",
            "Epoch 9: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3820 - val_loss: 1.6349 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3563\n",
            "Epoch 10: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3520 - val_loss: 1.6509 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 990ms/step\n",
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3875\n",
            "Epoch 1: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 4s 78ms/step - loss: 1.3904 - val_loss: 1.6375 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3889\n",
            "Epoch 2: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4049 - val_loss: 1.7071 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3818\n",
            "Epoch 3: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3811 - val_loss: 1.6549 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4032\n",
            "Epoch 4: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4015 - val_loss: 1.6596 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.3806\n",
            "Epoch 5: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 1.3806 - val_loss: 1.9893 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3863\n",
            "Epoch 6: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3777 - val_loss: 1.7476 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.3638\n",
            "Epoch 7: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3638 - val_loss: 1.7114 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.3639\n",
            "Epoch 8: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3639 - val_loss: 1.7624 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.3934\n",
            "Epoch 9: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3934 - val_loss: 1.9415 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4491\n",
            "Epoch 10: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4407 - val_loss: 1.7936 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 980ms/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4044\n",
            "Epoch 1: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 4s 78ms/step - loss: 1.4101 - val_loss: 1.6457 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4928\n",
            "Epoch 2: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4788 - val_loss: 1.8533 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3905\n",
            "Epoch 3: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3955 - val_loss: 1.7904 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.3817\n",
            "Epoch 4: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3817 - val_loss: 1.8383 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3877\n",
            "Epoch 5: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3875 - val_loss: 1.8004 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4041\n",
            "Epoch 6: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3947 - val_loss: 1.7995 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3652\n",
            "Epoch 7: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3788 - val_loss: 1.7923 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4232\n",
            "Epoch 8: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4172 - val_loss: 1.9948 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4300\n",
            "Epoch 9: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4300 - val_loss: 1.6610 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4098\n",
            "Epoch 10: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4157 - val_loss: 1.7841 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4107\n",
            "Epoch 1: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 4s 80ms/step - loss: 1.4097 - val_loss: 1.6485 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.3706\n",
            "Epoch 2: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3706 - val_loss: 1.7180 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4780\n",
            "Epoch 3: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4808 - val_loss: 1.6345 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4177\n",
            "Epoch 4: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4177 - val_loss: 1.6632 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4256\n",
            "Epoch 5: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4211 - val_loss: 1.9553 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4316\n",
            "Epoch 6: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4262 - val_loss: 1.8653 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4405\n",
            "Epoch 7: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4298 - val_loss: 1.9777 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4101\n",
            "Epoch 8: val_loss did not improve from 1.62643\n",
            "20/20 [==============================] - 1s 27ms/step - loss: 1.4028 - val_loss: 1.7976 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3782\n",
            "Epoch 9: val_loss improved from 1.62643 to 1.58125, saving model to /content/drive/My Drive/FYP Data/model/GRU_long_fintune_123.h5\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 1.3814 - val_loss: 1.5813 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4080\n",
            "Epoch 10: val_loss did not improve from 1.58125\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4100 - val_loss: 1.6841 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 1000ms/step\n",
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4423\n",
            "Epoch 1: val_loss did not improve from 1.58125\n",
            "20/20 [==============================] - 4s 77ms/step - loss: 1.4465 - val_loss: 1.6012 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4514\n",
            "Epoch 2: val_loss did not improve from 1.58125\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4461 - val_loss: 1.6592 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4020\n",
            "Epoch 3: val_loss did not improve from 1.58125\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 1.4064 - val_loss: 1.6048 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3852\n",
            "Epoch 4: val_loss did not improve from 1.58125\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3881 - val_loss: 1.7501 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3752\n",
            "Epoch 5: val_loss did not improve from 1.58125\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3793 - val_loss: 1.9311 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4220\n",
            "Epoch 6: val_loss did not improve from 1.58125\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4220 - val_loss: 1.6309 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4373\n",
            "Epoch 7: val_loss did not improve from 1.58125\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4394 - val_loss: 1.6513 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4188\n",
            "Epoch 8: val_loss did not improve from 1.58125\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4196 - val_loss: 1.8179 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4107\n",
            "Epoch 9: val_loss did not improve from 1.58125\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4218 - val_loss: 1.6248 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4053\n",
            "Epoch 10: val_loss did not improve from 1.58125\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4284 - val_loss: 1.7677 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 1/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4565\n",
            "Epoch 1: val_loss did not improve from 1.58125\n",
            "20/20 [==============================] - 5s 77ms/step - loss: 1.4459 - val_loss: 2.0031 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3891\n",
            "Epoch 2: val_loss did not improve from 1.58125\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3882 - val_loss: 1.7667 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3859\n",
            "Epoch 3: val_loss did not improve from 1.58125\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3753 - val_loss: 1.8275 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3732\n",
            "Epoch 4: val_loss improved from 1.58125 to 1.58013, saving model to /content/drive/My Drive/FYP Data/model/GRU_long_fintune_123.h5\n",
            "20/20 [==============================] - 2s 89ms/step - loss: 1.3794 - val_loss: 1.5801 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4109\n",
            "Epoch 5: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4073 - val_loss: 1.6660 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4098\n",
            "Epoch 6: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4098 - val_loss: 1.6738 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4217\n",
            "Epoch 7: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4217 - val_loss: 1.8419 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4079\n",
            "Epoch 8: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3978 - val_loss: 1.8685 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.3790\n",
            "Epoch 9: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3790 - val_loss: 1.7886 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3615\n",
            "Epoch 10: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3583 - val_loss: 1.7613 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 981ms/step\n",
            "Epoch 1/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3858\n",
            "Epoch 1: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 4s 80ms/step - loss: 1.4020 - val_loss: 1.6241 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4029\n",
            "Epoch 2: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4029 - val_loss: 1.5967 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4230\n",
            "Epoch 3: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4136 - val_loss: 2.0461 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4013\n",
            "Epoch 4: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3997 - val_loss: 1.7474 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4386\n",
            "Epoch 5: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 1.4386 - val_loss: 1.6636 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4071\n",
            "Epoch 6: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 1.4071 - val_loss: 1.7187 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4210\n",
            "Epoch 7: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4258 - val_loss: 1.7580 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4289\n",
            "Epoch 8: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4289 - val_loss: 1.8207 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4475\n",
            "Epoch 9: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4475 - val_loss: 1.8171 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.3836\n",
            "Epoch 10: val_loss did not improve from 1.58013\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3836 - val_loss: 1.8172 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 985ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4269\n",
            "Epoch 1: val_loss improved from 1.58013 to 1.53750, saving model to /content/drive/My Drive/FYP Data/model/GRU_long_fintune_123.h5\n",
            "20/20 [==============================] - 4s 98ms/step - loss: 1.4269 - val_loss: 1.5375 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4312\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4334 - val_loss: 1.8077 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4496\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4496 - val_loss: 2.0215 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4160\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4210 - val_loss: 1.7765 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3952\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3971 - val_loss: 1.6667 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3691\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3611 - val_loss: 1.7195 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4077\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4054 - val_loss: 1.8519 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3859\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3780 - val_loss: 1.8672 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4233\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4233 - val_loss: 1.7668 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3742\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3762 - val_loss: 1.7224 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 990ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4384\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 5s 89ms/step - loss: 1.4384 - val_loss: 1.6990 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3971\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3957 - val_loss: 1.7195 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3944\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3978 - val_loss: 2.0118 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3993\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 1.4025 - val_loss: 1.7050 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.3664\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3664 - val_loss: 1.6229 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4222\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4185 - val_loss: 1.6543 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4326\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4326 - val_loss: 1.7431 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.3924\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3924 - val_loss: 1.6463 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4182\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4243 - val_loss: 1.6075 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4674\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4721 - val_loss: 1.6456 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 958ms/step\n",
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4177\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 4s 79ms/step - loss: 1.4255 - val_loss: 1.7882 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4211\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4232 - val_loss: 1.7262 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4356\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4299 - val_loss: 1.7366 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4080\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4080 - val_loss: 1.6502 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3913\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3942 - val_loss: 1.8761 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4005\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3990 - val_loss: 1.7526 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4579\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4578 - val_loss: 1.7177 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4135\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4124 - val_loss: 1.7027 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4005\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3976 - val_loss: 1.7301 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4433\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4366 - val_loss: 1.6794 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3980\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 4s 77ms/step - loss: 1.3950 - val_loss: 1.6967 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4388\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4322 - val_loss: 1.7279 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4121\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4108 - val_loss: 1.6587 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4046\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4046 - val_loss: 1.8928 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3771\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3746 - val_loss: 1.7380 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4204\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4247 - val_loss: 1.8358 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4478\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4497 - val_loss: 1.8385 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4525\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4503 - val_loss: 1.8045 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4247\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4247 - val_loss: 1.7365 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3926\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4084 - val_loss: 1.7120 - lr: 0.0100\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.3984\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 4s 77ms/step - loss: 1.3984 - val_loss: 1.7778 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4254\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4528 - val_loss: 1.5941 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4233\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4224 - val_loss: 1.7461 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4432\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4432 - val_loss: 1.8691 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4356\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4311 - val_loss: 1.6696 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4304\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4418 - val_loss: 1.6907 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4743\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4682 - val_loss: 1.8836 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4120\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4194 - val_loss: 1.7667 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4525\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4525 - val_loss: 1.6423 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4620\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4620 - val_loss: 1.6654 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.3892\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 4s 82ms/step - loss: 1.3888 - val_loss: 1.7961 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4187\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4152 - val_loss: 1.8398 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4884\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4967 - val_loss: 1.7479 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4162\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4104 - val_loss: 1.8606 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4108\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4124 - val_loss: 1.6142 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4163\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4155 - val_loss: 1.6975 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3878\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3984 - val_loss: 1.6924 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3974\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4039 - val_loss: 1.6369 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4285\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4229 - val_loss: 1.8583 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.5058\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.5199 - val_loss: 1.6167 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 980ms/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4224\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 5s 84ms/step - loss: 1.4237 - val_loss: 1.7789 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4228\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4329 - val_loss: 1.6163 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4525\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4545 - val_loss: 1.7120 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4512\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4519 - val_loss: 1.6758 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4468\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4657 - val_loss: 1.6675 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4174\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4116 - val_loss: 1.5987 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3929\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4017 - val_loss: 1.6291 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4520\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4475 - val_loss: 1.7213 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4100\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4137 - val_loss: 1.6843 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4147\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4254 - val_loss: 1.5943 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 990ms/step\n",
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4738\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 4s 79ms/step - loss: 1.4711 - val_loss: 1.9603 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4426\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4467 - val_loss: 1.6309 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.3973\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3973 - val_loss: 1.6045 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4236\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4234 - val_loss: 1.7591 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3937\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4034 - val_loss: 1.6267 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4435\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4388 - val_loss: 1.7414 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4424\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4424 - val_loss: 2.0435 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4457\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4515 - val_loss: 1.7651 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3956\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4109 - val_loss: 1.6159 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4476\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4476 - val_loss: 1.7548 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 986ms/step\n",
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4243\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 4s 76ms/step - loss: 1.4261 - val_loss: 1.6401 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4472\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4437 - val_loss: 1.8923 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4191\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4191 - val_loss: 1.6992 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4401\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4401 - val_loss: 1.7774 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4661\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4847 - val_loss: 1.6628 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4343\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4343 - val_loss: 1.6892 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.3852\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.3894 - val_loss: 1.7927 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4328\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4368 - val_loss: 1.7184 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4419\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4478 - val_loss: 1.7271 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4674\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4674 - val_loss: 1.6196 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 966ms/step\n",
            "Epoch 1/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4507\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 5s 81ms/step - loss: 1.4425 - val_loss: 1.7822 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.5516\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.5496 - val_loss: 1.6121 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.3892\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3844 - val_loss: 1.6797 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4627\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4627 - val_loss: 1.6319 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4158\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4322 - val_loss: 1.6033 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4685\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4688 - val_loss: 1.7265 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4341\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4341 - val_loss: 1.6858 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4392\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4415 - val_loss: 1.6893 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4371\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4448 - val_loss: 1.7459 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4779\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4787 - val_loss: 1.6202 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 983ms/step\n",
            "Epoch 1/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4714\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 4s 78ms/step - loss: 1.4624 - val_loss: 1.8938 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4698\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4618 - val_loss: 1.7658 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4420\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4446 - val_loss: 2.1269 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4855\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4855 - val_loss: 1.7599 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4397\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4432 - val_loss: 1.6190 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4658\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4520 - val_loss: 1.8227 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4688\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4572 - val_loss: 1.7316 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4148\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4207 - val_loss: 1.6474 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4502\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4404 - val_loss: 1.7892 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4196\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4256 - val_loss: 1.6028 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4405\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 4s 77ms/step - loss: 1.4460 - val_loss: 1.7880 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4191\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4315 - val_loss: 1.6052 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4269\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4288 - val_loss: 1.6395 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4323\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4323 - val_loss: 1.7073 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4970\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4804 - val_loss: 1.8324 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4635\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4431 - val_loss: 1.7742 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4301\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4393 - val_loss: 1.7549 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4568\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4568 - val_loss: 1.6839 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.5148\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.5177 - val_loss: 1.6600 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4552\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4366 - val_loss: 1.8708 - lr: 0.0100\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4740\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 4s 78ms/step - loss: 1.4772 - val_loss: 1.6663 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4979\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4952 - val_loss: 1.8486 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4457\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4455 - val_loss: 1.8325 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4593\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4623 - val_loss: 1.6646 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4511\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4492 - val_loss: 1.6906 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4628\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4675 - val_loss: 1.7152 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4426\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4417 - val_loss: 1.6674 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4162\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4162 - val_loss: 1.7338 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4223\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4223 - val_loss: 1.7509 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4803\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4825 - val_loss: 1.7201 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 989ms/step\n",
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4375\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 4s 76ms/step - loss: 1.4354 - val_loss: 1.6116 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4473\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4458 - val_loss: 1.6681 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4517\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4547 - val_loss: 1.7891 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4969\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4957 - val_loss: 1.8112 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4484\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4512 - val_loss: 1.5935 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4399\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4377 - val_loss: 1.7350 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4539\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4569 - val_loss: 1.8332 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4288\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4351 - val_loss: 1.7332 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4364\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4333 - val_loss: 1.6814 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4185\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4185 - val_loss: 1.6451 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4235\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 5s 117ms/step - loss: 1.4290 - val_loss: 1.6525 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.4220\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 1.4225 - val_loss: 1.7593 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4336\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4299 - val_loss: 1.7914 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4497\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4491 - val_loss: 1.6025 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4560\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4655 - val_loss: 1.7255 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4564\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4698 - val_loss: 1.8903 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4439\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4495 - val_loss: 1.8385 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4664\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4714 - val_loss: 1.6722 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4308\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4350 - val_loss: 1.6549 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4497\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4520 - val_loss: 1.6482 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 1/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4473\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 4s 78ms/step - loss: 1.4486 - val_loss: 1.7314 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4595\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4525 - val_loss: 1.8486 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4439\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4432 - val_loss: 1.7561 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4997\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4942 - val_loss: 1.9008 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4500\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4492 - val_loss: 1.6246 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4368\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4368 - val_loss: 1.6800 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4359\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4489 - val_loss: 1.5707 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4491\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4479 - val_loss: 1.6929 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4563\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.4562 - val_loss: 1.6186 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4786\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4786 - val_loss: 1.7463 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.4486\n",
            "Epoch 1: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 4s 76ms/step - loss: 1.4438 - val_loss: 1.6967 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4639\n",
            "Epoch 2: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4698 - val_loss: 1.6794 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4539\n",
            "Epoch 3: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4641 - val_loss: 1.6118 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4367\n",
            "Epoch 4: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4389 - val_loss: 1.7218 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4672\n",
            "Epoch 5: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4618 - val_loss: 1.6524 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4626\n",
            "Epoch 6: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4708 - val_loss: 1.7487 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4724\n",
            "Epoch 7: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4732 - val_loss: 2.0023 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.5608\n",
            "Epoch 8: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.5569 - val_loss: 2.1921 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.5091\n",
            "Epoch 9: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4928 - val_loss: 1.8826 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 1.4572\n",
            "Epoch 10: val_loss did not improve from 1.53750\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.4504 - val_loss: 1.6938 - lr: 0.0100\n",
            "rmse 0.015335678801656916\n",
            "The money earned by GRU with Fundamental and Technical data is  1704.1274347305298\n",
            "The money earned by GRU with Fundamental and Technical data is % 40.83598280100755\n",
            "The money earned by GRU with Fundamental and Technical data is %(unchange) 40.83598280100755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_selection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMSLuXKzpe4f",
        "outputId": "5d1b5a3b-3144-4906-82c2-f5526275d49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['TAP',\n",
              "  'FDS',\n",
              "  'MGM',\n",
              "  'MOS',\n",
              "  'ADI',\n",
              "  'IEX',\n",
              "  'AMD',\n",
              "  'NI',\n",
              "  'MTCH',\n",
              "  'CHRW',\n",
              "  'LMT',\n",
              "  'LRCX',\n",
              "  'FRT',\n",
              "  'DLTR',\n",
              "  'DHI',\n",
              "  'NEE',\n",
              "  'F',\n",
              "  'COP',\n",
              "  'MO',\n",
              "  'UDR',\n",
              "  'AJG',\n",
              "  'ATVI',\n",
              "  'EW',\n",
              "  'HD',\n",
              "  'PKI',\n",
              "  'TECH',\n",
              "  'TRMB',\n",
              "  'LHX',\n",
              "  'TTWO',\n",
              "  'AIG'],\n",
              " ['WBA',\n",
              "  'MMC',\n",
              "  'OKE',\n",
              "  'ATO',\n",
              "  'NEE',\n",
              "  'MAA',\n",
              "  'FRT',\n",
              "  'K',\n",
              "  'ROST',\n",
              "  'MCHP',\n",
              "  'BXP',\n",
              "  'DLR',\n",
              "  'PSA',\n",
              "  'IRM',\n",
              "  'C',\n",
              "  'GPC',\n",
              "  'INTU',\n",
              "  'CNC',\n",
              "  'TSCO',\n",
              "  'UDR',\n",
              "  'REG',\n",
              "  'KR',\n",
              "  'BBWI',\n",
              "  'PEG',\n",
              "  'WAB',\n",
              "  'VFC',\n",
              "  'IFF',\n",
              "  'PGR',\n",
              "  'CMCSA',\n",
              "  'SPG'],\n",
              " ['MHK',\n",
              "  'STE',\n",
              "  'REGN',\n",
              "  'CHD',\n",
              "  'AMD',\n",
              "  'WAT',\n",
              "  'ODFL',\n",
              "  'WYNN',\n",
              "  'NKE',\n",
              "  'KR',\n",
              "  'PNR',\n",
              "  'BKR',\n",
              "  'AOS',\n",
              "  'SNPS',\n",
              "  'TSCO',\n",
              "  'AVB',\n",
              "  'CTRA',\n",
              "  'SWKS',\n",
              "  'CAG',\n",
              "  'MTCH',\n",
              "  'CNC',\n",
              "  'CTSH',\n",
              "  'BIIB',\n",
              "  'SHW',\n",
              "  'APH',\n",
              "  'TMO',\n",
              "  'ADI',\n",
              "  'ROST',\n",
              "  'AZO',\n",
              "  'HAS'],\n",
              " ['MHK',\n",
              "  'STE',\n",
              "  'REGN',\n",
              "  'CHD',\n",
              "  'AMD',\n",
              "  'WAT',\n",
              "  'ODFL',\n",
              "  'WYNN',\n",
              "  'NKE',\n",
              "  'KR',\n",
              "  'PNR',\n",
              "  'BKR',\n",
              "  'AOS',\n",
              "  'SNPS',\n",
              "  'TSCO',\n",
              "  'AVB',\n",
              "  'CTRA',\n",
              "  'SWKS',\n",
              "  'CAG',\n",
              "  'MTCH',\n",
              "  'CNC',\n",
              "  'CTSH',\n",
              "  'BIIB',\n",
              "  'SHW',\n",
              "  'APH',\n",
              "  'TMO',\n",
              "  'ADI',\n",
              "  'ROST',\n",
              "  'AZO',\n",
              "  'HAS'],\n",
              " ['MHK',\n",
              "  'STE',\n",
              "  'REGN',\n",
              "  'CHD',\n",
              "  'AMD',\n",
              "  'WAT',\n",
              "  'ODFL',\n",
              "  'WYNN',\n",
              "  'NKE',\n",
              "  'KR',\n",
              "  'PNR',\n",
              "  'BKR',\n",
              "  'AOS',\n",
              "  'SNPS',\n",
              "  'TSCO',\n",
              "  'AVB',\n",
              "  'CTRA',\n",
              "  'SWKS',\n",
              "  'CAG',\n",
              "  'MTCH',\n",
              "  'CNC',\n",
              "  'CTSH',\n",
              "  'BIIB',\n",
              "  'SHW',\n",
              "  'APH',\n",
              "  'TMO',\n",
              "  'ADI',\n",
              "  'ROST',\n",
              "  'AZO',\n",
              "  'HAS'],\n",
              " ['MHK',\n",
              "  'STE',\n",
              "  'REGN',\n",
              "  'CHD',\n",
              "  'AMD',\n",
              "  'WAT',\n",
              "  'ODFL',\n",
              "  'WYNN',\n",
              "  'NKE',\n",
              "  'KR',\n",
              "  'PNR',\n",
              "  'BKR',\n",
              "  'AOS',\n",
              "  'SNPS',\n",
              "  'TSCO',\n",
              "  'AVB',\n",
              "  'CTRA',\n",
              "  'SWKS',\n",
              "  'CAG',\n",
              "  'MTCH',\n",
              "  'CNC',\n",
              "  'CTSH',\n",
              "  'BIIB',\n",
              "  'SHW',\n",
              "  'APH',\n",
              "  'TMO',\n",
              "  'ADI',\n",
              "  'ROST',\n",
              "  'AZO',\n",
              "  'HAS'],\n",
              " ['AIZ',\n",
              "  'MSCI',\n",
              "  'WBA',\n",
              "  'DFS',\n",
              "  'CNP',\n",
              "  'PARA',\n",
              "  'LKQ',\n",
              "  'HUM',\n",
              "  'PRU',\n",
              "  'TEL',\n",
              "  'URI',\n",
              "  'WELL',\n",
              "  'RMD',\n",
              "  'V',\n",
              "  'NKE',\n",
              "  'YUM',\n",
              "  'FICO',\n",
              "  'ZBRA',\n",
              "  'MSI',\n",
              "  'AFL',\n",
              "  'MA',\n",
              "  'LEN',\n",
              "  'WY',\n",
              "  'PODD',\n",
              "  'PSA',\n",
              "  'NDAQ',\n",
              "  'DHI',\n",
              "  'EXR',\n",
              "  'AEP',\n",
              "  'DPZ'],\n",
              " ['AIZ',\n",
              "  'MSCI',\n",
              "  'WBA',\n",
              "  'DFS',\n",
              "  'CNP',\n",
              "  'PARA',\n",
              "  'LKQ',\n",
              "  'HUM',\n",
              "  'PRU',\n",
              "  'TEL',\n",
              "  'URI',\n",
              "  'WELL',\n",
              "  'RMD',\n",
              "  'V',\n",
              "  'NKE',\n",
              "  'YUM',\n",
              "  'FICO',\n",
              "  'ZBRA',\n",
              "  'MSI',\n",
              "  'AFL',\n",
              "  'MA',\n",
              "  'LEN',\n",
              "  'WY',\n",
              "  'PODD',\n",
              "  'PSA',\n",
              "  'NDAQ',\n",
              "  'DHI',\n",
              "  'EXR',\n",
              "  'AEP',\n",
              "  'DPZ'],\n",
              " ['RJF',\n",
              "  'LRCX',\n",
              "  'ELV',\n",
              "  'PTC',\n",
              "  'CE',\n",
              "  'TAP',\n",
              "  'DAL',\n",
              "  'TXN',\n",
              "  'TRV',\n",
              "  'BAC',\n",
              "  'IVZ',\n",
              "  'CSCO',\n",
              "  'TSN',\n",
              "  'HON',\n",
              "  'C',\n",
              "  'EMR',\n",
              "  'DE',\n",
              "  'TTWO',\n",
              "  'TROW',\n",
              "  'LKQ',\n",
              "  'JPM',\n",
              "  'HPQ',\n",
              "  'WDC',\n",
              "  'CRM',\n",
              "  'INTC',\n",
              "  'KLAC',\n",
              "  'AME',\n",
              "  'STX',\n",
              "  'CAT',\n",
              "  'MAR'],\n",
              " ['RJF',\n",
              "  'LRCX',\n",
              "  'ELV',\n",
              "  'PTC',\n",
              "  'CE',\n",
              "  'TAP',\n",
              "  'DAL',\n",
              "  'TXN',\n",
              "  'TRV',\n",
              "  'BAC',\n",
              "  'IVZ',\n",
              "  'CSCO',\n",
              "  'TSN',\n",
              "  'HON',\n",
              "  'C',\n",
              "  'EMR',\n",
              "  'DE',\n",
              "  'TTWO',\n",
              "  'TROW',\n",
              "  'LKQ',\n",
              "  'JPM',\n",
              "  'HPQ',\n",
              "  'WDC',\n",
              "  'CRM',\n",
              "  'INTC',\n",
              "  'KLAC',\n",
              "  'AME',\n",
              "  'STX',\n",
              "  'CAT',\n",
              "  'MAR'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN'],\n",
              " ['AMT',\n",
              "  'TDY',\n",
              "  'BK',\n",
              "  'MLM',\n",
              "  'PHM',\n",
              "  'SBAC',\n",
              "  'FDS',\n",
              "  'LKQ',\n",
              "  'PWR',\n",
              "  'UAL',\n",
              "  'SCHW',\n",
              "  'EQT',\n",
              "  'SNPS',\n",
              "  'WMB',\n",
              "  'OKE',\n",
              "  'TFX',\n",
              "  'NTRS',\n",
              "  'CNC',\n",
              "  'CI',\n",
              "  'DAL',\n",
              "  'LRCX',\n",
              "  'WAT',\n",
              "  'ON',\n",
              "  'CVS',\n",
              "  'CDNS',\n",
              "  'TTWO',\n",
              "  'HUM',\n",
              "  'EA',\n",
              "  'EVRG',\n",
              "  'REGN']]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_stock_selection = pd.DataFrame (stock_selection)\n",
        "df_stock_selection.to_csv(\"drive/My Drive/FYP Data/GRU_TF_long_rolling_123_new.csv\",index=True, header=True )"
      ],
      "metadata": {
        "id": "759v5aka0GCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM"
      ],
      "metadata": {
        "id": "xXnyKF-X1Uq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
        "mcp = ModelCheckpoint(filepath='/content/drive/My Drive/FYP Data/model/LSTM_rolling_long_1234.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
        "predictions = []\n",
        "\n",
        "for i in tqdm(range(26)):\n",
        "  if i == 0:\n",
        "    LSTM_model = keras.models.load_model('/content/drive/My Drive/FYP Data/model/LSTM_long_123.h5')\n",
        "  else:\n",
        "    LSTM_model = keras.models.load_model('/content/drive/My Drive/FYP Data/model/LSTM_rolling_long_1234.h5')\n",
        "  prediction = LSTM_model.predict(x_test[i:i+1])\n",
        "  predictions.append(prediction)\n",
        "  x_train = x_dataset[i:train_point+i]\n",
        "  y_train = y_dataset[i:train_point+i]\n",
        "\n",
        "  #fintune model\n",
        "  history = LSTM_model.fit(x_train, y_train, shuffle=True, epochs=10, callbacks=[es, rlr, mcp, tb], validation_split=0.2, verbose=1, batch_size=10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9e7764be5d5040b59674327193ba2480",
            "c4f5b5025b614b36a0b0501200560841",
            "63e2099dbba44a93a94adb6aff462f9c",
            "d64eb3ea9f954b0e80be7aba4ffce549",
            "41f09347971c4b089364f8657f340b76",
            "7063794290324b2ab5e6a56331840e57",
            "f3b8de3aa16e4e5894dee380e74c7756",
            "87820eefc9804a08a9f0ef9b23e56c80",
            "27718b57383549be809a79a7451f1326",
            "f8b70c88b1334f8dbdc27bc83cb600f2",
            "f0ba9bdc69bf4369a3ce6da165f05c9e"
          ]
        },
        "id": "so_3ppjH071E",
        "outputId": "9f407b39-a1db-4457-8020-cc3fdcc7784b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/26 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e7764be5d5040b59674327193ba2480"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 578ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.1279\n",
            "Epoch 1: val_loss improved from inf to 1.44988, saving model to /content/drive/My Drive/FYP Data/model/LSTM_rolling_long_1234.h5\n",
            "20/20 [==============================] - 8s 342ms/step - loss: 1.1279 - val_loss: 1.4499 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1282\n",
            "Epoch 2: val_loss improved from 1.44988 to 1.42704, saving model to /content/drive/My Drive/FYP Data/model/LSTM_rolling_long_1234.h5\n",
            "20/20 [==============================] - 1s 51ms/step - loss: 1.1260 - val_loss: 1.4270 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1030\n",
            "Epoch 3: val_loss did not improve from 1.42704\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0986 - val_loss: 1.5071 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0960\n",
            "Epoch 4: val_loss improved from 1.42704 to 1.41605, saving model to /content/drive/My Drive/FYP Data/model/LSTM_rolling_long_1234.h5\n",
            "20/20 [==============================] - 1s 47ms/step - loss: 1.1019 - val_loss: 1.4161 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1019\n",
            "Epoch 5: val_loss did not improve from 1.41605\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1023 - val_loss: 1.4539 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1040\n",
            "Epoch 6: val_loss improved from 1.41605 to 1.40121, saving model to /content/drive/My Drive/FYP Data/model/LSTM_rolling_long_1234.h5\n",
            "20/20 [==============================] - 1s 48ms/step - loss: 1.1000 - val_loss: 1.4012 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0902\n",
            "Epoch 7: val_loss improved from 1.40121 to 1.39797, saving model to /content/drive/My Drive/FYP Data/model/LSTM_rolling_long_1234.h5\n",
            "20/20 [==============================] - 1s 47ms/step - loss: 1.0860 - val_loss: 1.3980 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0878\n",
            "Epoch 8: val_loss did not improve from 1.39797\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0839 - val_loss: 1.4054 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0823\n",
            "Epoch 9: val_loss did not improve from 1.39797\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0827 - val_loss: 1.4120 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0710\n",
            "Epoch 10: val_loss did not improve from 1.39797\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0760 - val_loss: 1.4417 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 683ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.0863\n",
            "Epoch 1: val_loss did not improve from 1.39797\n",
            "20/20 [==============================] - 3s 61ms/step - loss: 1.0863 - val_loss: 1.4066 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0999\n",
            "Epoch 2: val_loss did not improve from 1.39797\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1040 - val_loss: 1.4292 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0889\n",
            "Epoch 3: val_loss did not improve from 1.39797\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0890 - val_loss: 1.4096 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0855\n",
            "Epoch 4: val_loss did not improve from 1.39797\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0906 - val_loss: 1.4030 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0707\n",
            "Epoch 5: val_loss did not improve from 1.39797\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 1.0715 - val_loss: 1.4139 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0812\n",
            "Epoch 6: val_loss did not improve from 1.39797\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0811 - val_loss: 1.4125 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0909\n",
            "Epoch 7: val_loss did not improve from 1.39797\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0848 - val_loss: 1.4878 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0863\n",
            "Epoch 8: val_loss improved from 1.39797 to 1.39173, saving model to /content/drive/My Drive/FYP Data/model/LSTM_rolling_long_1234.h5\n",
            "20/20 [==============================] - 1s 48ms/step - loss: 1.0850 - val_loss: 1.3917 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0873\n",
            "Epoch 9: val_loss improved from 1.39173 to 1.38776, saving model to /content/drive/My Drive/FYP Data/model/LSTM_rolling_long_1234.h5\n",
            "20/20 [==============================] - 1s 47ms/step - loss: 1.0870 - val_loss: 1.3878 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0737\n",
            "Epoch 10: val_loss did not improve from 1.38776\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0754 - val_loss: 1.4417 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 618ms/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.0903\n",
            "Epoch 1: val_loss did not improve from 1.38776\n",
            "20/20 [==============================] - 3s 61ms/step - loss: 1.1001 - val_loss: 1.5239 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1026\n",
            "Epoch 2: val_loss did not improve from 1.38776\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0991 - val_loss: 1.4153 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0776\n",
            "Epoch 3: val_loss did not improve from 1.38776\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 1.0825 - val_loss: 1.4289 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0929\n",
            "Epoch 4: val_loss did not improve from 1.38776\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0949 - val_loss: 1.4637 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0818\n",
            "Epoch 5: val_loss did not improve from 1.38776\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0855 - val_loss: 1.4249 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0865\n",
            "Epoch 6: val_loss did not improve from 1.38776\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0803 - val_loss: 1.4085 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0845\n",
            "Epoch 7: val_loss did not improve from 1.38776\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0784 - val_loss: 1.4535 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0712\n",
            "Epoch 8: val_loss did not improve from 1.38776\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0722 - val_loss: 1.3940 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0960\n",
            "Epoch 9: val_loss improved from 1.38776 to 1.38061, saving model to /content/drive/My Drive/FYP Data/model/LSTM_rolling_long_1234.h5\n",
            "20/20 [==============================] - 2s 111ms/step - loss: 1.0974 - val_loss: 1.3806 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0756\n",
            "Epoch 10: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0798 - val_loss: 1.4289 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 616ms/step\n",
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0947\n",
            "Epoch 1: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 2s 59ms/step - loss: 1.0948 - val_loss: 1.4489 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0818\n",
            "Epoch 2: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0774 - val_loss: 1.4702 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0805\n",
            "Epoch 3: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0816 - val_loss: 1.4389 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1033\n",
            "Epoch 4: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1023 - val_loss: 1.4707 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0827\n",
            "Epoch 5: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0796 - val_loss: 1.4394 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0906\n",
            "Epoch 6: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0924 - val_loss: 1.4210 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0699\n",
            "Epoch 7: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0731 - val_loss: 1.4411 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0953\n",
            "Epoch 8: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0901 - val_loss: 1.4623 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1022\n",
            "Epoch 9: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1062 - val_loss: 1.4364 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0802\n",
            "Epoch 10: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0852 - val_loss: 1.4375 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.0940\n",
            "Epoch 1: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 3s 61ms/step - loss: 1.0940 - val_loss: 1.4415 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0983\n",
            "Epoch 2: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0926 - val_loss: 1.4473 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0813\n",
            "Epoch 3: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0790 - val_loss: 1.4750 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0847\n",
            "Epoch 4: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0842 - val_loss: 1.4327 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0804\n",
            "Epoch 5: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0793 - val_loss: 1.4029 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0945\n",
            "Epoch 6: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0932 - val_loss: 1.4273 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1034\n",
            "Epoch 7: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1011 - val_loss: 1.4063 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0934\n",
            "Epoch 8: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0970 - val_loss: 1.4133 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1009\n",
            "Epoch 9: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1001 - val_loss: 1.4245 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1115\n",
            "Epoch 10: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1133 - val_loss: 1.4442 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 623ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.0995\n",
            "Epoch 1: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 3s 104ms/step - loss: 1.0995 - val_loss: 1.4130 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0900\n",
            "Epoch 2: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0940 - val_loss: 1.4072 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0950\n",
            "Epoch 3: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0989 - val_loss: 1.4405 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0866\n",
            "Epoch 4: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0898 - val_loss: 1.5092 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0905\n",
            "Epoch 5: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0879 - val_loss: 1.4027 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0787\n",
            "Epoch 6: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0821 - val_loss: 1.4255 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0906\n",
            "Epoch 7: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0960 - val_loss: 1.4417 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0991\n",
            "Epoch 8: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0992 - val_loss: 1.3935 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1150\n",
            "Epoch 9: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1085 - val_loss: 1.4520 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0994\n",
            "Epoch 10: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1007 - val_loss: 1.4587 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 615ms/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.1090\n",
            "Epoch 1: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 2s 60ms/step - loss: 1.1210 - val_loss: 1.4020 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1319\n",
            "Epoch 2: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1280 - val_loss: 1.4458 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1303\n",
            "Epoch 3: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1300 - val_loss: 1.4227 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1000\n",
            "Epoch 4: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0975 - val_loss: 1.4419 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0895\n",
            "Epoch 5: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0931 - val_loss: 1.4542 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1010\n",
            "Epoch 6: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1066 - val_loss: 1.4133 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0991\n",
            "Epoch 7: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1007 - val_loss: 1.4346 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0962\n",
            "Epoch 8: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0963 - val_loss: 1.4197 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0891\n",
            "Epoch 9: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0833 - val_loss: 1.4484 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1098\n",
            "Epoch 10: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1050 - val_loss: 1.4316 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 607ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.1168\n",
            "Epoch 1: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 2s 59ms/step - loss: 1.1168 - val_loss: 1.4879 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1151\n",
            "Epoch 2: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1206 - val_loss: 1.4184 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1010\n",
            "Epoch 3: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1076 - val_loss: 1.4262 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1183\n",
            "Epoch 4: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1182 - val_loss: 1.4712 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0979\n",
            "Epoch 5: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0929 - val_loss: 1.4515 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0791\n",
            "Epoch 6: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0788 - val_loss: 1.4087 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0813\n",
            "Epoch 7: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.0893 - val_loss: 1.4355 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0934\n",
            "Epoch 8: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0917 - val_loss: 1.4402 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0943\n",
            "Epoch 9: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0906 - val_loss: 1.4598 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0978\n",
            "Epoch 10: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1002 - val_loss: 1.4163 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 591ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.1188\n",
            "Epoch 1: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 3s 63ms/step - loss: 1.1188 - val_loss: 1.4085 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1396\n",
            "Epoch 2: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1409 - val_loss: 1.4389 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1366\n",
            "Epoch 3: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1345 - val_loss: 1.4502 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1351\n",
            "Epoch 4: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1356 - val_loss: 1.4777 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1101\n",
            "Epoch 5: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1151 - val_loss: 1.4553 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0883\n",
            "Epoch 6: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0941 - val_loss: 1.4263 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0956\n",
            "Epoch 7: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1036 - val_loss: 1.4568 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1094\n",
            "Epoch 8: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1089 - val_loss: 1.3918 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1321\n",
            "Epoch 9: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1283 - val_loss: 1.4119 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1084\n",
            "Epoch 10: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1090 - val_loss: 1.4448 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.1039\n",
            "Epoch 1: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 2s 61ms/step - loss: 1.1039 - val_loss: 1.4154 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1266\n",
            "Epoch 2: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1205 - val_loss: 1.4265 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1158\n",
            "Epoch 3: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1173 - val_loss: 1.4131 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1150\n",
            "Epoch 4: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1102 - val_loss: 1.5003 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1201\n",
            "Epoch 5: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1144 - val_loss: 1.4565 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1031\n",
            "Epoch 6: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0993 - val_loss: 1.4169 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1149\n",
            "Epoch 7: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1181 - val_loss: 1.4294 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0904\n",
            "Epoch 8: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0981 - val_loss: 1.4209 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1136\n",
            "Epoch 9: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1134 - val_loss: 1.4147 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1048\n",
            "Epoch 10: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1000 - val_loss: 1.4112 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.1455\n",
            "Epoch 1: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 3s 60ms/step - loss: 1.1440 - val_loss: 1.5078 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1531\n",
            "Epoch 2: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1578 - val_loss: 1.5037 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1535\n",
            "Epoch 3: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1551 - val_loss: 1.4646 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1190\n",
            "Epoch 4: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1170 - val_loss: 1.4279 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1315\n",
            "Epoch 5: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1332 - val_loss: 1.4430 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1217\n",
            "Epoch 6: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1239 - val_loss: 1.5132 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1355\n",
            "Epoch 7: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1381 - val_loss: 1.4533 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1227\n",
            "Epoch 8: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1157 - val_loss: 1.6364 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1325\n",
            "Epoch 9: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1347 - val_loss: 1.4713 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1551\n",
            "Epoch 10: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1584 - val_loss: 1.5655 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 590ms/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.1220\n",
            "Epoch 1: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 3s 62ms/step - loss: 1.1180 - val_loss: 1.4097 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.0998\n",
            "Epoch 2: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1017 - val_loss: 1.4033 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1012\n",
            "Epoch 3: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1000 - val_loss: 1.4037 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1131\n",
            "Epoch 4: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1136 - val_loss: 1.4848 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1302\n",
            "Epoch 5: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1284 - val_loss: 1.4530 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1367\n",
            "Epoch 6: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1394 - val_loss: 1.4255 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1047\n",
            "Epoch 7: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1109 - val_loss: 1.4330 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1021\n",
            "Epoch 8: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.0988 - val_loss: 1.4557 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1151\n",
            "Epoch 9: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1152 - val_loss: 1.4148 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1226\n",
            "Epoch 10: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1239 - val_loss: 1.4382 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 594ms/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.1181\n",
            "Epoch 1: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 2s 61ms/step - loss: 1.1173 - val_loss: 1.3998 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1040\n",
            "Epoch 2: val_loss did not improve from 1.38061\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1085 - val_loss: 1.3963 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1249\n",
            "Epoch 3: val_loss improved from 1.38061 to 1.37640, saving model to /content/drive/My Drive/FYP Data/model/LSTM_rolling_long_1234.h5\n",
            "20/20 [==============================] - 1s 49ms/step - loss: 1.1291 - val_loss: 1.3764 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1241\n",
            "Epoch 4: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1234 - val_loss: 1.4267 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1220\n",
            "Epoch 5: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1240 - val_loss: 1.4155 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1036\n",
            "Epoch 6: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1067 - val_loss: 1.3990 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1222\n",
            "Epoch 7: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1198 - val_loss: 1.4345 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1090\n",
            "Epoch 8: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1097 - val_loss: 1.4120 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1131\n",
            "Epoch 9: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1159 - val_loss: 1.4467 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1297\n",
            "Epoch 10: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1350 - val_loss: 1.4192 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.0950\n",
            "Epoch 1: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 2s 59ms/step - loss: 1.1041 - val_loss: 1.4499 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1067\n",
            "Epoch 2: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1079 - val_loss: 1.3996 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1287\n",
            "Epoch 3: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1352 - val_loss: 1.4140 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1309\n",
            "Epoch 4: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1271 - val_loss: 1.4717 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1134\n",
            "Epoch 5: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1130 - val_loss: 1.4701 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1122\n",
            "Epoch 6: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1114 - val_loss: 1.3907 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1729\n",
            "Epoch 7: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 1.1697 - val_loss: 1.4155 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1344\n",
            "Epoch 8: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1295 - val_loss: 1.4380 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1327\n",
            "Epoch 9: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1299 - val_loss: 1.4530 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1275\n",
            "Epoch 10: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1298 - val_loss: 1.4590 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 611ms/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.1146\n",
            "Epoch 1: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 3s 62ms/step - loss: 1.1250 - val_loss: 1.3819 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1062\n",
            "Epoch 2: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1060 - val_loss: 1.3942 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1330\n",
            "Epoch 3: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1335 - val_loss: 1.4436 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1589\n",
            "Epoch 4: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1593 - val_loss: 1.4403 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1301\n",
            "Epoch 5: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1318 - val_loss: 1.4427 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1694\n",
            "Epoch 6: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1650 - val_loss: 1.4074 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1624\n",
            "Epoch 7: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1586 - val_loss: 1.4073 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1263\n",
            "Epoch 8: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1301 - val_loss: 1.4091 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1226\n",
            "Epoch 9: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1216 - val_loss: 1.4364 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1358\n",
            "Epoch 10: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1383 - val_loss: 1.4018 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 615ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.1353\n",
            "Epoch 1: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 3s 60ms/step - loss: 1.1353 - val_loss: 1.4269 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1093\n",
            "Epoch 2: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1151 - val_loss: 1.4015 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1193\n",
            "Epoch 3: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1185 - val_loss: 1.4249 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1661\n",
            "Epoch 4: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1658 - val_loss: 1.5495 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1358\n",
            "Epoch 5: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1372 - val_loss: 1.4389 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1350\n",
            "Epoch 6: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1364 - val_loss: 1.4015 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1466\n",
            "Epoch 7: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1427 - val_loss: 1.5187 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1393\n",
            "Epoch 8: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1370 - val_loss: 1.4550 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1259\n",
            "Epoch 9: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1290 - val_loss: 1.4242 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1366\n",
            "Epoch 10: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1422 - val_loss: 1.4457 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 592ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.1301\n",
            "Epoch 1: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 3s 64ms/step - loss: 1.1301 - val_loss: 1.3927 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1433\n",
            "Epoch 2: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1394 - val_loss: 1.4254 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1248\n",
            "Epoch 3: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 1.1306 - val_loss: 1.4250 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1263\n",
            "Epoch 4: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1317 - val_loss: 1.4275 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1365\n",
            "Epoch 5: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1376 - val_loss: 1.4723 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1593\n",
            "Epoch 6: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1580 - val_loss: 1.4096 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1678\n",
            "Epoch 7: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1632 - val_loss: 1.4614 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1321\n",
            "Epoch 8: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1342 - val_loss: 1.4171 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1475\n",
            "Epoch 9: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1456 - val_loss: 1.4543 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1413\n",
            "Epoch 10: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1405 - val_loss: 1.4038 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 613ms/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.1154\n",
            "Epoch 1: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 3s 61ms/step - loss: 1.1153 - val_loss: 1.4471 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1336\n",
            "Epoch 2: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1284 - val_loss: 1.4293 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1318\n",
            "Epoch 3: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1326 - val_loss: 1.4149 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1326\n",
            "Epoch 4: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1321 - val_loss: 1.4039 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1427\n",
            "Epoch 5: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1455 - val_loss: 1.4092 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1217\n",
            "Epoch 6: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1230 - val_loss: 1.4438 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1253\n",
            "Epoch 7: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1205 - val_loss: 1.3847 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1159\n",
            "Epoch 8: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1159 - val_loss: 1.3899 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1647\n",
            "Epoch 9: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1605 - val_loss: 1.4921 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1438\n",
            "Epoch 10: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1450 - val_loss: 1.4702 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.1433\n",
            "Epoch 1: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 2s 62ms/step - loss: 1.1433 - val_loss: 1.4503 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1543\n",
            "Epoch 2: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1536 - val_loss: 1.4898 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1550\n",
            "Epoch 3: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1613 - val_loss: 1.4287 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1616\n",
            "Epoch 4: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1572 - val_loss: 1.4673 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1500\n",
            "Epoch 5: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1426 - val_loss: 1.4742 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1474\n",
            "Epoch 6: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1521 - val_loss: 1.4383 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1605\n",
            "Epoch 7: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1583 - val_loss: 1.4199 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1350\n",
            "Epoch 8: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1370 - val_loss: 1.4208 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1343\n",
            "Epoch 9: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1349 - val_loss: 1.4234 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1523\n",
            "Epoch 10: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1545 - val_loss: 1.4004 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1495\n",
            "Epoch 1: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 3s 61ms/step - loss: 1.1425 - val_loss: 1.4113 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1420\n",
            "Epoch 2: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1463 - val_loss: 1.4304 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1457\n",
            "Epoch 3: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1455 - val_loss: 1.4278 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1508\n",
            "Epoch 4: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1520 - val_loss: 1.3991 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1398\n",
            "Epoch 5: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1467 - val_loss: 1.4213 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1487\n",
            "Epoch 6: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1482 - val_loss: 1.4742 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1507\n",
            "Epoch 7: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1475 - val_loss: 1.4023 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1608\n",
            "Epoch 8: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1599 - val_loss: 1.4556 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1499\n",
            "Epoch 9: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1489 - val_loss: 1.4580 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1591\n",
            "Epoch 10: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1584 - val_loss: 1.4171 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 592ms/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.1495\n",
            "Epoch 1: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 2s 61ms/step - loss: 1.1443 - val_loss: 1.4276 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1424\n",
            "Epoch 2: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1437 - val_loss: 1.4029 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1476\n",
            "Epoch 3: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1520 - val_loss: 1.4135 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1558\n",
            "Epoch 4: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1562 - val_loss: 1.4484 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1820\n",
            "Epoch 5: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1798 - val_loss: 1.4178 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1537\n",
            "Epoch 6: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1505 - val_loss: 1.4598 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1394\n",
            "Epoch 7: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1403 - val_loss: 1.4618 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1558\n",
            "Epoch 8: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1536 - val_loss: 1.4158 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1695\n",
            "Epoch 9: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1686 - val_loss: 1.4311 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1574\n",
            "Epoch 10: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1580 - val_loss: 1.4163 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 595ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.1471\n",
            "Epoch 1: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 2s 60ms/step - loss: 1.1471 - val_loss: 1.4237 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1354\n",
            "Epoch 2: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1345 - val_loss: 1.4240 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1435\n",
            "Epoch 3: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1487 - val_loss: 1.4323 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1346\n",
            "Epoch 4: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1344 - val_loss: 1.4332 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1589\n",
            "Epoch 5: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1571 - val_loss: 1.4443 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1583\n",
            "Epoch 6: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1581 - val_loss: 1.4890 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1599\n",
            "Epoch 7: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1627 - val_loss: 1.3996 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1970\n",
            "Epoch 8: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1926 - val_loss: 1.4595 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1618\n",
            "Epoch 9: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1650 - val_loss: 1.4268 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1799\n",
            "Epoch 10: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1758 - val_loss: 1.4438 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 1/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1357\n",
            "Epoch 1: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 2s 62ms/step - loss: 1.1369 - val_loss: 1.3962 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1444\n",
            "Epoch 2: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1413 - val_loss: 1.4973 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1550\n",
            "Epoch 3: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1522 - val_loss: 1.4518 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1435\n",
            "Epoch 4: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1448 - val_loss: 1.4238 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1573\n",
            "Epoch 5: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1606 - val_loss: 1.5456 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1734\n",
            "Epoch 6: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1665 - val_loss: 1.4871 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1574\n",
            "Epoch 7: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1614 - val_loss: 1.4219 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1672\n",
            "Epoch 8: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1637 - val_loss: 1.4300 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1675\n",
            "Epoch 9: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1657 - val_loss: 1.4438 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1631\n",
            "Epoch 10: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1606 - val_loss: 1.4474 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 603ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.1481\n",
            "Epoch 1: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 3s 103ms/step - loss: 1.1481 - val_loss: 1.4067 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1793\n",
            "Epoch 2: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1724 - val_loss: 1.4631 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1478\n",
            "Epoch 3: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1426 - val_loss: 1.4138 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1542\n",
            "Epoch 4: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1510 - val_loss: 1.4397 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1678\n",
            "Epoch 5: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1702 - val_loss: 1.4651 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1556\n",
            "Epoch 6: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1519 - val_loss: 1.4463 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1506\n",
            "Epoch 7: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1509 - val_loss: 1.4965 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1614\n",
            "Epoch 8: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1638 - val_loss: 1.4143 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1802\n",
            "Epoch 9: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1771 - val_loss: 1.4284 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1676\n",
            "Epoch 10: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1670 - val_loss: 1.4288 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 634ms/step\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.1533\n",
            "Epoch 1: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 3s 60ms/step - loss: 1.1533 - val_loss: 1.4552 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1748\n",
            "Epoch 2: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1736 - val_loss: 1.4095 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1528\n",
            "Epoch 3: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1522 - val_loss: 1.4081 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1523\n",
            "Epoch 4: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1515 - val_loss: 1.4294 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1736\n",
            "Epoch 5: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1645 - val_loss: 1.4250 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1469\n",
            "Epoch 6: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1537 - val_loss: 1.4245 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1469\n",
            "Epoch 7: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1505 - val_loss: 1.4175 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1482\n",
            "Epoch 8: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1523 - val_loss: 1.4345 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1572\n",
            "Epoch 9: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1549 - val_loss: 1.4456 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1569\n",
            "Epoch 10: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1549 - val_loss: 1.4116 - lr: 0.0100\n",
            "1/1 [==============================] - 1s 587ms/step\n",
            "Epoch 1/10\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 1.1330\n",
            "Epoch 1: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 2s 60ms/step - loss: 1.1327 - val_loss: 1.3963 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1502\n",
            "Epoch 2: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1527 - val_loss: 1.4225 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1358\n",
            "Epoch 3: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1372 - val_loss: 1.4210 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1447\n",
            "Epoch 4: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1474 - val_loss: 1.3953 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1763\n",
            "Epoch 5: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.1803 - val_loss: 1.4306 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1684\n",
            "Epoch 6: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1683 - val_loss: 1.4171 - lr: 0.0100\n",
            "Epoch 7/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1930\n",
            "Epoch 7: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1891 - val_loss: 1.4543 - lr: 0.0100\n",
            "Epoch 8/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1654\n",
            "Epoch 8: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1665 - val_loss: 1.4167 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1608\n",
            "Epoch 9: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1580 - val_loss: 1.4400 - lr: 0.0100\n",
            "Epoch 10/10\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 1.1711\n",
            "Epoch 10: val_loss did not improve from 1.37640\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 1.1701 - val_loss: 1.4081 - lr: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = np.vstack([predictions[i] for i in range(26)])\n",
        "#Model Evaluation\n",
        "#predictions = scaler.inverse_transform(predictions)\n",
        "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "print('rmse', rmse)\n",
        "\n",
        "#profit test\n",
        "test_period = time[n_past+train_point:]\n",
        "\n",
        "#calculate the top 10 stock we picked\n",
        "stock_selection_index = np.argsort(predictions)[:,-30:]\n",
        "stock_selection = []\n",
        "for index in stock_selection_index:\n",
        "  stock_list = []\n",
        "  for stock_i in index:\n",
        "    stock_list.append(SP500_ticker[stock_i])\n",
        "  stock_selection.append(stock_list)\n",
        "\n",
        "#trading simulate\n",
        "original_money = 0\n",
        "trading = 0\n",
        "for stock in stock_selection[0]:\n",
        "  original_money = original_money + stock_data[stock][\"Close\"][test_period[0]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[0]])\n",
        "\n",
        "\n",
        "trading = - original_money\n",
        "i = 0\n",
        "\n",
        "for stock_list in stock_selection:\n",
        "  if i==0 or 25:\n",
        "    i = i + 1\n",
        "    continue\n",
        "\n",
        "  for stock in stock_list:\n",
        "    trading = trading + stock_data[stock][\"Close\"][test_period[i-1]] - stock_data[stock][\"Close\"][test_period[i]]\n",
        "    #print(trading)\n",
        "  \n",
        "  i = i + 1\n",
        "\n",
        "end_money = 0\n",
        "\n",
        "for stock in stock_selection[-1]:\n",
        "  trading = trading + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  end_money = end_money + stock_data[stock][\"Close\"][test_period[-1]]\n",
        "  #print(stock_data[stock][\"Close\"][test_period[-1]])\n",
        "\n",
        "print('The money earned by LSTM with Fundamental and Technical data is ',trading)\n",
        "print('The money earned by LSTM with Fundamental and Technical data is %',trading*100/original_money)\n",
        "print('The money earned by LSTM with Fundamental and Technical data is %(unchange)',(end_money-original_money)*100/original_money)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkwGETM04v3b",
        "outputId": "d6200d98-b01e-4069-d594-5e87ec4dded3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rmse 0.04123566888845884\n",
            "The money earned by LSTM with Fundamental and Technical data is  -5697.271071434021\n",
            "The money earned by LSTM with Fundamental and Technical data is % -47.54179265008586\n",
            "The money earned by LSTM with Fundamental and Technical data is %(unchange) -47.54179265008586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_stock_selection = pd.DataFrame (stock_selection)\n",
        "df_stock_selection.to_csv(\"drive/My Drive/FYP Data/LSTM_TF_long_rolling_123.csv\",index=True, header=True )"
      ],
      "metadata": {
        "id": "GMnqD-A72Ctz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a1HlYlJLDYpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New data preprocessing"
      ],
      "metadata": {
        "id": "mS14D5cJDkn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_df = pd.read_csv(\"drive/My Drive/FYP Data/Long_label_1234.csv\",index_col = 0)\n",
        "label_df = label_df.reindex(index=label_df.index[::-1])\n",
        "label_df.reset_index()\n",
        "label_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "mYJTXt7DDySs",
        "outputId": "d9ce3065-aee7-42c9-d04c-9ae474751afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            MMM  AOS  ABT  ABBV  ACN  ATVI  ADM  ADBE  ADP  AAP  ...  WTW  \\\n",
              "Date                                                             ...        \n",
              "2000-01-31    2    1    3     0    0     1    1     3    2    0  ...    0   \n",
              "2000-02-29    1    2    2     0    0     1    1     2    2    0  ...    0   \n",
              "2000-03-31    2    3    3     0    0     1    1     3    3    0  ...    0   \n",
              "2000-04-28    2    2    3     0    0     2    3     1    2    0  ...    0   \n",
              "2000-05-31    2    2    3     0    0     3    1     3    2    0  ...    0   \n",
              "...         ...  ...  ...   ...  ...   ...  ...   ...  ...  ...  ...  ...   \n",
              "2022-08-31    1    0    3     3    1     3    2     0    2    2  ...    3   \n",
              "2022-09-30    2    2    0     1    2     0    3     2    1    3  ...    1   \n",
              "2022-10-31    0    3    2     2    1     0    0     2    2    0  ...    3   \n",
              "2022-11-30    1    1    3     3    0     3    1     2    0    2  ...    3   \n",
              "2022-12-30    0    3    0     0    1     0    0     2    0    1  ...    1   \n",
              "\n",
              "            GWW  WYNN  XEL  XYL  YUM  ZBRA  ZBH  ZION  ZTS  \n",
              "Date                                                        \n",
              "2000-01-31    2     0    2    0    2     3    0     2    0  \n",
              "2000-02-29    3     0    2    0    3     1    0     1    0  \n",
              "2000-03-31    1     0    3    0    3     3    0     2    0  \n",
              "2000-04-28    1     0    2    0    1     1    0     3    0  \n",
              "2000-05-31    1     0    1    0    2     1    0     2    0  \n",
              "...         ...   ...  ...  ...  ...   ...  ...   ...  ...  \n",
              "2022-08-31    1     3    0    3    3     0    3     2    3  \n",
              "2022-09-30    3     0    0    3    2     1    1     0    0  \n",
              "2022-10-31    1     3    2    2    2     0    1     0    0  \n",
              "2022-11-30    0     3    3    2    3     1    3     1    1  \n",
              "2022-12-30    1     3    0    0    1     3    0     2    3  \n",
              "\n",
              "[276 rows x 500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89b7c62c-f18f-42c0-a2d9-50f17c8993ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MMM</th>\n",
              "      <th>AOS</th>\n",
              "      <th>ABT</th>\n",
              "      <th>ABBV</th>\n",
              "      <th>ACN</th>\n",
              "      <th>ATVI</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADBE</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AAP</th>\n",
              "      <th>...</th>\n",
              "      <th>WTW</th>\n",
              "      <th>GWW</th>\n",
              "      <th>WYNN</th>\n",
              "      <th>XEL</th>\n",
              "      <th>XYL</th>\n",
              "      <th>YUM</th>\n",
              "      <th>ZBRA</th>\n",
              "      <th>ZBH</th>\n",
              "      <th>ZION</th>\n",
              "      <th>ZTS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-31</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-29</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-31</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-04-28</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-05-31</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>276 rows Ã— 500 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89b7c62c-f18f-42c0-a2d9-50f17c8993ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89b7c62c-f18f-42c0-a2d9-50f17c8993ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89b7c62c-f18f-42c0-a2d9-50f17c8993ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_factor = pd.read_csv(\"drive/My Drive/FYP Data/stock data month.csv\",index_col = 0,header = [0,1])\n",
        "multi_factor = multi_factor.reindex(index=multi_factor.index[::-1])\n",
        "multi_factor.reset_index()\n",
        "multi_factor = multi_factor.drop(index='2023-01-31')\n",
        "multi_factor = multi_factor.drop(columns = ['year', 'month','if_last_date','date'], axis=1)\n",
        "multi_factor = multi_factor[84:]\n",
        "multi_factor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "id": "wD7Df7qgD4YA",
        "outputId": "b874e6d2-a110-4301-ab6f-4012f62996f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-98-5f3361fcc5b5>:5: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  multi_factor = multi_factor.drop(columns = ['year', 'month','if_last_date','date'], axis=1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 FOXA                                                         \\\n",
              "                 Open       High        Low      Close  Adj Close     Volume   \n",
              "Date                                                                           \n",
              "2000-01-31        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-02-29        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-03-31        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-04-28        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "2000-05-31        NaN        NaN        NaN        NaN        NaN        NaN   \n",
              "...               ...        ...        ...        ...        ...        ...   \n",
              "2022-08-31  34.400002  34.689999  34.160000  34.180000  33.940510  2479900.0   \n",
              "2022-09-30  30.719999  31.360001  30.549999  30.680000  30.465034  3276000.0   \n",
              "2022-10-31  28.840000  29.000000  28.469999  28.870001  28.667717  3363700.0   \n",
              "2022-11-30  31.629999  32.465000  31.250000  32.450001  32.222633  4222200.0   \n",
              "2022-12-30  30.299999  30.459999  29.920000  30.370001  30.157207  2620900.0   \n",
              "\n",
              "                   ZTS                                      ...   WTW   GWW  \\\n",
              "                  Open        High         Low       Close  ...    AD    AD   \n",
              "Date                                                        ...               \n",
              "2000-01-31         NaN         NaN         NaN         NaN  ...  1.00  0.44   \n",
              "2000-02-29         NaN         NaN         NaN         NaN  ...  1.00  1.00   \n",
              "2000-03-31         NaN         NaN         NaN         NaN  ...  1.00  0.40   \n",
              "2000-04-28         NaN         NaN         NaN         NaN  ...  1.00  0.88   \n",
              "2000-05-31         NaN         NaN         NaN         NaN  ...  1.00  1.00   \n",
              "...                ...         ...         ...         ...  ...   ...   ...   \n",
              "2022-08-31  158.160004  159.410004  156.210007  156.529999  ...  0.08  0.04   \n",
              "2022-09-30  150.419998  152.029999  148.039993  148.289993  ...  0.84  0.92   \n",
              "2022-10-31  152.110001  153.339996  149.839996  150.779999  ...  0.56  0.08   \n",
              "2022-11-30  148.089996  154.179993  146.910004  154.139999  ...  0.12  0.04   \n",
              "2022-12-30  147.199997  147.789993  144.740005  146.550003  ...  0.20  0.68   \n",
              "\n",
              "            WYNN   XEL   XYL   YUM  ZBRA   ZBH  ZION   ZTS  \n",
              "              AD    AD    AD    AD    AD    AD    AD    AD  \n",
              "Date                                                        \n",
              "2000-01-31  1.00  0.28  1.00  1.00  0.32  1.00  0.56  1.00  \n",
              "2000-02-29  1.00  0.96  1.00  1.00  0.84  1.00  0.84  1.00  \n",
              "2000-03-31  1.00  0.40  1.00  0.08  0.64  1.00  0.24  1.00  \n",
              "2000-04-28  1.00  0.08  1.00  0.04  0.36  1.00  0.24  1.00  \n",
              "2000-05-31  1.00  0.04  1.00  1.00  0.88  1.00  0.48  1.00  \n",
              "...          ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "2022-08-31  1.00  0.04  0.04  1.00  1.00  0.96  0.04  1.00  \n",
              "2022-09-30  0.32  1.00  0.92  0.96  1.00  0.88  1.00  0.92  \n",
              "2022-10-31  0.84  0.56  0.56  0.56  0.48  0.80  0.80  0.56  \n",
              "2022-11-30  0.16  0.04  0.04  0.04  0.36  0.36  0.32  0.32  \n",
              "2022-12-30  0.08  0.16  0.84  0.04  0.84  0.04  0.72  0.76  \n",
              "\n",
              "[276 rows x 6500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8a79396-08e8-4eda-948a-e430b203f7a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">FOXA</th>\n",
              "      <th colspan=\"4\" halign=\"left\">ZTS</th>\n",
              "      <th>...</th>\n",
              "      <th>WTW</th>\n",
              "      <th>GWW</th>\n",
              "      <th>WYNN</th>\n",
              "      <th>XEL</th>\n",
              "      <th>XYL</th>\n",
              "      <th>YUM</th>\n",
              "      <th>ZBRA</th>\n",
              "      <th>ZBH</th>\n",
              "      <th>ZION</th>\n",
              "      <th>ZTS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>...</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "      <th>AD</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.44</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.28</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-29</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.84</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.84</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-04-28</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.88</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.36</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-05-31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.88</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.48</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>34.400002</td>\n",
              "      <td>34.689999</td>\n",
              "      <td>34.160000</td>\n",
              "      <td>34.180000</td>\n",
              "      <td>33.940510</td>\n",
              "      <td>2479900.0</td>\n",
              "      <td>158.160004</td>\n",
              "      <td>159.410004</td>\n",
              "      <td>156.210007</td>\n",
              "      <td>156.529999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.04</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>30.719999</td>\n",
              "      <td>31.360001</td>\n",
              "      <td>30.549999</td>\n",
              "      <td>30.680000</td>\n",
              "      <td>30.465034</td>\n",
              "      <td>3276000.0</td>\n",
              "      <td>150.419998</td>\n",
              "      <td>152.029999</td>\n",
              "      <td>148.039993</td>\n",
              "      <td>148.289993</td>\n",
              "      <td>...</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.96</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.88</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>28.840000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>28.469999</td>\n",
              "      <td>28.870001</td>\n",
              "      <td>28.667717</td>\n",
              "      <td>3363700.0</td>\n",
              "      <td>152.110001</td>\n",
              "      <td>153.339996</td>\n",
              "      <td>149.839996</td>\n",
              "      <td>150.779999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>31.629999</td>\n",
              "      <td>32.465000</td>\n",
              "      <td>31.250000</td>\n",
              "      <td>32.450001</td>\n",
              "      <td>32.222633</td>\n",
              "      <td>4222200.0</td>\n",
              "      <td>148.089996</td>\n",
              "      <td>154.179993</td>\n",
              "      <td>146.910004</td>\n",
              "      <td>154.139999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>30.299999</td>\n",
              "      <td>30.459999</td>\n",
              "      <td>29.920000</td>\n",
              "      <td>30.370001</td>\n",
              "      <td>30.157207</td>\n",
              "      <td>2620900.0</td>\n",
              "      <td>147.199997</td>\n",
              "      <td>147.789993</td>\n",
              "      <td>144.740005</td>\n",
              "      <td>146.550003</td>\n",
              "      <td>...</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>276 rows Ã— 6500 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8a79396-08e8-4eda-948a-e430b203f7a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8a79396-08e8-4eda-948a-e430b203f7a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8a79396-08e8-4eda-948a-e430b203f7a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_factor_data[np.isnan(multi_factor_data)] = 0\n",
        "#get time list\n",
        "\n",
        "time = multi_factor_data.index.values\n",
        "time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sclCg9TrFrqa",
        "outputId": "431fe3a0-a927-4624-b405-c2a44cf12b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['2000-01-31', '2000-02-29', '2000-03-31', '2000-04-28',\n",
              "       '2000-05-31', '2000-06-30', '2000-07-31', '2000-08-31',\n",
              "       '2000-09-29', '2000-10-31', '2000-11-30', '2000-12-29',\n",
              "       '2001-01-31', '2001-02-28', '2001-03-30', '2001-04-30',\n",
              "       '2001-05-31', '2001-06-29', '2001-07-31', '2001-08-31',\n",
              "       '2001-09-28', '2001-10-31', '2001-11-30', '2001-12-31',\n",
              "       '2002-01-31', '2002-02-28', '2002-03-28', '2002-04-30',\n",
              "       '2002-05-31', '2002-06-28', '2002-07-31', '2002-08-30',\n",
              "       '2002-09-30', '2002-10-31', '2002-11-29', '2002-12-31',\n",
              "       '2003-01-31', '2003-02-28', '2003-03-31', '2003-04-30',\n",
              "       '2003-05-30', '2003-06-30', '2003-07-31', '2003-08-29',\n",
              "       '2003-09-30', '2003-10-31', '2003-11-28', '2003-12-31',\n",
              "       '2004-01-30', '2004-02-27', '2004-03-31', '2004-04-30',\n",
              "       '2004-05-28', '2004-06-30', '2004-07-30', '2004-08-31',\n",
              "       '2004-09-30', '2004-10-29', '2004-11-30', '2004-12-31',\n",
              "       '2005-01-31', '2005-02-28', '2005-03-31', '2005-04-29',\n",
              "       '2005-05-31', '2005-06-30', '2005-07-29', '2005-08-31',\n",
              "       '2005-09-30', '2005-10-31', '2005-11-30', '2005-12-30',\n",
              "       '2006-01-31', '2006-02-28', '2006-03-31', '2006-04-28',\n",
              "       '2006-05-31', '2006-06-30', '2006-07-31', '2006-08-31',\n",
              "       '2006-09-29', '2006-10-31', '2006-11-30', '2006-12-29',\n",
              "       '2007-01-31', '2007-02-28', '2007-03-30', '2007-04-30',\n",
              "       '2007-05-31', '2007-06-29', '2007-07-31', '2007-08-31',\n",
              "       '2007-09-28', '2007-10-31', '2007-11-30', '2007-12-31',\n",
              "       '2008-01-31', '2008-02-29', '2008-03-31', '2008-04-30',\n",
              "       '2008-05-30', '2008-06-30', '2008-07-31', '2008-08-29',\n",
              "       '2008-09-30', '2008-10-31', '2008-11-28', '2008-12-31',\n",
              "       '2009-01-30', '2009-02-27', '2009-03-31', '2009-04-30',\n",
              "       '2009-05-29', '2009-06-30', '2009-07-31', '2009-08-31',\n",
              "       '2009-09-30', '2009-10-30', '2009-11-30', '2009-12-31',\n",
              "       '2010-01-29', '2010-02-26', '2010-03-31', '2010-04-30',\n",
              "       '2010-05-28', '2010-06-30', '2010-07-30', '2010-08-31',\n",
              "       '2010-09-30', '2010-10-29', '2010-11-30', '2010-12-31',\n",
              "       '2011-01-31', '2011-02-28', '2011-03-31', '2011-04-29',\n",
              "       '2011-05-31', '2011-06-30', '2011-07-29', '2011-08-31',\n",
              "       '2011-09-30', '2011-10-31', '2011-11-30', '2011-12-30',\n",
              "       '2012-01-31', '2012-02-29', '2012-03-30', '2012-04-30',\n",
              "       '2012-05-31', '2012-06-29', '2012-07-31', '2012-08-31',\n",
              "       '2012-09-28', '2012-10-31', '2012-11-30', '2012-12-31',\n",
              "       '2013-01-31', '2013-02-28', '2013-03-28', '2013-04-30',\n",
              "       '2013-05-31', '2013-06-28', '2013-07-31', '2013-08-30',\n",
              "       '2013-09-30', '2013-10-31', '2013-11-29', '2013-12-31',\n",
              "       '2014-01-31', '2014-02-28', '2014-03-31', '2014-04-30',\n",
              "       '2014-05-30', '2014-06-30', '2014-07-31', '2014-08-29',\n",
              "       '2014-09-30', '2014-10-31', '2014-11-28', '2014-12-31',\n",
              "       '2015-01-30', '2015-02-27', '2015-03-31', '2015-04-30',\n",
              "       '2015-05-29', '2015-06-30', '2015-07-31', '2015-08-31',\n",
              "       '2015-09-30', '2015-10-30', '2015-11-30', '2015-12-31',\n",
              "       '2016-01-29', '2016-02-29', '2016-03-31', '2016-04-29',\n",
              "       '2016-05-31', '2016-06-30', '2016-07-29', '2016-08-31',\n",
              "       '2016-09-30', '2016-10-31', '2016-11-30', '2016-12-30',\n",
              "       '2017-01-31', '2017-02-28', '2017-03-31', '2017-04-28',\n",
              "       '2017-05-31', '2017-06-30', '2017-07-31', '2017-08-31',\n",
              "       '2017-09-29', '2017-10-31', '2017-11-30', '2017-12-29',\n",
              "       '2018-01-31', '2018-02-28', '2018-03-29', '2018-04-30',\n",
              "       '2018-05-31', '2018-06-29', '2018-07-31', '2018-08-31',\n",
              "       '2018-09-28', '2018-10-31', '2018-11-30', '2018-12-31',\n",
              "       '2019-01-31', '2019-02-28', '2019-03-29', '2019-04-30',\n",
              "       '2019-05-31', '2019-06-28', '2019-07-31', '2019-08-30',\n",
              "       '2019-09-30', '2019-10-31', '2019-11-29', '2019-12-31',\n",
              "       '2020-01-31', '2020-02-28', '2020-03-31', '2020-04-30',\n",
              "       '2020-05-29', '2020-06-30', '2020-07-31', '2020-08-31',\n",
              "       '2020-09-30', '2020-10-30', '2020-11-30', '2020-12-31',\n",
              "       '2021-01-29', '2021-02-26', '2021-03-31', '2021-04-30',\n",
              "       '2021-05-28', '2021-06-30', '2021-07-30', '2021-08-31',\n",
              "       '2021-09-30', '2021-10-29', '2021-11-30', '2021-12-31',\n",
              "       '2022-01-31', '2022-02-28', '2022-03-31', '2022-04-29',\n",
              "       '2022-05-31', '2022-06-30', '2022-07-29', '2022-08-31',\n",
              "       '2022-09-30', '2022-10-31', '2022-11-30', '2022-12-30'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_factor_data['MMM']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "7KECaMfiHvMC",
        "outputId": "5e9be572-f9c3-4bf2-b64a-75ee057b79ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Open        High         Low       Close   Adj Close  \\\n",
              "Date                                                                     \n",
              "2000-01-31   46.125000   48.687500   46.031250   46.812500   25.322666   \n",
              "2000-02-29   42.656250   44.593750   42.312500   44.093750   24.006483   \n",
              "2000-03-31   45.187500   46.000000   44.281250   44.281250   24.108566   \n",
              "2000-04-28   43.718750   43.781250   43.000000   43.312500   23.581133   \n",
              "2000-05-31   43.062500   43.656250   42.875000   42.875000   23.494240   \n",
              "...                ...         ...         ...         ...         ...   \n",
              "2022-08-31  124.849998  126.459999  123.610001  124.349998  121.304688   \n",
              "2022-09-30  112.000000  113.150002  110.389999  110.500000  107.793869   \n",
              "2022-10-31  126.099998  126.449997  125.360001  125.790001  122.709427   \n",
              "2022-11-30  125.900002  126.250000  121.360001  125.970001  124.323906   \n",
              "2022-12-30  119.650002  120.029999  118.510002  119.919998  118.352959   \n",
              "\n",
              "                Volume        VEMA12        VSTD20       V20          AR  ...  \\\n",
              "Date                                                                      ...   \n",
              "2000-01-31   3282800.0  3.396133e+06  1.258872e+06  0.068587  154.302103  ...   \n",
              "2000-02-29   2765400.0  3.420850e+06  5.943768e+05  0.044478   91.292517  ...   \n",
              "2000-03-31   2459200.0  3.777333e+06  1.112069e+06  0.100248  174.311927  ...   \n",
              "2000-04-28   2947000.0  4.087617e+06  1.923669e+06  0.106520  108.888889  ...   \n",
              "2000-05-31   2137000.0  2.381167e+06  6.184604e+05  0.030176   71.906841  ...   \n",
              "...                ...           ...           ...       ...         ...  ...   \n",
              "2022-08-31  31642100.0  2.258349e+07  1.616253e+07  0.040454   71.351134  ...   \n",
              "2022-09-30   3112800.0  3.815517e+06  1.095232e+07  0.014331   55.208111  ...   \n",
              "2022-10-31   4326200.0  3.581908e+06  8.146275e+05  0.029522  150.489714  ...   \n",
              "2022-11-30   5830600.0  2.614475e+06  9.948474e+05  0.019789   97.537094  ...   \n",
              "2022-12-30   2096000.0  2.889992e+06  1.286652e+06  0.020080   69.415663  ...   \n",
              "\n",
              "               peRatio   pbRatio  evToSales  receivablesTurnover  \\\n",
              "Date                                                               \n",
              "2000-01-31   21.917166  6.189360  10.228160             1.448164   \n",
              "2000-02-29   21.917166  6.189360  10.228160             1.448164   \n",
              "2000-03-31   18.080753  5.627306   9.267104             1.441993   \n",
              "2000-04-28   18.080753  5.627306   9.267104             1.441993   \n",
              "2000-05-31   18.080753  5.627306   9.267104             1.441993   \n",
              "...                ...       ...        ...                  ...   \n",
              "2022-08-31  236.836891  5.377173  10.145611             1.770859   \n",
              "2022-09-30    4.071806  4.463949   8.813598             1.825286   \n",
              "2022-10-31    4.071806  4.463949   8.813598             1.825286   \n",
              "2022-11-30    4.071806  4.463949   8.813598             1.825286   \n",
              "2022-12-30   30.584033  4.480965   9.744875             1.782657   \n",
              "\n",
              "            payablesTurnover  debtToAssets  inventoryTurnover       roe  \\\n",
              "Date                                                                      \n",
              "2000-01-31          2.231151      0.520725           1.107882  0.070599   \n",
              "2000-02-29          2.231151      0.520725           1.107882  0.070599   \n",
              "2000-03-31          2.302846      0.551936           1.075463  0.077808   \n",
              "2000-04-28          2.302846      0.551936           1.075463  0.077808   \n",
              "2000-05-31          2.302846      0.551936           1.075463  0.077808   \n",
              "...                      ...           ...                ...       ...   \n",
              "2022-08-31          1.556065      0.697243           0.902214  0.005676   \n",
              "2022-09-30          1.543585      0.693434           0.842030  0.274077   \n",
              "2022-10-31          1.543585      0.693434           0.842030  0.274077   \n",
              "2022-11-30          1.543585      0.693434           0.842030  0.274077   \n",
              "2022-12-30          1.440465      0.682058           0.853500  0.036628   \n",
              "\n",
              "            revenuePerShare  cashPerShare  \n",
              "Date                                       \n",
              "2000-01-31         5.057833      0.554438  \n",
              "2000-02-29         5.057833      0.554438  \n",
              "2000-03-31         5.094292      0.346995  \n",
              "2000-04-28         5.094292      0.346995  \n",
              "2000-05-31         5.094292      0.346995  \n",
              "...                     ...           ...  \n",
              "2022-08-31        15.239930      5.225919  \n",
              "2022-09-30        15.152954      6.309775  \n",
              "2022-10-31        15.152954      6.309775  \n",
              "2022-11-30        15.152954      6.309775  \n",
              "2022-12-30        14.638521      7.053814  \n",
              "\n",
              "[276 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73c7ce25-62e3-4eba-bc67-54a9574cc96e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>VEMA12</th>\n",
              "      <th>VSTD20</th>\n",
              "      <th>V20</th>\n",
              "      <th>AR</th>\n",
              "      <th>...</th>\n",
              "      <th>peRatio</th>\n",
              "      <th>pbRatio</th>\n",
              "      <th>evToSales</th>\n",
              "      <th>receivablesTurnover</th>\n",
              "      <th>payablesTurnover</th>\n",
              "      <th>debtToAssets</th>\n",
              "      <th>inventoryTurnover</th>\n",
              "      <th>roe</th>\n",
              "      <th>revenuePerShare</th>\n",
              "      <th>cashPerShare</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-31</th>\n",
              "      <td>46.125000</td>\n",
              "      <td>48.687500</td>\n",
              "      <td>46.031250</td>\n",
              "      <td>46.812500</td>\n",
              "      <td>25.322666</td>\n",
              "      <td>3282800.0</td>\n",
              "      <td>3.396133e+06</td>\n",
              "      <td>1.258872e+06</td>\n",
              "      <td>0.068587</td>\n",
              "      <td>154.302103</td>\n",
              "      <td>...</td>\n",
              "      <td>21.917166</td>\n",
              "      <td>6.189360</td>\n",
              "      <td>10.228160</td>\n",
              "      <td>1.448164</td>\n",
              "      <td>2.231151</td>\n",
              "      <td>0.520725</td>\n",
              "      <td>1.107882</td>\n",
              "      <td>0.070599</td>\n",
              "      <td>5.057833</td>\n",
              "      <td>0.554438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-29</th>\n",
              "      <td>42.656250</td>\n",
              "      <td>44.593750</td>\n",
              "      <td>42.312500</td>\n",
              "      <td>44.093750</td>\n",
              "      <td>24.006483</td>\n",
              "      <td>2765400.0</td>\n",
              "      <td>3.420850e+06</td>\n",
              "      <td>5.943768e+05</td>\n",
              "      <td>0.044478</td>\n",
              "      <td>91.292517</td>\n",
              "      <td>...</td>\n",
              "      <td>21.917166</td>\n",
              "      <td>6.189360</td>\n",
              "      <td>10.228160</td>\n",
              "      <td>1.448164</td>\n",
              "      <td>2.231151</td>\n",
              "      <td>0.520725</td>\n",
              "      <td>1.107882</td>\n",
              "      <td>0.070599</td>\n",
              "      <td>5.057833</td>\n",
              "      <td>0.554438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-31</th>\n",
              "      <td>45.187500</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>44.281250</td>\n",
              "      <td>44.281250</td>\n",
              "      <td>24.108566</td>\n",
              "      <td>2459200.0</td>\n",
              "      <td>3.777333e+06</td>\n",
              "      <td>1.112069e+06</td>\n",
              "      <td>0.100248</td>\n",
              "      <td>174.311927</td>\n",
              "      <td>...</td>\n",
              "      <td>18.080753</td>\n",
              "      <td>5.627306</td>\n",
              "      <td>9.267104</td>\n",
              "      <td>1.441993</td>\n",
              "      <td>2.302846</td>\n",
              "      <td>0.551936</td>\n",
              "      <td>1.075463</td>\n",
              "      <td>0.077808</td>\n",
              "      <td>5.094292</td>\n",
              "      <td>0.346995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-04-28</th>\n",
              "      <td>43.718750</td>\n",
              "      <td>43.781250</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.312500</td>\n",
              "      <td>23.581133</td>\n",
              "      <td>2947000.0</td>\n",
              "      <td>4.087617e+06</td>\n",
              "      <td>1.923669e+06</td>\n",
              "      <td>0.106520</td>\n",
              "      <td>108.888889</td>\n",
              "      <td>...</td>\n",
              "      <td>18.080753</td>\n",
              "      <td>5.627306</td>\n",
              "      <td>9.267104</td>\n",
              "      <td>1.441993</td>\n",
              "      <td>2.302846</td>\n",
              "      <td>0.551936</td>\n",
              "      <td>1.075463</td>\n",
              "      <td>0.077808</td>\n",
              "      <td>5.094292</td>\n",
              "      <td>0.346995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-05-31</th>\n",
              "      <td>43.062500</td>\n",
              "      <td>43.656250</td>\n",
              "      <td>42.875000</td>\n",
              "      <td>42.875000</td>\n",
              "      <td>23.494240</td>\n",
              "      <td>2137000.0</td>\n",
              "      <td>2.381167e+06</td>\n",
              "      <td>6.184604e+05</td>\n",
              "      <td>0.030176</td>\n",
              "      <td>71.906841</td>\n",
              "      <td>...</td>\n",
              "      <td>18.080753</td>\n",
              "      <td>5.627306</td>\n",
              "      <td>9.267104</td>\n",
              "      <td>1.441993</td>\n",
              "      <td>2.302846</td>\n",
              "      <td>0.551936</td>\n",
              "      <td>1.075463</td>\n",
              "      <td>0.077808</td>\n",
              "      <td>5.094292</td>\n",
              "      <td>0.346995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>124.849998</td>\n",
              "      <td>126.459999</td>\n",
              "      <td>123.610001</td>\n",
              "      <td>124.349998</td>\n",
              "      <td>121.304688</td>\n",
              "      <td>31642100.0</td>\n",
              "      <td>2.258349e+07</td>\n",
              "      <td>1.616253e+07</td>\n",
              "      <td>0.040454</td>\n",
              "      <td>71.351134</td>\n",
              "      <td>...</td>\n",
              "      <td>236.836891</td>\n",
              "      <td>5.377173</td>\n",
              "      <td>10.145611</td>\n",
              "      <td>1.770859</td>\n",
              "      <td>1.556065</td>\n",
              "      <td>0.697243</td>\n",
              "      <td>0.902214</td>\n",
              "      <td>0.005676</td>\n",
              "      <td>15.239930</td>\n",
              "      <td>5.225919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>112.000000</td>\n",
              "      <td>113.150002</td>\n",
              "      <td>110.389999</td>\n",
              "      <td>110.500000</td>\n",
              "      <td>107.793869</td>\n",
              "      <td>3112800.0</td>\n",
              "      <td>3.815517e+06</td>\n",
              "      <td>1.095232e+07</td>\n",
              "      <td>0.014331</td>\n",
              "      <td>55.208111</td>\n",
              "      <td>...</td>\n",
              "      <td>4.071806</td>\n",
              "      <td>4.463949</td>\n",
              "      <td>8.813598</td>\n",
              "      <td>1.825286</td>\n",
              "      <td>1.543585</td>\n",
              "      <td>0.693434</td>\n",
              "      <td>0.842030</td>\n",
              "      <td>0.274077</td>\n",
              "      <td>15.152954</td>\n",
              "      <td>6.309775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>126.099998</td>\n",
              "      <td>126.449997</td>\n",
              "      <td>125.360001</td>\n",
              "      <td>125.790001</td>\n",
              "      <td>122.709427</td>\n",
              "      <td>4326200.0</td>\n",
              "      <td>3.581908e+06</td>\n",
              "      <td>8.146275e+05</td>\n",
              "      <td>0.029522</td>\n",
              "      <td>150.489714</td>\n",
              "      <td>...</td>\n",
              "      <td>4.071806</td>\n",
              "      <td>4.463949</td>\n",
              "      <td>8.813598</td>\n",
              "      <td>1.825286</td>\n",
              "      <td>1.543585</td>\n",
              "      <td>0.693434</td>\n",
              "      <td>0.842030</td>\n",
              "      <td>0.274077</td>\n",
              "      <td>15.152954</td>\n",
              "      <td>6.309775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>125.900002</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>121.360001</td>\n",
              "      <td>125.970001</td>\n",
              "      <td>124.323906</td>\n",
              "      <td>5830600.0</td>\n",
              "      <td>2.614475e+06</td>\n",
              "      <td>9.948474e+05</td>\n",
              "      <td>0.019789</td>\n",
              "      <td>97.537094</td>\n",
              "      <td>...</td>\n",
              "      <td>4.071806</td>\n",
              "      <td>4.463949</td>\n",
              "      <td>8.813598</td>\n",
              "      <td>1.825286</td>\n",
              "      <td>1.543585</td>\n",
              "      <td>0.693434</td>\n",
              "      <td>0.842030</td>\n",
              "      <td>0.274077</td>\n",
              "      <td>15.152954</td>\n",
              "      <td>6.309775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>119.650002</td>\n",
              "      <td>120.029999</td>\n",
              "      <td>118.510002</td>\n",
              "      <td>119.919998</td>\n",
              "      <td>118.352959</td>\n",
              "      <td>2096000.0</td>\n",
              "      <td>2.889992e+06</td>\n",
              "      <td>1.286652e+06</td>\n",
              "      <td>0.020080</td>\n",
              "      <td>69.415663</td>\n",
              "      <td>...</td>\n",
              "      <td>30.584033</td>\n",
              "      <td>4.480965</td>\n",
              "      <td>9.744875</td>\n",
              "      <td>1.782657</td>\n",
              "      <td>1.440465</td>\n",
              "      <td>0.682058</td>\n",
              "      <td>0.853500</td>\n",
              "      <td>0.036628</td>\n",
              "      <td>14.638521</td>\n",
              "      <td>7.053814</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>276 rows Ã— 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73c7ce25-62e3-4eba-bc67-54a9574cc96e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73c7ce25-62e3-4eba-bc67-54a9574cc96e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73c7ce25-62e3-4eba-bc67-54a9574cc96e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get multifactor list\n",
        "multifactor_list = Technical_list+fundamental_list\n",
        "\n",
        "# get x_dataset, y_dataset\n",
        "multi_factor_data = multi_factor_data.astype(float)\n",
        "label_df = label_df.astype(float)\n",
        "x_dataset = []\n",
        "y_dataset = []\n",
        "multi_factor_ticker = []\n",
        "\n",
        "for ticker in tqdm(SP500_ticker):\n",
        "  y_dataset.append(label_df[ticker])\n",
        "  #print(ticker)\n",
        "  for factor in multifactor_list:\n",
        "    multi_factor_ticker.append(multi_factor_data[ticker, factor])\n",
        "\n",
        "y_dataset = np.array(y_dataset).T\n",
        "x_dataset = np.array(x_dataset).T\n",
        "\n",
        "print('y_dataset',y_dataset.shape)\n",
        "print('x_dataset',x_dataset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "c6e70cec92084e2e812c0d84b0be376e",
            "e44e7227d46d42d4a4e61f96c0449b19",
            "348df167dbb04d059291d44a6829a334",
            "77f5ae7a46134bdaa55a20759cc9c2d0",
            "048a8ef3bdc5411995994c592a69e87c",
            "16a087cfd3db4e169c674d0020de7ddd",
            "c768b1e6414249a68ce67962a86ec96f",
            "d3da43a635654d61a97c7693f9c7136e",
            "0a62ea14e8024ce8bfca0e1e1db8fac2",
            "c3317fafacde4d9099df5ab9cab0e988",
            "46a8cd48c97746a8b51ba09c2dc6120c"
          ]
        },
        "id": "jinpIfp5FlMT",
        "outputId": "c734b247-325f-466c-f99a-42d520c86616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6e70cec92084e2e812c0d84b0be376e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_dataset (276, 500)\n",
            "x_dataset (276, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGGVg21NG04t",
        "outputId": "c7b0cf0a-9d7c-4e51-d74c-2d6610594400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.68125000e+01, 3.28280000e+06, 3.39613333e+06, ...,\n",
              "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "x_dataset = scaler.fit_transform(x_dataset)\n",
        "y_dataset = scaler.fit_transform(y_dataset)\n",
        "x_dataset.shape"
      ],
      "metadata": {
        "id": "GwxbT1xpFxIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparation of training set\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i in range(n_past, len(x_dataset) - n_future +1):\n",
        "  #print(i)\n",
        "  X.append(x_dataset[i - n_past:i,:])\n",
        "Y = y_dataset[n_past:]\n",
        "X, Y = np.array(X), np.array(Y)\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "AvJY6SASF0jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_point = X.shape[0]-26\n",
        "\n",
        "#Preparation of test set\n",
        "x_train = X[0:train_point]\n",
        "y_train = Y[0:train_point]\n",
        "\n",
        "x_test = X[train_point:]\n",
        "y_test = Y[train_point:]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "NRscItSgF2fD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNVB+mG2wagJKZ6FsUiN7R9",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6e70cec92084e2e812c0d84b0be376e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e44e7227d46d42d4a4e61f96c0449b19",
              "IPY_MODEL_348df167dbb04d059291d44a6829a334",
              "IPY_MODEL_77f5ae7a46134bdaa55a20759cc9c2d0"
            ],
            "layout": "IPY_MODEL_048a8ef3bdc5411995994c592a69e87c"
          }
        },
        "e44e7227d46d42d4a4e61f96c0449b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16a087cfd3db4e169c674d0020de7ddd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c768b1e6414249a68ce67962a86ec96f",
            "value": "100%"
          }
        },
        "348df167dbb04d059291d44a6829a334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3da43a635654d61a97c7693f9c7136e",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a62ea14e8024ce8bfca0e1e1db8fac2",
            "value": 500
          }
        },
        "77f5ae7a46134bdaa55a20759cc9c2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3317fafacde4d9099df5ab9cab0e988",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_46a8cd48c97746a8b51ba09c2dc6120c",
            "value": " 500/500 [00:01&lt;00:00, 243.91it/s]"
          }
        },
        "048a8ef3bdc5411995994c592a69e87c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16a087cfd3db4e169c674d0020de7ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c768b1e6414249a68ce67962a86ec96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3da43a635654d61a97c7693f9c7136e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a62ea14e8024ce8bfca0e1e1db8fac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3317fafacde4d9099df5ab9cab0e988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46a8cd48c97746a8b51ba09c2dc6120c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70c5b167d69b4cfdb4fbb3dec4ccbaab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de8bd591cb6a4ff19aa3184e8c34c447",
              "IPY_MODEL_6444f2e66f6240d4b91d87be65497c8e",
              "IPY_MODEL_dd4c62282ce841fcbe77f83f20b64ad2"
            ],
            "layout": "IPY_MODEL_8a682286f6374973a07d15397d9bd447"
          }
        },
        "de8bd591cb6a4ff19aa3184e8c34c447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90c7cb64659245378833e391230f758f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c2fcd3e215c6401ba93de100d2bf193c",
            "value": "100%"
          }
        },
        "6444f2e66f6240d4b91d87be65497c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_806a464727674843a12f7ce55e4ee8f0",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3073da8b73d64e07b0fc51bc062a1964",
            "value": 500
          }
        },
        "dd4c62282ce841fcbe77f83f20b64ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_680a0bdb067b459bb6595d932304fd4e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7da5668281b3446ea1684bfc7786ba68",
            "value": " 500/500 [00:00&lt;00:00, 1202.59it/s]"
          }
        },
        "8a682286f6374973a07d15397d9bd447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c7cb64659245378833e391230f758f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2fcd3e215c6401ba93de100d2bf193c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "806a464727674843a12f7ce55e4ee8f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3073da8b73d64e07b0fc51bc062a1964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "680a0bdb067b459bb6595d932304fd4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da5668281b3446ea1684bfc7786ba68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "867a567209184bf8a7aac60c39f836cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e87c17598c245ec8707cad59cf8cdad",
              "IPY_MODEL_2820dedc911f41ff876795807a4df66a",
              "IPY_MODEL_ae8efcbb8fa444acbf9e05336909ff02"
            ],
            "layout": "IPY_MODEL_3fae791a12044b87a2fc79d576fa4d43"
          }
        },
        "2e87c17598c245ec8707cad59cf8cdad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e5fbdb5ef03439ba2f576a5fa88430b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4d2d0a955cd7419586e17c246b418f96",
            "value": "100%"
          }
        },
        "2820dedc911f41ff876795807a4df66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc53ad5c84ec41fba30b6cc5b016ae73",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89d02ba505b649d1a70d81c547bc6356",
            "value": 500
          }
        },
        "ae8efcbb8fa444acbf9e05336909ff02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50f0dc003d66484898ac232d79efb105",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3e13da0773154c6b94ec006842bf5ce9",
            "value": " 500/500 [00:00&lt;00:00, 582.36it/s]"
          }
        },
        "3fae791a12044b87a2fc79d576fa4d43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e5fbdb5ef03439ba2f576a5fa88430b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d2d0a955cd7419586e17c246b418f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc53ad5c84ec41fba30b6cc5b016ae73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89d02ba505b649d1a70d81c547bc6356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50f0dc003d66484898ac232d79efb105": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e13da0773154c6b94ec006842bf5ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80ef02b5b2e349528bf54c67094be30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98e08d0ba04f46c481f02db75868d286",
              "IPY_MODEL_59f5b0291fec4e5cb717f449b49da0a8",
              "IPY_MODEL_90f94970061448baa4fbcd4c04229a72"
            ],
            "layout": "IPY_MODEL_6442a9e5e127479b9bc863db54a007cc"
          }
        },
        "98e08d0ba04f46c481f02db75868d286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de8f5e6092be445e8544cdec2ec26717",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0a4d85eb46d84a4db9496d5f7420a419",
            "value": "100%"
          }
        },
        "59f5b0291fec4e5cb717f449b49da0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4a1141c3091474b9a51d04ad1905293",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9eb5fecc6004552a1ebe5d32414607f",
            "value": 500
          }
        },
        "90f94970061448baa4fbcd4c04229a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f1c7164ba6545d3bebec129c3d45745",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e8557f46463f4fefb68ebf56f141fc97",
            "value": " 500/500 [00:00&lt;00:00, 1238.95it/s]"
          }
        },
        "6442a9e5e127479b9bc863db54a007cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de8f5e6092be445e8544cdec2ec26717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a4d85eb46d84a4db9496d5f7420a419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4a1141c3091474b9a51d04ad1905293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9eb5fecc6004552a1ebe5d32414607f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f1c7164ba6545d3bebec129c3d45745": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8557f46463f4fefb68ebf56f141fc97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23feb6203fe74ed5ad5412e53c3835d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2fdae44a22040e0b3c60654ba6b0353",
              "IPY_MODEL_fd54f23a6c20497091414e821e46724c",
              "IPY_MODEL_958dde2f5a1c439ca3408b436520b9f9"
            ],
            "layout": "IPY_MODEL_c352d92a7118454da967cdda387e4bbe"
          }
        },
        "f2fdae44a22040e0b3c60654ba6b0353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ec5cae9e4184336a6c79a95ae46e0f8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3f3efb60c6bc482698f30f0619a9350a",
            "value": "100%"
          }
        },
        "fd54f23a6c20497091414e821e46724c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5194fbdc39c740cba6d8920a87a212b9",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bf7e40db1d64962804bb56f72f407db",
            "value": 500
          }
        },
        "958dde2f5a1c439ca3408b436520b9f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53c2584ec2104f5b90763de9905975ae",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b1c34a090910476fa7f5e7ac9aceb995",
            "value": " 500/500 [00:01&lt;00:00, 346.72it/s]"
          }
        },
        "c352d92a7118454da967cdda387e4bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec5cae9e4184336a6c79a95ae46e0f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f3efb60c6bc482698f30f0619a9350a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5194fbdc39c740cba6d8920a87a212b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bf7e40db1d64962804bb56f72f407db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53c2584ec2104f5b90763de9905975ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1c34a090910476fa7f5e7ac9aceb995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "532961c98d67440ca589bc61c0a7ff3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71ba8353a7b4416d8d733044555bc815",
              "IPY_MODEL_f620b2595d4d4e0ea8ebff8e5ee7e36d",
              "IPY_MODEL_145baa11c9cb41afb1787518a607f3e0"
            ],
            "layout": "IPY_MODEL_afff8d0761e94b9d945460b700ecc033"
          }
        },
        "71ba8353a7b4416d8d733044555bc815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c6b1a9cb3cc494ca31e8dd243d7b5fd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b7806d7262e943ba93e71488f207f6ac",
            "value": "100%"
          }
        },
        "f620b2595d4d4e0ea8ebff8e5ee7e36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79a2927e56e742a9851b4772179fd6f3",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b543d43578ac4528877fb4ccb6e03858",
            "value": 500
          }
        },
        "145baa11c9cb41afb1787518a607f3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7108cf7aa5a40e7aaee7ffa5bdc2eba",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_03bacc9e50b84c6fba35473707682f74",
            "value": " 500/500 [00:01&lt;00:00, 422.75it/s]"
          }
        },
        "afff8d0761e94b9d945460b700ecc033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6b1a9cb3cc494ca31e8dd243d7b5fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7806d7262e943ba93e71488f207f6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79a2927e56e742a9851b4772179fd6f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b543d43578ac4528877fb4ccb6e03858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7108cf7aa5a40e7aaee7ffa5bdc2eba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03bacc9e50b84c6fba35473707682f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "620c2af3075b4ecfb7addabf248b7f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_deb6b4c4f5a34324b02b615cc3295bff",
              "IPY_MODEL_0bb6f564907d49e19e34e31ca75892ea",
              "IPY_MODEL_bf36acb0f3fe47ffb8772b344fa99d5c"
            ],
            "layout": "IPY_MODEL_328268cb36aa4dfea7adccfe854414de"
          }
        },
        "deb6b4c4f5a34324b02b615cc3295bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_447dbb959e6d4bf18bccf2fe927cfcf7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_573649a3fa444cbd95ad0c9c8b13c690",
            "value": "100%"
          }
        },
        "0bb6f564907d49e19e34e31ca75892ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e28cdf2772824dbf8f223c3df85a5b77",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e4298c243ab4f5ba54193747daa97d7",
            "value": 26
          }
        },
        "bf36acb0f3fe47ffb8772b344fa99d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_327deda11ff0445ebfb583218b57ed08",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_789fb395675942938f228ffde5f8fcd0",
            "value": " 26/26 [05:25&lt;00:00, 12.81s/it]"
          }
        },
        "328268cb36aa4dfea7adccfe854414de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "447dbb959e6d4bf18bccf2fe927cfcf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "573649a3fa444cbd95ad0c9c8b13c690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e28cdf2772824dbf8f223c3df85a5b77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e4298c243ab4f5ba54193747daa97d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "327deda11ff0445ebfb583218b57ed08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "789fb395675942938f228ffde5f8fcd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e7764be5d5040b59674327193ba2480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4f5b5025b614b36a0b0501200560841",
              "IPY_MODEL_63e2099dbba44a93a94adb6aff462f9c",
              "IPY_MODEL_d64eb3ea9f954b0e80be7aba4ffce549"
            ],
            "layout": "IPY_MODEL_41f09347971c4b089364f8657f340b76"
          }
        },
        "c4f5b5025b614b36a0b0501200560841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7063794290324b2ab5e6a56331840e57",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f3b8de3aa16e4e5894dee380e74c7756",
            "value": "100%"
          }
        },
        "63e2099dbba44a93a94adb6aff462f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87820eefc9804a08a9f0ef9b23e56c80",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27718b57383549be809a79a7451f1326",
            "value": 26
          }
        },
        "d64eb3ea9f954b0e80be7aba4ffce549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8b70c88b1334f8dbdc27bc83cb600f2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f0ba9bdc69bf4369a3ce6da165f05c9e",
            "value": " 26/26 [05:17&lt;00:00, 11.57s/it]"
          }
        },
        "41f09347971c4b089364f8657f340b76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7063794290324b2ab5e6a56331840e57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3b8de3aa16e4e5894dee380e74c7756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87820eefc9804a08a9f0ef9b23e56c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27718b57383549be809a79a7451f1326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8b70c88b1334f8dbdc27bc83cb600f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0ba9bdc69bf4369a3ce6da165f05c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}